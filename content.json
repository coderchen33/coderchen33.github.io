{"pages":[],"posts":[{"title":"物理层","text":"主要内容 物理层的任务 信道复用技术 宽带接入技术 物理层任务主要任务：确定与传输媒体的接口的一些特性。 机械特性 ：指明接口所用接线器的形状和尺寸、引线数目和排列、固定和锁定装置等。 电气特性：指明在接口电缆的各条线上出现的电压的范围。4V— 6V表示二进制“0”,用-4V—-6V表示二进制“1” 功能特性：指明某条线上出现的某一电平的电压表示何种意义。 过程特性 ：指明对于不同功能的各种可能事件的出现顺序。 信道复用技术 频分复用：所有主机在相同的时间占用不同的频率带宽资源 时分复用：所有主机在不同的时间占用相同的频率带宽资源 统计时分复用：是对时分复用的一种改进，不固定每个用户在时分复用帧中的位置，只要有数据就集中起来组成统计时分复用帧然后发送 宽带接入技术 ADSL非对称数字用户线ASDL是用数字技术对模拟电话用户线进行改造。 ADSL把0~4kHZ的低频谱留给传统电话使用，而把原来没有被利用的高端频谱留给用户上网使用。 由于我们在上网时主要是从互联网上下载各种文档，而向互联网发送的信息量一般都不打。因此ADSL的下行(从ISP到用户)带宽都远大于上行(从用户到ISP)带宽，因此成为非对称的。 ADSL 的特点： 上行和下行带宽做成不对称的。 ADSL 在用户线（铜线）的两端各安装一个 ADSL 调制解调器。 我国目前采用的方案是离散多音调 DMT，DMT 调制技术采用频分复用的方法 ADSL 采用自适应调制技术使用户线能够传送尽可能高的数据率 光纤同轴混合网（HFC网）在有线电视网的基础上开发的一种居民宽带接入网。 用户接口盒 UIB (User Interface Box) 要提供三种连接，即： 使用同轴电缆连接到机顶盒 (set-top box)，然后再连接到用户的电视机。 使用双绞线连接到用户的电话机。 使用电缆调制解调器连接到用户的计算机。 FTTx FTTx 表示 Fiber To The…（光纤到…），例如： 光纤到户 FTTH (Fiber To The Home)：光纤一直铺设到用户家庭，可能是居民接入网最后的解决方法。 光纤到大楼 FTTB (Fiber To The Building)：光纤进入大楼后就转换为电信号，然后用电缆或双绞线分配到各用户。 光纤到路边 FTTC (Fiber To The Curb)：光纤铺到路边，从路边到各用户可使用星形结构双绞线作为传输媒体。","link":"/2020/03/07/%E2%80%9C%E7%89%A9%E7%90%86%E5%B1%82/"},{"title":"传输层","text":"主要内容 传输层概念、端口号、套接字 UDP传输特点和数据报格式 TCP传输特点和数据报格式 可靠传输原理 TCP可靠运输的实现 TCP流量控制、拥塞控制 三次握手和四次握手抓包分析 传输层运输层向它上面应用层提供通信服务，它属于面向通信部分的最高层，同时也是用户功能中的最底层。 两个主机进行通信实际上就是两个主机中的应用进程互相通信。应用进程之间的通信又称为端到端的通信。 传输层有两种不同的协议：用户数据报协议UDP和传输控制协议TCP 学习这两个重要协议之前，先简单了解下端口的概念。 端口端口(16位)用来对 TCP/IP 体系的应用进程进行区分。 端口号只具有本地意义，即端口号只是为了标志本计算机应用层中的各进程。在因特网中不同计算机的相同端口号是没有联系的。 端口号分为两类： 服务端使用的端口号服务器端使用的端口又分为两类：熟知端口和登记端口。熟知端口数值一般为0~1023(比如我们常见的http使用的就是80端口)。登记端口数值为1024 ~ 49151，这些端口是为没有熟知端口号的应用程序使用的。使用这个范围的端口号必须在 IANA 登记，以防止重复。 服务器端常见端口号： 客户端使用的端口号数值为49152~65535，留给客户进程选择暂时使用，仅在客户进程运行时才动态选择，因此又叫短暂端口号。当服务器进程收到客户进程的报文时，就知道了客户进程所使用的动态端口号。通信结束后，这个端口号可供其他客户进程以后使用。 套接字套接字针对的是TCP连接，每一条TCP连接有两个端点，那两个端点称为套接字（socket） 端口号拼接到IP地址后面构成套接字。套接字socket=（IP地址：端口号） 所以每一条TCP连接唯一地被通信两端的两个端点（两个套接字）所确定。即：TCP连接::={socket1,socket2}={(IP1:port1),(IP2:port2)} 用户数据报协议UDPUDP 只在IP的数据报服务之上增加了很少一点的功能，即端口的功能和差错检测的功能。 UDP特点 无连接 (即发送数据之前不需要建立连接) 不可靠 (UDP使用尽最大努力交付，即不保证可靠交付，同时也不使用拥塞控制) 面向报文 (对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部) 支持一对一、一对多、多对一、多对多的交互通信 UDP没有拥塞机制(网络出现拥塞不会使源主机发送速率降低，对于一些实时应用如视频会议等十分合适) UDP首部开销小 只有8个字节，比TCP20个字节要短。 UDP首部 首部字段只有 8 个字节，包括：源端口 源端口号，在需要对方回信时调用目的端口 目的端口号 在重点交付报文时使用长度：UDP用户数据报的长度，其最小值是8（仅有首部）检验和 检测UDP用户数据报在传输中是否有错，有错就丢弃。 注意： 虽然在UDP之间的通信要用到其端口号，但由于UDP通信是无连接的，因此不需要使用套接字。 在计算检验和时，要在UDP用户数据报之前添加12个字节的“伪首部”。这个伪首部既不向下传递也不向上递交。仅仅是为了计算检验和。 UDP在计算检验和时是把首部和数据部分一起检验，而IP数据报首部检验和只检验IP数据报首部，不检验数据部分 传输控制协议TCPTCP除了基本的数据交付和差错检查外，还提供了可靠数据传输和拥塞控制服务 TCP特点 面向连接 (应用程序使用TCP协议前必须先建立TCP连接) 只能是点对点的（一对一） (每一条TCP连接只能有两个端点) 提供可靠交付 (TCP连接传送的数据无差错、不丢失、不重复，按序到达) 全双工通信 允许通信双方的应用进程再任何时候都能发送数据。 面向字节流 （把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块） TCP首部 源端口和目的端口：各占2个字节，分别写入源端口号和目的端口号。 序号 ：占4个字节。序号范围是[0,2^32 - 1],用于对字节流进行编号。例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：占4个字节，是期望收到对方下一个报文段的第一个数据字节的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。若确认号=N，则表明：到序号N-1为止的所有数据都已正确收到 数据偏移 ：占4位，指的是TCP报文段数据起始处距离报文段起始处的偏移量，实际上指的是TCP报文段的首部长度。 保留：占6位，保留为今后使用，但目前应置为0. 紧急URG:当URG=1时，表明紧急指针字段有效。告诉系统此报文段中有紧急数据，应尽快传送，而不要按原来的排队顺序来传送。 确认 ACK ：仅当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 推送PSH：发送方把PSH置1，并立即创建一个报文段发送出去，接收方TCP收到PSH=1的报文段，就尽快地交付接收应用进程，而不用等到整个缓存都填满了后再向上交付。很少使用 复位RST：当RST=1时，表明TCP连接中出现严重差错，必须释放连接，然后再重新建立运输连接。 同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口 ：占2个字节。值是[0,2^16 - 1]之间的整数。窗口指的是发送本报文段一方的接收窗口。窗口值告诉对方：从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量（以字节为单位）。窗口字段明确指出了现在允许对方发送的数据量。窗口值经常在动态变化。 检验和：占2个字节。检验和字段检验的范围包括首部和数据这两部分。和UDP一样，在计算检验和时，要在TCP报文段的前面加上12字节的伪首部。 紧急指针：占2个字节。紧急指针仅在URG=1时才有意义，它指出本报文段中的紧急数据的字节数。 选项： 长度可变，最长可达40字节。当没有使用选项是，TCP首部为20字节。 可靠传输原理理想的传输条件有以下两个特点： 传输信道不产生差错。 不管发送方以多快的速度发送数据，接收方总是来得及处理收到的数据。然而实际的网络都不具备以上两个理想条件。必须使用一些可靠传输协议，在不可靠的传输信道实现可靠传输 那么在TCP中就有两种方式来实现可靠传输了 停止等待协议 连续 ARQ 协议 停止等待协议“停止等待”就是每发送完一个分组就停止发送，等待对方的确认。在收到确认后再发送下一个分组。 停止等待协议有两种情况： 无差错情况如下图a，A发送分组M1，发送完就暂停，等待B的确认。B收到了M1就向A发送确认。A收到了对M1的确认后就再发送下一个分组M2。之后收到确认后再发送M3 出现差错可能M1在传输过程中直接丢失，B未收到分组则什么也不做或者B收到分组后检测出了差错，就丢弃M1并且也什么都不做。 对于上面分组丢失的问题，可靠传输协议的解决： A 为每一个已发送的分组都设置了一个超时计时器。 A 只要在超时计时器到期之前收到了相应的确认，就撤销该超时计时器，继续发送下一个分组 M2 。 注意： 在发送完一个分组后，必须暂时保留已发送的分组的副本，以备重发。 分组和确认分组都必须进行编号。 超时计时器的重传时间应当比数据在分组传输的平均往返时间更长一些。 像上述的这种可靠传输协议常称为自动重传请求 ARQ (Automatic Repeat reQuest)。即重传的请求是自动进行的，接收方不需要请求发送方重传某个出错的分组。 为了提高传输效率，发送方可以不使用低效率的停止等待协议，而是采用流水线传输。 流水线传输就是发送方可连续发送多个分组，不必每发完一个分组就停顿下来等待对方的确认。这样可使信道上一直有数据不间断地传送。 连续ARQ协议滑动窗口协议是TCP协议的精髓，现在简单介绍下 发送方维持的发送窗口，它的意义是：位于发送窗口内的分组都可连续发送出去，而不需要等待对方的确认。这样，信道利用率就提高了。 连续 ARQ 协议规定，发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置。 即不必对收到的分组逐个发送确认，而是对按序到达的最后一个分组发送确认，这样就表示：到这个分组为止的所有分组都已正确收到了。 优点：容易实现，即使确认丢失也不必重传。缺点：不能向发送方反映出接收方已经正确收到的所有分组的信息。 如果发送方发送了前 5 个分组，而中间的第 3 个分组丢失了。这时接收方只能对前两个分组发出确认。发送方无法知道后面三个分组的下落，而只好把后面的三个分组都再重传一次。这就叫做 Go-back-N（回退 N），表示需要再退回来重传已发送过的 N 个分组。 TCP可靠传输的实现上面我们已经了解了可靠传输的简单原理，现在我们看先TCP是如何具体实现的。 TCP 连接的每一端都必须设有一个发送窗口和一个接收窗口。两端的四个窗口经常处于动态变化之中。 TCP 的可靠传输机制用字节为单位使用字节序号进行控制。TCP 所有的确认都是基于序号而不是基于报文段。 TCP超时重传的时间选择不是固定不变的，而是自适应的（使用特定的算法估算较为合理的重传时间）。 TCP的流量控制 TCP流量控制通过滑动窗口实现，就是让发送方的发送速率不要太快，要让接收方来得及接收。 发送方的发送窗口不能超过接收方给出的接收窗口的数值。 如果B向A发送了零窗口的报文段后不久，B的接收缓存又有了一些存储空间，B向A发送非零窗口报文段，但是这个报文段丢失了，那么就会造成A一直等待收到B发送的非零窗口的通知，而B也一直等待A发送的数据，如果没有其他措施，这种互相等待的死锁局面会一直延续下去。 为了解决上述问题，TCP为每个连接接设有一个持续计时器，只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。 若持续计时器设置的时间到期，就发送一个零窗口探测报文段。对方在确认这个探测报文段时给出现在窗口值，如果窗口仍然是零，那么收到这个报文段的一方就重新设置持续计时器。如果窗口不是零就，就可以打破死锁的僵局。 TCP的拥塞控制拥塞控制原理出现拥塞的条件：对资源需求 &gt; 可用资源 即使增大资源也不是能解决拥塞的问题的。不但不能解决拥塞问题，而且还可能使网络的性能更坏。 拥塞引起的重传并不会缓解网络的拥塞，反而会加剧网络的拥塞。因为会引起更多的分组流入网络和被网络中的路由器丢弃。 拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载 拥塞控制和流量控制的区别 拥塞控制是全局性的，而流量控制是指点对点通信量的控制 拥塞控制是防止过多的数据注入到网路中，而流量控制是控制发送端发送数据的速率，以便接收端来得及接收。 拥塞控制的作用：注意横坐标代表的是单位时间内输入给网络的分组数目。 TCP拥塞控制方法有四种：慢开始、拥塞避免、快重传、快恢复。 拥塞的判断： 重传定时器超时 收到三个相同（重复）的 ACK（丢失个别报文段时，快重传对接收到的报文段的重复确认） 拥塞控制流程图：其中ssthresh为慢开始门限 TCP连接管理TCP连接建立(3次握手) 客户端A向服务器端B发出连接请求报文段，这时首部中的同步位SYN=1，同时选择一个初始序号seq=x。TCP规定，SYN报文段不能携带数据，但要消耗掉一个序号。这时，TCP客户进程进入SYN-SENT（同步已发送）状态。 B收到连接请求报文段后，如同意建立连接，则向A发送确认。在确认报文段中应把SYN位和确认ACK为都置1，确认号是ack=x+1，同时也为自己选择一个初始序号seq=y。这个报文段也不能携带数据，但同样要消耗一个序号。这时TCP服务器进程进入SYN-RCVD（同步收到）状态。 TCP客户进程收到B的确认后，还要向B给出确认。确认报文段的ACK置1.确认号ack=y+1，而自己的序号seq=x+1。TCP的标准规定，ACK报文段可以携带数据，但如果不携带数据则不消耗序号。这时，TCP连接已建立，A进入ESTABLISHEN（已建立连接）状态。 三次握手的理解第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常所以三次握手就能确认双发收发功能都正常，缺一不可。 理解清楚了之后,我们就知道为什么不能连接建立不能两次或者四次了 两次：如果没有第三次握手，服务器端无法知道自己发送和对方接收是否正常。例如，如果A发出的第一个连接请求报文没有丢失而是滞留在网络结点上，之后A再次发出请求与B建立连接，传送完数据后释放连接。这时A第一次发送的请求（失效报文）才到达B，B会误认为是A的又一个请求报文，就向A发送确认报文，同意建立连接。这时如果没有第三次握手，只要B发出确认，新的连接就直接建立，但是A没有发送建立连接请求，就会造成B一直等待A发送数据，造成B的资源浪费。 四次：没有必要，因为三次握手已经能够确保双方的收发功能正常。 抓包验证下吧第一次握手 第二次握手 第三次握手 TCP连接释放(4次挥手) 数据传输结束后，A和B处于ESTABLISHEN状态。A的应用进程先向其TCP发出连接释放报文段，并停止再发送数据，主动关闭TCP连接。A把连接释放报文段首部的FIN置1，其序号seq=u，等于前面已经传送过的数据的最后一个字节的加1.这时A进入FIN-WAIT-1（终止等待1）状态，等待B的确认。 B收到连接释放报文段后即发出确认，确认号是ack=u+1，而这个报文段自己的序号是v。等于B前面已经传送过的数据的最后一个字节的序号加1。然后B进入CLOSE-WAIT（关闭等待）状态。TCP服务器进程这时应通知高层应用进程，因而从A到B这个方向的连接就释放了，这时的TCP连接处于半关闭状态。即A已经没有数据要发送了，但B若发送数据，A仍要接受。A收到来自B的确认后，就进入FIN-WAIT-2（终止等待2）状态，等待B发出的连接释放报文段。 若B已经没有要向A发送的数据，其应用进程就通知TCP释放链接。这时B发出的报文段必须使FIN=1。现假定B的序号为w（在半关闭状态B可能由发送了一些数据）。B还必须重复上次已经发送过的确认号ack=u+1。这时B就进入LAST-ACK（最后确认）状态，等待A的确认。 A在收到B的连接释放报文段后，必须对此发出确认。在确认报文段中把ACK置1，确认号ack=w+1，而自己的序号是seq=u+1。然后进入到TIME-WAIT（时间等待）状态。请注意，现在TCP连接还没有释放掉。必须经过时间等待计时器设置的时间2MSL（最长报文段寿命）后，A才进入到CLOSED状态。时间MSL叫做最长报文段寿命（Maximum Segment Lifetime）。 这里抓包就不仔细分析了 A 必须等待 2MSL 的时间： 为了保证 A 发送的最后一个 ACK 报文段能够到达 B。（因为A最后发送的ACK报文段有可能丢失，因而B收不到A发送的FIN+ACK报文段的确认。B会超时重传FIN+ACK报文段，而A就能在2MSL内收到这个重传的FIN+ACK报文段，接着A重传一次确认，重新启动2MSL计时器。最后正常释放连接。如果A不等待2MSL而是在发送完ACK确认报文后立即释放连接，就无法收到B重传的FIN+ACK报文，因而也就不会发送确认报文，这样B就无法进入CLOSED状态） 防止 “已失效的连接请求报文段”出现在本连接中。A 在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段，都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。 此外，TCP还设有一个保活计时器。服务器每收到一次客户数据，就重新设置保活计时器(时间通常为2小时)。若两小时没有收到客户的数据，则服务器发送一个探测报文段，以后每隔75s发送一次。若一连发送10个探测报文段后仍无客户的响应，服务器就认为客户端出现了故障，接着就关闭这个连接。","link":"/2020/03/09/%E4%BC%A0%E8%BE%93%E5%B1%82/"},{"title":"计算机网络开篇","text":"计算机网络 搞起来 哇咔咔 互联网、因特网与万维网 互联网的组成 计算机网络类别 计算机网络的性能 计算机网络体系结构 互联网、因特网与万维网 互联网：网络把主机连接起来，而互联网是通过某种协议将多种不同的网络连接起来， 因此互联网是网络的网络。 国际标准的互联网写法是internet，字母i小写！ 因特网：采用TCP/IP协议族作为通信的规则的互联网。国际标准的因特网写法是Internet，字母I大写！ TCP/IP协议由很多协议组成，不同类型的协议又被放在不同的层，其中，位于应用层的协议就有很多，比如FTP、SMTP、HTTP。所以，因特网提供的服务一般包括有：www（万维网）服务、电子邮件服务（outlook）、远程登录（QQ）服务、文件传输（FTP）服务、网络电话等等 万维网(www)：只要应用层使用的是HTTP协议，就称为万维网。万维网又称环球网，是一种建立在Internet上的全球性的、交互的、动态、多平台、分布式、图形信息系统。它只是建立在Internet上的一种网络服务。 之所以在浏览器里输入百度网址时，能看见百度网提供的网页，就是因为你的个人浏览器和百度网的服务器之间使用的是HTTP协议在交流。 三者关系：互联网包含因特网，因特网包含万维网 目前，围绕互联网发展的业务主要有两类，分别是ISP（因特网服务提供商）与ICP（因特网网内容提供商） ISP(Internet Service Provider):指向广大用户综合提供互联网接入业务、信息业务和增值业务的电信运营商（比如中国电信、移动、联通提供的宽度服务）ISP拥有从因特网管理机构申请到的多个IP地址，同时拥有通信线路以及路由器等连网设备。中国的电信、网通等都是ISP，我们通常所说的上网就是指通过某个ISP接入到因特网，IP地址的管理机构不会把一个单个的IP地址分配给单个用户，而是把一批IP地址有偿地分配给经审查合格的ISP。现在的因特网是由全世界无数个大大小小的ISP所共同拥有的。 ICP(Internet Content Provider):向广大用户综合提供互联网信息和增值业务的企业（比如：新浪、搜狐、腾讯）。其实，我们说的ICP域名备案就是指互联网内容提供商向工信部提交经营审核。 互联网的组成因特网的拓扑结构虽然非常复杂，并且在地理上覆盖全球，单从工作方式上看，可以划分为以下两大块： 网络边缘：由所连接在因特网上的主机组成。这部分是用户直接使用的，用来进行通信和资源共享。主机也称为端系统 网络核心：由大量网络和连接这些网络的路由器组成。这部分是为边缘部分提供服务的 在互联网边缘的端系统之间的通信方式通常可划分为两类： 客户服务器方式（Client/Server, C/S方式）：客户和服务器都是指通信中所涉及到的两个应用进程。最主要的特征是：客户是服务请求方，服务器是服务提供方C/S方式是因特网上最常用的传统方式，我们在网上发送电子邮件或在网站上查找资料时，都是客户服务器方式。 对等方式（Peer-to-Peer, P2P方式）：两个主机在通信时并不区分哪一个是服务请求者还是服务提供者，这要两个主机都运行了对等连接软件，他们就可以进行平等的、对等连接通信。这时，双方都可以下载对方已经存储在硬盘中的共享文档，因此这种工作方式也称为P2P文件共享。 还有一种被称为浏览器服务器的方式（B/S, Browser/Server方式），可以看作是客户服务器方式的特例。只不过客户端是浏览器而已。 互联网核心部分 电路交换 ：电路交换用于电话通信系统，两个用户要通信之前需要建立一条专用的物理链路，并且在整个通信过程中始终占用该链路。由于通信的过程中不可能一直在使用传输线路，因此电路交换对线路的利用率很低，往往不到 10%。 分组交换 ：分组交换采用存储转发技术。每个分组都有首部和尾部，包含了源地址和目的地址等控制信息，在同一个传输线路上同时传输多个分组互相不会影响，因此在同一条传输线路上允许同时传输多个分组，也就是说分组交换不需要占用传输线路。 计算机网络类别按照网络的作用范围进行分类 广域网WAN:通过长距离(例如跨越不同国家)运送主机发送数据。 作用范围通常为几十到几千公里 城域网MAN: 一般是一个城市。 作用距离为5~50km 局域网LAN: 用计算机或工作站通过高速通信线路相连。作用距离为1km左右。学校或企业大都拥有多个互连的局域网称为校园网或企业网。 个人局域网PAN:把属于个人的电子设备用无线技术连接起来的网络，也常称为无线个人局域网(WPAN)。 作用距离10m左右。 按照网络的使用者进行分类 公用网： 指电信公司出资建造的大型网络。需要向电信公司交纳一定的费用 专用网： 指某个部门因为特殊业务工作需要而建造的网络。不向本单位以外的人提供服务。如军队、铁路、银行、电力系统等。 用来把用户接入到互联网的网络 接入网AN： 搭建起用户与互联网连接的”桥梁”。 计算机网络的性能 比特率：连接在计算机网络上的主机在数字信道上传送数据的速率。比特率速率的单位是b/s（比特每秒），有时候也写为bps，即bit persecond 带宽：表示在单位时间内从网络的某一点到另一点所能通过的最高数据率,单位是bit/s。 吞吐量：在单位时间内通过某个网络的实际数据量。是表示实际网络传输是的速率。 受网络带宽或网络的额定速率的限制。 时延：数据从网络一端传送到另一端所需要的时间。(1) 发送时延： 主机或路由器发送数据帧所需要的时间(2) 排队时延： 分组经过路由器后，要先在输入队列中排队等待处理(3) 处理时延： 主机或路由器收到分组时需要花费一定时间进行处理，如分析首部、提取数据部分、差错检测等。(4) 传播时延： 电磁波在信道中传播一定距离花费的时间。约为光速。 总时延 = 发送时延 + 排队时延 + 处理时 + 延传播时延 另外，在描述数据量大小时，往往使用字节（byte）作为度量单位。一个字节（记为大写的B）代表8个bit即1byte = 8bit在实际上网应用中，下载软件时常常看到诸如下载速度显示为176KB/s，103KB/s等宽带速率大小字样，因为ISP提供的线路带宽使用的单位是比特（bit），而一般下载软件显示的是字节（Byte）（1Byte=8bit），所以要通过换算，才能得实际值。我们以1M宽带为例，按照换算公式换算一下：1Mb/s=1024*1024b/s=1024K b/s=1024/8KB/s=128KB/s 计算机网络体系结构 OSI模型是国际标准组织提出过一个标准框架，只要遵循OSI标准，一个系统就可以和世界上任何地方的、也遵循统一标准的其他任何系统进行通信。但它既复杂又不实用。TCP/IP是一个四层的体系结构，包含应用层、传输层、网际层和网际接口层。不过从实质上讲，TCP/IP只有最上面的三层，网际接口层并没有什么具体内容。因此学习计算机网络的原理时往往采取折中的办法，即总和OSI和TCP/IP的优点，采用一种五层协议的体系结构。 下面看一下每层的具体作用： 应用层 ：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等协议。数据单位为报文。 传输层 ：为进程提供通用数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。传输层包括两种协议： 传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。 TCP 主要提供完整性服务，UDP 主要提供及时性服务。 网络层 ：为主机提供数据传输服务。而传输层协议是为主机中的进程提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据报封装成分组。 数据链路层 ：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。 物理层 ：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。 OSI中的剩余两层： 表示层 ：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。 会话层 ：建立及管理会话。五层协议没有表示层和会话层，而是将这些功能留给应用程序开发者处理。 数据传输过程： 在向下的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。","link":"/2020/03/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%BC%80%E7%AF%87/"},{"title":"数据链路层","text":"主要内容 数据链路层的三个基本问题：封装成帧、透明传输、差错检测 点对点信道PPP协议 和 广播信道CSMA/CD协议 局域网、以太网、MAC地址和适配器 集线器、网桥、交换机 虚拟局域网(VLAN) 以太网网络接入PPPoE协议 链路层提供的服务1.封装成帧所有在因特网上传送的数据都是以IP数据报为传送单位的，网络层的IP数据报传送到数据链路层就成为帧的数据部分，在帧的数据部分的前面和后面添加上首部和尾部，构成一个完整的帧。 图为RFC 1042和以太网的封装格式其中CRC字段用于帧内后续字节差错的循环冗余码检验 最大传送单元(MTU)(Maximum Transfer Unit)：每一种链路层协议都规定了帧的数据部分的长度上限。比如上图中以太网数据帧的长度最大值分别是1500字节。 路径MTU:如果两台主机之间的通信要通过多个网络，那么每个网络的链路层就可能有不同的MTU。重要的不是两台主机所在网络的MTU的值，重要的是两台通信主机路径中的最小MTU。它被称作路径MTU。注意：从A到B的路由可能与从B到A的路由不同，因此路径MTU在两个方向上不一定是一致的 2.透明传输透明传输，即无论什么样的比特流都能够通过数据链路层传输。 帧使用首部和尾部进行定界，如果帧的数据部分含有和首部尾部相同的内容，那么帧的开始和结束位置就会被错误的判定。 解决这种矛盾的方法是，将数据中可能出现的控制字符的前面插入转义字符“ESC”，而在接收端再删除该转义字符，这种方法被称为字节填充。这个过程透明传输的内容是转义字符，用户察觉不到转义字符的存在。 3.差错检测现实的通信线路都不会是理想的，比特在传输过程中可能会产生差错：1可能会变成0，0也可能会变成1。为了保证数据传输的可靠性，必须采用各种差错检测措施。目前在数据链路层广泛使用的是循环冗余检验CRC（Cyclic Redundancy Check） 我们并没有要求数据链路层向网络层提供“可靠传输”服务，是因为：“可靠传输”指的是数据链路层发送端发送什么，在接收端就收到什么。而传输差错除了上面提到的比特差错外，还会有一些其他差错。如帧丢失、帧重复或帧失序。 信道分类点对点信道一对一通信因为不会发生碰撞，因此也比较简单，使用 PPP(Point-to-PointProtocol)协议进行控制。 PPP协议我们知道，因特网用户通常都要连接到某个ISP才能接入到因特网。PPP协议就是用户计算机和ISP进行通信时所使用的数据链路层协议。 PPP协议由三个部分组成：（1）一个将IP数据报封装到串行链路的方法。（2）一个用来建立、配置和测试数据链路连接的链路控制协议LCP（Link Control Protocol）。（3）一套网络控制协议NCP（Network Control Protocol）。 当用户拨号接入ISP后，就建立了一条从用户PC机到ISP的物理连接。这时，用户PC机向ISP发送一系列的LCP分组（封装成多个PPP帧），以便建立LCP连接。这些分组及其响应选择了将要使用的一些PPP参数。接着还要进行网络层配置，NCP给新接入的用户PC机分配一个临时的IP地址。这样，用户PC机就成为一个拥有IP地址的主机了。 当用户通信完毕时，NCP释放网络层连接，收回原来分配出去的IP地址。接着，LCP释放数据链路层连接。最后释放的是物理层的连接。 PPP帧结构 F 字段为帧的定界符 A 和 C 字段暂时没有意义 FCS 字段是使用 CRC 的检验序列 信息部分的长度不超过 1500 广播信道一对多通信 一个节点发送的数据能够被广播信道上所有的节点接收到。局域网就是一个很好的例子 由于所有的节点都在同一个广播信道上发送数据，因此需要有专门的控制方法进行协调，避免发生冲突（冲突也叫碰撞）。 主要有两种控制方法进行协调，一个是使用信道复用技术(代价较高，不适用于局域网)，一是使用 CSMA/CD（载波监听多点接入/碰撞检测）协议。 CSMA/CD协议CSMA/CD 表示载波监听多点接入 / 碰撞检测。 多点接入 ：说明这是总线型网络，许多主机以多点的方式连接到总线上。 载波监听 ：不管在发送前还是在发送中，每个主机都必须不停地监听信道。在发送前，如果监听到信道正在使用，就必须等待。 碰撞检测 ：在发送中，如果监听到信道已有其它主机正在发送数据，就表示发生了碰撞。虽然每个主机在发送数据之前都已经监听到信道为空闲，但是由于电磁波的传播时延的存在，还是有可能会发生碰撞。 记端到端的传播时延为 τ，最先发送的站点最多经过 2τ 就可以知道是否发生了碰撞，称2τ为争用期 。只有经过争用期之后还没有检测到碰撞，才能肯定这次发送不会发生碰撞。 当发生碰撞时，站点要停止发送，等待一段时间再发送。这个时间采用截断二进制指数退避算法来确定。从离散的整数集合 {0, 1, .., (2k-1)} 中随机取出一个数，记作 r，然后取r倍的争用期作为重传等待时间。 局域网局域网主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。 局域网具有广播功能，从一个站点可很方便地访问全网，局域网上的主机可共享连接在局域网上的各种硬件和软件资源。 局域网主要有以太网、令牌环网、FDDI 和 ATM 等局域网技术，目前以太网占领着有线局域网市场。 按照网络拓扑结构对局域网进行分类: 以太网由于以太网技术的快速发展，目前在局域网市场中占据了绝对优势，现在以太网几乎成为了局域网的同义词。 传统以太网是总线型网络结构，但随着集线器和双绞线的出现，以太网主要是星型网络拓扑结构。从表面上看，使用集线器的局域网在物理上是一个星型网，但由于集线器使用电子器件模拟实际电缆线工作，因此在逻辑上仍然是一个总线网，使用的还是CSMA/CD协议。 MAC地址MAC 地址是链路层地址，长度为 6 字节（48位），用于唯一标识网络适配器（网卡）。 一台主机拥有多少个网络适配器就有多少个 MAC 地址。例如笔记本电脑普遍存在无线网络适配器和有线网络适配器，因此就有两个 MAC 地址。 MAC帧格式： 如上图所示，MAC地址由五个字段组成。前两个字段为目的地址和源地址。第三个字段是类型字段，用来标识上一层使用的是什么协议，以便把收到的MAC帧的数据上交给上一层的这个协议。第四个字段是数据字段，最后一个是帧检验序列FCS（使用CRC检验）。 适配器计算机与外界局域网的连接是通过适配器。 计算机的硬件地址就在适配器的ROM中，而计算机的IP地址则在计算机的存储器中。 适配器有帧过滤功能。适配器从网络上每收到一个MAC帧就先用硬件检查MAC帧中的目的地址，如果是发往本站的帧则收下，否则丢弃。发往本站的帧包括以下三种帧： 单播帧，即收到的帧的MAC地址与本站的硬件地址相同。 广播帧，即发送给本局域网上所有站点的帧。（全1） 多播帧，即发送给本局域网上一部分站点的帧。 局域网的扩展在物理层扩展局域网集线器 采用双绞线的以太网采用星形拓扑，在星形的中心则增加了一种可靠性非常高的设备，叫做集线器(hub) 集线器使用电子器件模拟实际电缆线工作，因此在逻辑上仍然是一个总线网 由于是总线网结构,因此集线器使用的还是CSMA/CD协议。所以同一个时间只能有两个端口是互联的，其它的端口都处于载波侦听状态，无法使用网络带宽。 集线器工作在物理层， 作用于比特而不是帧.当一个比特到达接口时，集线器重新生成这个比特，并将其能量强度放大，从而扩大网络的传输距离，之后再将这个比特发送到其它所有接口。如果集线器同时收到两个不同接口的帧，那么就发生了碰撞。 优点： 使原来属于不同碰撞域的局域网上的计算机能够进行跨碰撞域的通信。 扩大了局域网覆盖的地理范围。 缺点 碰撞域增大了，但总的吞吐量并未提高。 如果不同的碰撞域使用不同的数据率，那么就不能用集线器将它们互连起来。 在数据链路层扩展局域网网桥 工作在数据链路层。具有过滤帧的功能,当网桥收到一个帧时，并不是向所有的接口转发此帧，而是先检查此帧的目的MAC地址，然后再确定将该帧转发到哪一个接口。 优点 过滤通信量。 扩大了物理范围。 提高了可靠性。 可互连不同物理层、不同 MAC 子层和不同速率（如10Mb/s 和 100 Mb/s 以太网）的局域网 缺点 存储转发增加了时延。 在MAC子层并没有流量控制功能。 具有不同 MAC子层的网段桥接在一起时时延更大。 网桥只适合于用户数不太多(不超过几百个)和通信量不太大的局域网，否则有时还会因传播过多的广播信息而产生网络拥塞。这就是所谓的广播风暴。 交换机 交换式集线器淘汰了网桥，并且由于性能远超普通集线器，淘汰了在物理层的集线器。目前以太网主要使用交换机 交换机工作在数据链路层，（又称以太网交换机、交换式集线器)。交换机实质上就是一个多接口的网桥。它不会发生碰撞，能根据 MAC 地址进行存储转发。 以太网交换机工作在全双工方式。区别于传统的使用集线器的总线以太网使用CSMA/CD协议，以半双工的方式工作，以太网交换机一般工作在全双工方式，不适用CSMA/CD协议 以太网交换机具有并行性 即能同时连通多对接口，使多对主机能同时通信。所以相互通信的主机都是独占传输媒体，无碰撞地传输数据。比如对于普通 10 Mb/s 的共享式以太网，若共有 N个用户，则每个用户占有的平均带宽只有总带宽(10 Mb/s)的 N 分之一。使用以太网交换机时，虽然在每个接口到主机的带宽还是 10 Mb/s，但由于一个用户在通信时是独占而不是和其他网络用户共享传输媒体的带宽，因此对于拥有 N 对接口的交换机的总容量为 N*10 Mb/s。这正是交换机的最大优点。 以太网交换机是即插即用的 以太网交换机内部的帧交换表（又称为地址表）是通过自学习算法自动地逐渐建立起来的。 虚拟局域网虚拟局域网（Virtual Local Area Network，VLAN）是一组逻辑上的设备和用户，通过端口分配、MAC地址分配等方式将同一局域网内的主机划分为不同的区域（VLAN），不同区域之间的主机无法直接通信（即使它们都在同一个有线局域网中），而同一区域内的主机之间可以正常通信，这就好像一个局域网一样，因此叫做虚拟局域网。 与传统局域网相比优点： 网络设备的移动、添加和修改的管理开销减少 可以控制广播活动 可以提高网络的安全性 完全隔离的两个VLAN如何通信？使用VLAN干线连接来建立虚拟局域网，每台交换机上的一个特殊接口被设置为干线接口，以互连VLAN交换机。该干线端口属于所有VLAN，发送到任何VLAN的帧经过干线链路转发到其他交换机。 交换机如何区别到达干线端口的帧属于哪个VLAN？IEEE 定义了一种扩展的以太网帧格式 802.1Q，它在标准以太网帧上加进了4字节首部VLAN标签，用于表示该帧属于哪一个虚拟局域网。 使用以太网进行网络接入以太网接入的一个重要特点是它可以提供双向的带宽通信，并且可以根据用户对带宽的需求灵活的进行带宽升级。 然而以太网帧格式标准中，在地址字段部分并没有用户名字段，也没有让用户键入密码来鉴别用户身份过程，于是人们想到将PPP协议再封装到以太网中来传输，就是1999年公布的PPPoE协议。因此，PPPoE协议是宽带上网的主机使用的链路层协议。","link":"/2020/03/07/%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/"},{"title":"网络层(一)","text":"主要内容 虚拟互联网络的概念 IP地址和物理地址的关系 传统的分类的IP地址（子网掩码）和无分类域间路由选择CIDR 网络层服务及虚拟互联网的概念因为网络层是整个互联网的核心，因此应当让网络层尽可能简单。 网络层向上只提供简单的、无连接的、尽最大努力交互(不可靠)的数据报服务。 无连接：IP并不需要事先建立连接或者维护任何关于后续数据报的状态信息。每个数据报的处理相互独立，并且可以不按发送顺序接收。 不可靠：它不能保证IP数据报能成功地到达目的地。IP仅提供最好的传输服务 所传送的分组可能出错、丢失、重复和失序，当然也不保证分组交付的时限。 使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络称为虚拟互联网络，由于使用的是IP协议也称为IP网。 与IP协议配套使用的还有三个协议： 地址解析协议 ARP (Address Resolution Protocol) 网际控制报文协议 ICMP (Internet Control Message Protocol) 网际组管理协议 IGMP (Internet Group Management Protocol) 逆地址解析协议(RARP) (DHCP协议(应用层协议)已经包含了RARP协议，所以RARP协议现在已经不使用了) IP地址和物理地址物理地址是数据链路层和物理层使用的地址，而IP地址（32位）是网络层和以上各层使用的地址，是一种逻辑地址。 下图为3个局域网用2个路由器R1和R2连接起来，现在主机H1要和主机H2进行通信。 通信路径为 H1-&gt;经过R1转发-&gt;经过R2转发-&gt;H2 其中路由器R1和R2同时连接在两个局域网上，因此有两个硬件地址 实际在不同层次中的不同区间的源地址和目的地址 我们可以知道： 在IP层抽象的互联网上只能看到IP数据报 路由器只根据目的IP地址进行路由选择 在局域网链路层只能看见MAC地址。 (从表中可以看到在从H1到H2通信过程中MAC帧首部的源地址和目的地址发生变化，在上面的IP层看不见这种变化) IP层抽象的互联网屏蔽了下层复杂细节，只要我们在网络层上讨论问题，就能够使用统一的、抽象的IP地址研究主机和主机或路由器之间的通信。 ARP协议网络层使用的是IP地址，最终在实际网络的链路上传送数据帧时，最终还是必须使用硬件地址。这就需要解决一个问题，如何根据一个机器的IP地址找出其对应的物理地址 地址解析协议ARP就是根据IP地址找出其对应的物理地址。 ARP工作过程： 当主机A要向本局域网上的某台主机B发送IP数据报，就先在其ARP高速缓存中查看有无主机B的IP地址。 如果ARP高速缓存中有该IP地址到MAC地址的映射，就在ARP高速缓存中查出其对应的硬件地址，再把硬件地址写入MAC帧中，然后通过局域网把该MAC地址发往此硬件地址。 如果没有，此时主机A就自动运行ARP。首先通过广播的方式发ARP请求分组，主机B收到该请求后会发送ARP响应分组给主机A告知其MAC地址。 主机A收到主机B的ARP响应分组后，向其高速缓存中写入主机B的IP地址到 MAC 地址的映射。 ARP协议抓包分析 ARP协议注意: ARP协议只在局域网中工作,如果要找的主机和源主机不在同一个局域网上(如上面的H1和H2)，H1就无法解析出另一个局域网H2主机。而是把路由器R1的IP地址解析为硬件地址HA3,以便能把IP数据报传送到路由器R1。 之后再由R1进行分组转发，直至最终交付给主机H2。 每个主机都有一个ARP高速缓存，里面有本局域网上的各主机和路由器的IP地址到MAC地址的映射表，并且这个映射表还可以动态更新。 IP地址划分IP地址就是给互联网上的每一台主机(或路由器)的每一个接口分配一个在全世界范围内唯一的32位的标识符。对IP地址的编址方式经历了三个历史阶段： 分类的IP地址 （最基本编址方法） 子网的划分 （对最基本编址方法的改进） 构成超网 （无分类编址，1993年提出后很快得到推广应用） 分类的IP地址由两部分组成，网络号和主机号。IP 地址 ::= {&lt; 网络号 &gt;, &lt; 主机号 &gt;} 这些32位的地址通常写成四个十进制的数，其中每个整数对应一个字节。这种表示方法称作“点分十进制表示法（Dotted decimal notation）”区分各类地址的最简单方法是看它的第一个十进制整数，如下图所示。 常用IP 子网的划分由三部分组成，网络号、子网号和主机号。IP地址 ::= {&lt;网络号&gt;, &lt;子网号&gt;, &lt;主机号&gt;} 为什么需要划分子网呢，因为上面的两级IP地址虽然方便，但却有很多缺点： IP地址空间的利用率有时很低 给每一个物理网络分配一个网络号会使路由表变得太大而使网络性能变坏 两级IP地址不够灵活 所以为了解决上面的问题，所以在分类IP地址中增加了一个子网字段，使得两级IP地址变为三级IP地址。这种方法叫做划分子网 划分子网的注意: 划分子网纯属一个单位内部的事情。单位对外仍然表现为一个网络。 划分子网的方法是从主机号借用若干个位作为子网号subnet-id，而主机号host-id也就相应减少了若干个位。 凡是从其他网络发送给本单位某个主机的IP数据报，仍然是根据 IP 数据报的目的网络号 net-id，先找到连接在本单位网络上的路由器。然后此路由器在收到 IP 数据报后，再按目的网络号 net-id 和子网号 subnet-id 找到目的子网(需要借助于子网掩码)。最后就将 IP 数据报直接交付目的主机。 无分类编址CIDR（构造超网）由网络前缀号和主机号组成。IP地址::= {&lt; 网络前缀号 &gt;, &lt; 主机号 &gt;} 无分类编址CIDR消除了传统 A类、B类和C类地址以及划分子网的概念，并且网络前缀的长度可以根据需要变化。 CIDR的记法上采用在IP地址后面加上网络前缀长度的方法，例如 128.14.35.7/20表示前20位为网络前缀。 CIDR的地址掩码可以继续称为子网掩码，子网掩码1的长度为网络前缀的长度。 一个组织通常被分配成一块连续的地址，即具有相同前缀的一段地址，这种情况下，该组织内部的设备的IP地址将共享共同的前缀。剩余的32-x比特用于区分该组织内部设备。 一个 CIDR地址块中有很多地址，一个CIDR表示的网络就可以表示原来的很多个网络，并且在路由表中只需要一个路由就可以代替原来的多个路由，减少了路由表项的数量。把这种通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为构成超网。 子网掩码上面使用子网的IP地址和无分类编址CIDR都提到了子网掩码，什么是子网掩码呢？它的作用是什么呢？我们举个例子就可以理解了 下图表示某单位拥有一个B类IP地址，网络地址是145.13.0.0（网络号是145.13） 现把上图中的网络划分为三个子网，这里假定子网号占用8位，因此主机号只剩8位。所划分的子网分别是：145.13.3.0 145.13.7.0、145.13.21.0 划分子网后，整个网络对外仍表现为一个网络，其网络地址仍为145.13.0.0，但是路由器R1在收到外来的数据报后，再根据数据报的目的地址把它转发到相应的子网。 假定有一个数据报的目的地址是145.13.3.10已经到达路由器R1，那么这个路由器如何把它转发到子网145.13.3.0呢？这就需要借助子网掩码（subnetmask）来实现了。 路由器会把子网掩码和收到的数据报地址的目的IP地址145.13.3.10进行按位“与”操作，得出所要找的子网的网络地址 可以看到，子网掩码与IP地址进行“与”操作之后，就将主机号“过滤”掉了，只剩下了网络号与子网号。 实际上，因特网的标准规定：所有网络必须使用子网掩码。即便一个网络没有划分子网，也要使用默认子网掩码。默认子网掩码中1的位置和IP地址中的网络号字段正好相对应，因此，两者进行“与”操作后，就能得出该IP地址的网络地址。 A类、B类、C类地址的默认子网掩码是固定的： 例，已知 IP 地址是141.14.72.24（注意是IP数据报中的目的地址），子网掩码是 255.255.192.0。试求子网网络地址。","link":"/2020/03/07/%E7%BD%91%E7%BB%9C%E5%B1%82/"},{"title":"Java常用类","text":"","link":"/2020/03/10/Java%E5%B8%B8%E7%94%A8%E7%B1%BB/"},{"title":"多线程开篇","text":"主要内容 程序、进程、线程、并行、并发、同步、异步、阻塞、非阻塞 创建线程的三种基本方式(线程池的方式后面再加) 基本概念程序、进程、线程 程序：是为完成特定任务，用某种语言编写的一组指令的集合，即指一段静态的代码，静态对象。 进程：是程序的一次执行过程，或是正在运行的一个程序，是一个动态的过程，有它自身的产生，存在和消亡的过程。 线程：进程可进一步细化为线程，是一个程序内部的一条执行路径 进程和线程的对比： 进程是资源分配的基本单位,而线程不拥有资源（也有一点儿必不可少的资源），但同一进程内多个线程共享进程内的资源 线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，则会引起进程切换。 创建或撤销进程时的开销远大于创建或撤销线程时的开销。(创建或撤销进程时，系统都要为之分配或回收资源) 线程不能单独执行，必须组成进程，一个进程至少有一个主线程。简而言之，一个程序至少有一个进程，一个进程至少有一个线程。 并行、并发 并行：一个时间点多个程序可以同时执行。(**多个人同时做多件事) 多核多CPU或多机器处理同一段处理逻辑的时候，同一时刻多个执行流共同执行 并发：一段时间内多个程序可以运行。一个CPU，通过CPU的调度算法，使用户感觉像是同时处理多个任务，但同一时刻只有一个执行流占用CPU执行。 同步、异步同步和异步强调的是消息通信机制。 同步:就是调用某个方法时，调用方得等待这个调用返回结果才能继续往后执行。 异步 ：调用方不会立即得到结果，而是在调用发出后继续执行后续操作，被调用者通过状态来通知调用者。 阻塞、非阻塞阻塞和非阻塞 强调的是程序在等待调用结果（消息，返回值）时的状态. 阻塞：调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。 非阻塞：指在不能立刻得到结果之前，该调用不会阻塞当前线程。 创建线程的三种基本方式创建线程的3中基本方式： 继承 Thread类 实现 Runnable接口 实现 Callable接口 继承Thread类继承Thread类，重写run方法 12345678public class MyThread extends Thread { @Override public void run() { for (int i = 0; i &lt; 100; i++) { System.out.println(); } }} 调用时直接使用线程的start()方法。 12345678910public class test { public static void main(String[] args) { //创建两个线程 MyThread t1 = new MyThread1(); MyThread t2 = new MyThread1(); //启动线程 t1.start(); t2.start(); }} 实现Runnable接口实现Runnable接口，实现run方法 12345678public class MyRunnable implements Runnable { @Override public void run() { for (int i = 0; i &lt;100 ; i++) { System.out.println(i); } }} 注意调用线程时，还是使用Thread的start()方法。 123456789101112public class test { public static void main(String[] args) { //创建实现Runnable接口的类对象 Runnable myRunnable = new MyRunnable(); //将接口类对象作为参数传递到Thread类创建线程 Thread t1 = new Thread(myRunnable); Thread t2 = new Thread(myRunnable); //启动线程 t1.start(); t2.start(); }} 实现Callable接口基于java.util.concurrent.Callable工具类的实现 123456public class MyCallable implements Callable { @Override public Object call() throws Exception { return 1; }} 12345678910111213141516171819public class test { public static void main(String[] args){ //创建实现Callable接口的类对象 Callable myCallable = new MyCallable(); //构建FutureTask对象 FutureTask&lt;Integer&gt; integerFutureTask = new FutureTask&lt;&gt;(myCallable); //创建线程 Thread t1 = new Thread(integerFutureTask); //启动线程 t1.start(); try { System.out.println(integerFutureTask.get()); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } }} 当然更常见的也是更加经常书写的是使用匿名内部类的方式或者lambda表达式的方式 匿名内部类 1234567891011121314151617181920212223public class test { public static void main(String[] args){ //实现Runnable接口方法 new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; 100; i++) { System.out.println(i); } } }).start(); //继承Thread类方法 new Thread(){ @Override public void run() { for (int i = 0; i &lt; 100; i++) { System.out.println(i); } } }.start(); }} 当然还可以使用Java8新特性lambda表达式的形式 123456789public class test { public static void main(String[] args){ new Thread(()-&gt;{ for (int i = 0; i &lt; 100; i++) { System.out.println(i); } }).start(); }} 注意事项实现接口 VS 继承 Thread 实现接口会更好一些，因为： Java 不支持多重继承，因此继承了 Thread 类就无法继承其它类，但是可以实现多个接口； 实现Runnable接口更适合用来处理多个线程共享数据的情况。 类可能只要求可执行就行，继承整个 Thread 类开销过大。 start()方法和run()方法 start()方法的作用：1.启动当前线程 2.调用当前线程的run()方法(在主线程中生成子线程，有两条线程) run()方法的作用：在主线程中调用后，只有主线程一条线程中执行了该线程方法。(调用线程run方法，只调用run方法，并不新开线程) Runnable接口和Callable接口 使用方法相似，只不过Callable接口功能更丰富些： call方法可以有泛型返回值(获取返回结果需要借助FutureTask类) call方法可以抛出异常 Runnable接口源代码 123public interface Runnable { public abstract void run();} Callable接口源代码 1234@FunctionalInterface //支持函数式接口public interface Callable&lt;V&gt; { V call() throws Exception;}","link":"/2020/03/10/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"title":"HTTP/1.1、HTTP2和HTTP3","text":"主要内容 HTTP/1.1和HTTP/1.0对比(长连接、短连接) HTTP/1.1和HTTP/2对比 HTTP/2和HTTP/3对比 HTTP1.1与HTTP/1.0对比 HTTP/1.1默认使用持久化连接(长连接)，而HTTP/1.0使用短连接。 管线化 客户端可以同时发出多个HTTP请求，而不用一个个等待响应 断点续传 实际上就是利用HTTP消息头使用分块传输编码，将实体主体分块传输。 长连接和短连接短连接就是：每请求一个资源都要重新进行一次HTTP连接。 比如我们请求一个网页，这个网页中包含html文档、js文件、css文件、图片等，对每个资源都进行一次HTTP连接。 短连接过程：建立连接——数据传输——关闭连接…建立连接——数据传输——关闭连接 长连接就是：建立一次连接，多次请求均由这个连接完成！ 只要客户端和服务器端任意一端没有明确提出断开TCP连接，就一直保持连接。 当然如果这个连接阻塞了，还是会开新的TCP连接的 长连接的过程：建立连接——数据传输…（保持连接）…数据传输——关闭连接 由于HTTP协议传输层是TCP协议，所以HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。 管线化长连接使管线化连接成为了可能，客户可以不等待响应，直接发送下一个请求，从而做到同时并行发送多个请求，节约时间。 HTTP/1.1、HTTP/2和HTTP/3的发展HTTP2和HTTP/1.1对比虽然上面提到了HTTP/1.1的很多优点，但是HTTP/1.1仍然存在着很多不足： 队头阻塞(Head of line blocking) HTTP/1.1通过管道技术实现一次性发送多个请求,但是这种技术在接收响应时，要求必须按照发送请求的顺序返回。如果，第一个请求被堵塞了，则后面的请求即使处理完毕了，也需要等待，这就是队头阻塞。 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分 发送冗长的首部。每次互相发送相同的首部造成的浪费较多 没有请求优先级控制 请求只能从客户端开始，服务器只能被动响应 针对上述问题HTTP/2对HTTP/1.1做了以下改进： 多路复用 HTTP/2 是可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。也就不会再出现「队头阻塞」问题，降低了延迟，大幅度提高了连接的利用率。 图片来自文章HTTP2和HTTPS不来了解下 二进制格式HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式。头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧和数据帧。 数据流HTTP2连接上传输的每个帧都关联到一个“流”。流是一个独立的，双向的帧序列可以通过一个HTTP2的连接在服务端与客户端之间不断的交换数据。此外，客户端还可以指定数据流的优先级。优先级高的请求，服务器就先响应该请求。 头部压缩HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你消除重复的分。这就是所谓的HPACK 算法 服务器推送HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以主动向客户端发送消息。 例如，在浏览器刚请求 HTML 的时候，就提前把可能会用到的 JS、CSS 文件等静态资源主动发给客户端，减少延时的等待，也就是服务器推送 HTTP/3和HTTP/2对比HTTP/2 主要的问题在于：多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。 所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。 HTTP/1.1 中的管道传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞住了 HTTP/2 多请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。 这都是基于 TCP 传输层的问题，所以HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！ UDP 发生是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的一个丢包全部重传问题。 大家都知道 UDP 是不可靠传输的，但基于 UDP 的QUIC 协议 可以实现类似 TCP 的可靠性传输。 QUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响。 TL3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack。 HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 TLS/1.3 的三次握手。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。","link":"/2020/03/10/HTTP-1-1%E3%80%81HTTP2%E5%92%8CHTTP3/"},{"title":"网络层(二)","text":"主要内容 IP数据报格式 IP层分组转发算法 路由选择协议 ICMP协议、ping、traceroute 路由器的功能就是进行分组转发和路由选择，路由器是如何在知道IP地址时进行分组转发或者路由选择呢？ 为此，我们需要先了解下IP数据报的格式。 IP数据报的格式 版本 : 有 4（IPv4）和 6（IPv6）两个值； 首部长度 : 占4位，因此最大值为15。值为1表示的是1个32位字的长度，也就是4字节（即单位是4个字节，最多表示60个字节）。因为IP首部固定部分长度为20字节，因此该值最小为5。如果可选字段的长度不是4字节的整数倍，就用尾部的填充部分来填充。最常用的首部长度是20字节，这时不适用任何选项。 区分服务 : 占8位，用来获得更好的服务，一般情况下不使用。 总长度 : 包括首部长度和数据部分长度。单位为字节。因此数据报最大长度为2^16-1=65535字节。但我们知道数据链路层中规定了数据帧中的数据字段的最大长度即最大传送单元MTU（通常为1500字节）。当数据报总长度超过MTU时，就必须把过长的数据报进行分片处理。在进行分片时，数据报首部中的总长度字段指分片后的每一个分片的首部长度与该分片的数据长度的总和。 标识 : 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。 标志 ： 占3位，但目前只有两位有意义。其中最低位记为MF。MF=1即表示后面还有分片的数据报，MF=0表示这是若干数据报中的最后一个。中间位记为DF，意思是不能分片，只有当DF=0时才允许分片。 片偏移 : 和标识符一起，用于发生分片的情况。表明较长的分组在分片后，某片在原分组中的相对位置，也就是说相对于用户数据字段的起点。片偏移的单位为8字节。 生存时间 ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL为0时就丢弃数据报。 协议 ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。 首部检验和 ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。 源地址：32位 目的地址：32位 分片： 分组转发算法使用分类IP的分组转发算使用分类的IP地址的转发，可以看到路由表中主要是以下两个信息： （目的网络地址， 下一跳地址） 以路由器R2的路由表为例，由于R2同时连接在网络2和3上，因此只要目的主机在网络2或3上，都可以通过接口0或1有路由器R2直接进行交付（当然还要利用地址解析协议ARP才能找到这些主机的硬件地址）。若目的主机在网络1中，则下一跳路由应为R1，其IP地址为20.0.0.7。路由器R1和R2由于同时连接在网络2上，因此从路由器R2把分组转发给路由器R1是很容易的。 使用分类IP的分组转发算法过程 从数据报的首部提取目的主机的 IP 地址 D, 得出目的网络地址为 N。 若网络 N 与此路由器直接相连，则把数据报直接交付目的主机 D；否则是间接交付，执行步骤3。 若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给路由表中所指明的下一跳路由器；否则，执行步骤4。 若路由表中有到达网络 N 的路由，则把数据报传送给路由表指明的下一跳路由器；否则，执行步骤5。 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；否则，执行步骤6。 报告转发分组出错。 上面步骤5中提到的默认路由对于连接在小网络上的主机发送IP数据报时是十分有用的。如下图中连接在网络N1上的任何一个主机中的路由表只需要三个项目即可。 本网络主机路由，其目的网络就是本网络N1,因而不需要路由转发。 到网络N2的路由，对应的下一条路由器是R2 默认路由，只要目的网络是其他网络(不是N1或N2),就一律选择默认路由，把数据报先交付路由器R1,让R1再转发给互联网中的下一个路由，一直转发到目的网络上的路由器，最后进行直接交付。 使用子网的分组转发算法在划分子网的情况下，分组转发算法必须做相应改动，路由表中必须包含以下三项内容:目的网络地址、子网掩码、下一跳地址 使用子网的分组转发算法 从收到的数据报的首部提取目的IP地址D。 先判断是否为直接交付。对路由器直接相连的网络逐个进行检查：用各网络的子网掩码和D逐位“与”，看结果是否和相应的网络地址匹配，若匹配，则把分组进行直接交付（当然还需要把D转换成物理地址，把数据报封装成帧发送出去），转发任务结束。否则是间接交付，执行步骤3。 若路由表中有目的地址为D的特定主机路由，则把数据报传送给路由表中所指明的下一跳路由。否则执行步骤4 对路由表中的每一行（目的网络地址、子网掩码、下一跳地址），用其中的子网掩码和D逐位相“与”，其结果为N。若N与该行的目的网络地址匹配，则把数据报传动给该行指明的下一跳路由。否则执行步骤5. 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；否则，执行步骤6。 报告转发分组出错。 比如对于上面的图中H1与主机H2之间进行通信，首先H1会将H2的IP地址128.30.33.128和本子网的网络地址128.30.33.0相与，得到128.30.33.0，与自己本子网的网络地址不同，则判断为间接交付，将数据报交付给路由器R1，由R1进行转发。 路由器收到数据报后，根据路由表中的记录，将IP地址与子网掩码进行逐位相与，如先看R1路由表的第一行。将子网掩码和目的IP逐位相与后得到128.30.33.128，与这一行的目的网路地址128.30.33.0比较不匹配。 则继续寻找下一行。 可以看到在第二行中匹配成功，则不再继续找下去而是R1把分组从接口1直接交付主机H2。 使用CIDR的分组转发算法在使用CIDR时，由于采用了网络前缀的这种方法，因此在路由表中的项目也要有相应改变。这时，每个项目由两个内容构成：网络前缀、下一跳地址 但是在查找时可能会得到不止一个匹配结果，此时应当采用最长前缀匹配来确定应该匹配哪一个。这是因为网络前缀越长，其地址块越小，因而路由选择就越具体。 具体转发流程和使用子网的分组转发方法类似，只不过中间是用掩码相与后，再使用最长前缀匹配进行选择，不在赘述。 比如，大学下属四系希望ISP把转发给四系的数据报直接发送到四系而不经过大学路由器，则在ISP路由器的路由表中至少有以下两个项目，即206.0.68.0/22(大学) 和206.0.71.128/25。假定目的IP地址为D=206.0.171.130,则按照下图进行掩码逐位与后都匹配，根据最长匹配前缀原理，应当选择后者。 注意： CIDR使用32位的地址掩码，其中1的长度为网络前缀的长度，例如/20的地址掩码为11111111 11111111 11110000 0000。 虽然CIDR不使用子网了，但是仍然可将地址掩码称为子网掩码。注意这个不使用子网的意思是说没有在32位地址中指明若干位作为子网字段，但分配到一个CIDR地址块后，仍然可以在本单位继续划分子网。 并且这些子网的网络前缀比整个单位网路的网络前缀长。 由于CIDR使用的是地址块，因此在路由表中可以直接利用CIDR地址块来查找目的网络，使得路由表中的一个项目可以表示原来传统分类地址的多个路由。这种路由聚合也称为构成超网 路由选择协议路由选择协议就是用来解决路由器中的路由表是如何获得的。 互联网采用的路由选择协议主要是自适应的(即动态的)，分布式路由选择协议。 互联网可以划分为许多较小的自治系统 AS，一个 AS 可以使用一种和别的 AS 不同的路由选择协议。在目前的互联网中，一个大的ISP就是一个自治系统。这样互联网就把路由选择协议划分为两大类： -内部网关协议IGP ： 即在一个自治系统内部使用的路由选择协议。主要有RIP 和 OSPF协议-外部网关协议EGP： 若源主机和目的主机处在不同的自治系统中，当数据报传送到一个自治系统边界时，就需要使用一种协议将路由选择信息传递到另一个自治系统中。这样的协议就是外部网关协议。主要有BGP协议。 内部网关协议 内部网关协议RIP RIP 是一种基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1。跳数最多为 15，超过 15 表示不可达。 RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。 距离向量算法： 对地址为 X 的相邻路由器发来的 RIP 报文，先修改报文中的所有项目，把下一跳字段中的地址改为 X，并把所有的距离字段加 1； 对修改后的 RIP 报文中的每一个项目，进行以下步骤： 若原来的路由表中没有目的网络 N，则把该项目添加到路由表中； 否则：若下一跳路由器地址是 X，则把收到的项目替换原来路由表中的项目；否则：若收到的项目中的距离 d 小于路由表中的距离，则进行更新（例如原始路由表项为 Net2, 5, P，新表项为 Net2, 4, X，则更新）；否则什么也不做。 若 3 分钟还没有收到相邻路由器的更新路由表，则把该相邻路由器标为不可达，即把距离置为 16。 RIP 协议实现简单，开销小。但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。 内部网关协议 OSPF 开放最短路径优先 OSPF，是为了克服 RIP 的缺点而开发出来的。 开放表示 OSPF 不受某一家厂商控制，而是公开发表的；最短路径优先表示使用了 Dijkstra 提出的最短路径算法 SPF。 OSPF 具有以下特点： 向本自治系统中的所有路由器发送信息，这种方法是洪泛法。 发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。 只有当链路状态发生变化时，路由器才会发送信息。 所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。 外部网关协议 BGPBGP（Border Gateway Protocol，边界网关协议） AS 之间的路由选择很困难，主要是由于： 互联网规模很大； 各个 AS 内部使用不同的路由选择协议，无法准确定义路径的度量； AS 之间的路由选择必须考虑有关的策略，比如有些 AS 不愿意让其它 AS 经过。 BGP 只能寻找一条比较好的路由，而不是最佳路由。 每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。 网际控制报文协议ICMPICMP协议是为了能够更有效地转发IP数据报和提高交付成功的机会。但ICMP不是高层协议(虽然ICMP数据报文作为IP层数据)，而是IP层协议。 ICMP报文： ICMP报文种类有两种： ICMP差错报告报文 ICMP询问报文 常见ICMP报文类型 ICMP差错报告报文具有相同的格式： 其中取需要进行差错报告的IP数据报数据字段前8个字节是为了得到运输层端口号(对于TCP和UDP)以及运输层报文的发送序号(对于TCP)。 ICMP常见的应用就是ping和traceroute ping ping是分组网间嗅探，用来测试两台主机的连通性。 ping是应用层直接使用网络层，没有经过传输层的TCP或UDP ping百度的抓包分析： 可以看到执行ping命令后，直接进行了4次request和reply。在下面的请求报文中可以看到和上面的ICMP报文格式一一对应。这里的 Type=8,code=0, 校验是正确，且这是一个Echo请求报文。我们再点击Responseframe:8，这里说明响应报文在序号8。详情如下： 同样的Type=8,code=0校验正确，且最下面根据请求和响应的时间戳计算出来的响应延迟。 tracerouteTraceroute是ICMP的另一个应用，用来跟踪一个分组从源点到终点的路径。traceroute是UNIX系统中的名字，在windows系统中是tracert。 traceroute发送的IP数据报封装的是无法交付的UDP用户数据报（使用了非法端口号），并由目的主机发送终点不可达差错报告报文。 源主机向目的主机发送一连串的IP数据报。第一个数据报P1的生存时间TTL设置为1，当P1到达路径上的第一个路由器R1时，R1收下它并把TTL减 1，此时TTL等于0，R1就把P1丢弃，并向源主机发送一个ICMP时间超过差错报告报文； 源主机接着发送第二个数据报P2，并把TTL设置为2。P2先到达 R1，R1收下后把TTL减 1 再转发给R2，R2收下后也把TTL减1，由于此时TTL等于0，R2就丢弃P2，并向源主机发送一个ICMP时间超过差错报文。 不断执行这样的步骤，直到最后一个数据报刚刚到达目的主机，主机不转发数据报，也不把TTL值减1。但是因为数据报封装的是无法交付的UDP，因此目的主机要向源主机发送ICMP终点不可达差错报告报文。 之后源主机知道了到达目的主机所经过的路由器IP地址以及到达每个路由器的往返时间。 UDP抓包(traceroute和tracert的不同)","link":"/2020/03/09/%E7%BD%91%E7%BB%9C%E5%B1%822/"},{"title":"深入理解JVM之类加载器","text":"主要内容 类加载机制概述 类加载的过程和时机 类加载器有几种 双亲委派机制 还是把这张图放上来，今天我们主要学习下类加载器和执行引擎。 类加载机制概述我们知道我们自己写的类讲过javac编译后成为.class文件，虚拟机通过类加载器把这些描述类的数据从Class文件加载到内存，之后对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。 类是在运行期间第一次使用时动态加载的，而不是一次性加载所有类。 类加载的过程和时机类的整个生命周期： 类的加载过程包括：加载、连接、初始化 1. 加载 加载是类加载的一个阶段，注意不要混淆。加载过程完成以下三件事： 通过类的完全限定名称获取定义该类的二进制字节流。 将该字节流表示的静态存储结构转换为方法区的运行时存储结构。 在内存中生成一个代表该类的 Class 对象，作为方法区中该类各种数据的访问入口。 2. 验证 确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 3. 准备 为类变量(static关键字修饰)在方法去中分配内存 设置类变量初值(通常为0值) 4. 解析 将常量池的符号引用替换为直接引用的过程。 5. 初始化 真正开始执行类中定义的Java字节码。即根据我们的代码去初始化类变量和其他资源 类加载器3+1类加载器的作用是： 通过类的完全限定名称获取定义该类的二进制字节流。(所以类加载器只作用于上述过程中的加载阶段) 由类加载器和这个类本身一同确立这个类在虚拟机中的唯一性。 对于类加载器我们需要明确： 只是将class文件加载到jvm虚拟机中，之后的验证、准备、解析、初始化不归它管。 将该字节流表示的静态存储结构转换为方法区的运行时存储结构。 在内存中生成一个代表该类的Class对象（hotspot虚拟机就是将该Class对象放到方法区中），作为方法区中该类各种数据的访问入口。 通过class文件开头的特定标识(CAFE BABE)确定是否是class文件 类加载器分类 类加载器分为两类： **虚拟机自带的类加载器** - 启动类加载器(BootStrapClassLoader) - 扩展类加载器(ExtClassLoader) - 应用程序类加载器(AppClassLoader) 用户自定义类加载器Java.lang.ClassLoader的子类，用户可以定制类的加载方式 类加载器如下图所示: 启动类加载器 启动类加载器是java的顶级类加载器，加载$JAVA_HOME/jre/lib下面的核心类库。这也是为什么我们装上jdk后，就可以直接使用Object类、String类和我们的ArrayList类等。比如下图就是jre/lib下面的rt.jar包中的Object.class。 我们试下看是不是BootStrap类加载器： 1234567public class MyObject { public static void main(String[] args) { Object object = new Object(); System.out.println(object.getClass().getClassLoader()); System.out.println(object.getClass().getClassLoader().getParent()); }} 运行结果如下图所示输出的是null，是因为BootStrap类加载器它本身是虚拟机的一部分，所以它并不是一个JAVA类，也就是无法在java代码中获取它的引用。所以BootStrap类加载器在程序中获得的是null。 123nullException in thread \"main\" java.lang.NullPointerException at com.company.MultiThread.MyObject.main(MyObject.java:10) 扩展类加载器 用于加载$JAVA_HOME/jre/ext下的类库。因为Java设计之初，不可能想到之后会用在哪些方面，应该提供哪些基本类，所以才会有这个扩展类加载器。主要加载下面这些包，加载完后是javax.xxx下面的类。 应用程序类加载器 AppClassLoader应用类加载器,又称为系统类加载器,它负责加载用户类路径（ClassPath）上所指定的类库，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。我们平时写的类都是通过这个类加载器加载的。 12345678910111213public class MyObject { public static void main(String[] args) {// Object object = new Object();// System.out.println(object.getClass().getClassLoader());// System.out.println(object.getClass().getClassLoader().getParent()); //这里和上面的区别在于这个MyObject类是我们自己定义的 MyObject myObject = new MyObject(); System.out.println(myObject.getClass().getClassLoader().getParent().getParent()); System.out.println(myObject.getClass().getClassLoader().getParent()); System.out.println(myObject.getClass().getClassLoader()); }} 从下面的结果中我们就能够看到，首先是BootStrapClassLoader、然后是ExtClassLoader，最后才是我们的AppClassLoader 123nullsun.misc.Launcher$ExtClassLoader@1b6d3586sun.misc.Launcher$AppClassLoader@18b4aac2 自定义类加载器 步骤： 继承ClassLoader 重写findClass()方法 调用defineClass()方法 这里就不写了,贴篇文章Java类加载机制及自定义加载器 双亲委派机制 当一个类收到了类加载请求，他首先不会尝试自己去加载这个类，而是把这个请求委派给父类去完成，每一个层次类加载器都是如此，因此所有的加载请求都应该传送到启动类加载其中，只有当父类加载器反馈自己无法完成这个请求的时候（在它的加载路径下没有找到所需加载的Class），子类加载器才会尝试自己去加载。 即加载流程为： 当AppClassLoader加载一个class时，它首先不会自己去尝试载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 如果BootStrapClassLoader加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class），会使用ExtClassLoader来尝试加载； 若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。 我们通过public abstract class ClassLoader下面的loadClass方法的源码来看下是否是上面所说的那样。 1234567891011121314151617181920212223242526272829303132333435363738394041protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { //首先检查这个class是否已经加载过了 Class&lt;?&gt; c = findLoadedClass(name); //如果类没有加载过 if (c == null) { long t0 = System.nanoTime(); try { //如果有父类的加载器则让父类的加载器加载 if (parent != null) { c = parent.loadClass(name, false); } else { //如果父类的加载器为null说明已经递归到了BootStrapClassLoader //BootStrapClassLoader无法通过get获取 c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { //如果BootStrapClassLoader仍然没有加载过，则会回来，尝试自己加载class // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } 我们写个小的demo验证下。比如我们就自己创建一个java.lang.String类 1234567package java.lang;public class String { public static void main(String[] args) { System.out.println(\"Hello\"); }} 运行结果如下图所示： 123错误: 在类 java.lang.String 中找不到 main 方法, 请将 main 方法定义为: public static void main(String[] args)否则 JavaFX 应用程序类必须扩展javafx.application.Application 可以看到程序报错，且提示我们在java.lang.String中找不到main方法，可是我们明明上面已经写了main方法。这就是因为双亲委派模型，加载String类时一直往上，找到BootStrapClassLoader后进行加载，原来java自定义的String类中一定不会有main方法，所以才会出现上述结果。 从上面的小demo中我们也就知道了双亲委派的作用： 双亲委派机制的作用 防止重复加载同一个.class。通过委托去向上面问一问，加载过了，就不用再加载一遍。保证数据安全。 保证核心.class不能被篡改。通过委托方式，不会去篡改核心.clas，即使篡改也不会去加载，即使加载也不会是同一个.class对象了。这样保证了Class执行安全。也称为沙箱安全机制","link":"/2020/03/15/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E4%B9%8B%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8/"},{"title":"HTTP(一)","text":"主要内容 HTTP协议概念和特点 HTTP状态码 HTTP请求方法 HTTP报文 URL和URI Cookie和Session HTTP概念和特点什么是HTTP呢？ HTTP (HyperText Transfer Protocol)是超文本传输协议，超文本指的是包含文字、图片、音频、视频的资源。 HTTP 协议是双向的。 HTTP 是一个在计算机世界里专门在两点之间传输数据的约定和规范 HTTP特点(针对http/1.1而言)： 参考文章硬核！30 张图解 HTTP 常见的面试题 优点 简单 HTTP 基本的报文格式就是header + body，头部信息也是 key-value 简单文本的形式，易于理解。 灵活和易于扩展 HTTP协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员自定义和扩充。 同时 HTTP 由于是工作在应用层（ OSI 第七层），则它下层可以随意变化。HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层，HTTP/3 甚至把 TCPP 层换成了基于 UDP 的 QUIC。 应用广泛和跨平台从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应用片地开花，同时天然具有跨平台的优越性。 缺点 HTTP 协议里有优缺点一体的双刃剑，分别是「无状态、明文传输」，同时还有一大缺点「不安全」。 无状态双刃剑 无状态的好处，因为服务器不会去记忆 HTTP 的状态，所以能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。 无状态的坏处，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。 对于无状态的问题，可以使用比较简单的方式用 Cookie技术解决。 明文传输双刃剑 明文传输的好处是在传输过程中的信息是可方便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。 明文传输的坏处在于HTTP 的所有信息毫无隐私可言，很容易就能被窃取 不安全 不安全是HTTP协议比较严重的缺点，可以使用 HTTPS 解决 HTTP状态码状态码用来描述客户端向服务器端发送请求时，服务端返回的请求结果。 1XX 1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。 2XX 一般是请求成功 200 OK 正常处理 204 No Content 成功处理，但服务器没有新数据返回，显示页面不更新 206 Partial Content 对服务器进行范围请求，只返回一部分数据 3XX 一般表示重定向 301 Moved Permanently 请求的资源已分配了新的URI中，URL地址改变了。【永久重定向】 302 Found 请求的资源临时分配了新的URI中，URL地址没变【转发】 303 See Other 与302相同的功能，但明确客户端应该采用GET方式来获取资源 304 Not Modified 发送了附带请求，但不符合条件【返回未过期的缓存数据】 307 Temporary Redirect 与302相同，但不会把POST请求变成GET 4XX 表示客户端出错了 400 Bad Request 请求报文语法错误了 401 Unauthrized 需要认证身份 403 Forbidden 没有权限访问 404 Not Found 服务器没有这个资源 5XX 服务器出错了 500 Internal Server Erro 内部资源出错了 503 Service Unavailable 服务器正忙 HTTP请求方法 我们比较常用的就是GET和POST了 GET和POST区别： GET方法时请求从服务器获取资源，而POST方法是向URI指定资源提交数据。 GET方法是安全且幂等的，而POST方法是不安全且不幂等的。 GET请求响应能被缓存，而POST请求响应不能缓存(一般也不缓存) GET请求参数以查询字符串出现在URL中，而POST请求参数存储在实体中。 对于第2点补充下安全和幂等的概念： 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。 那么很明显 GET方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。 POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。 HTTP报文HTTP报文可以分为报文首部、空行、报文主体两块。客户端的HTTP报文称为请求报文，服务器端的叫做响应报文。 对于请求报文主要包含：a、请求行：包含请求方法、URI、HTTP版本信息 (GET /HTTP/1.1)b、请求首部字段（请求头）c、空行d、请求内容实体 对于响应报文主要包含：a、响应行：包含HTTP版本、状态码、状态码的原因短语(HTTP/1.1 200 OK)b、响应首部字段（响应头）c、空行d、请求内容实体 下面是我们访问www.baidu.com的请求头和响应头。请求头： 响应头： 我们知道请求头和响应头一共包含四种首部字段，下面直接给出参数，以供以后查阅 请求首部字段 响应首部字段 通用首部字段 实体首部字段 URL和URIURI是统一资源标识符URL是统一资源定位符 对于URI和URL的理解，可以这样理解：对于网络中的所有资源，我们需要统一来对资源进行唯一标识 URI就是一种规定，说可以根据不同的协议来用不同的方式来表示资源的定位标识符。而URL和URN就是一种具体的实现。 URL就是通过网络资源的位置来唯一标识网络上的资源，URN就是通过编号来进行标识。 Cookie和SessionCookie Cookie是解决HTTP/1.1的无状态连接的 Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。 Cookie的用途 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） Cookie的创建和工作过程服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。 HTTP/1.0 200 OKContent-type: text/htmlSet-Cookie: yummy_cookie=chocoSet-Cookie: tasty_cookie=strawberry 客户端之后对同一个服务器发送请求时，会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器。 GET /sample_page.html HTTP/1.1Host: www.example.orgCookie: yummy_cookie=choco; tasty_cookie=strawberry SessionSession 可以用来将用户信息存储在服务器端，存储在服务器端的信息更加安全。 Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。 使用 Session 维护用户登录状态的过程如下 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中； 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID； 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中； 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后拿到 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。 应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。","link":"/2020/03/10/HTTP/"},{"title":"深入理解JVM之四大垃圾收集算法和七大垃圾收集器","text":"主要内容 判断对象是否存活 四大垃圾收集算法 七大垃圾收集器 上一节我们在介绍Java堆中简单提了下说Java堆是垃圾收集管理的主要区域，那么 如何判断Java堆内存中的对象是否是垃圾？(判断对象是否存活) 如果是垃圾，如何对垃圾进行收集？(四大垃圾收集算法) 收集时使用的垃圾收集器一共有几种？(七大垃圾收集器) 判断对象是否存活引用计数算法 为对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。 优点：实现简单、判定效率高 缺点：无法解决循环引用的问题。 demo 可达性分析算法 以一系列GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收。 Java 虚拟机使用该算法来判断对象是否可被回收，GC Roots 一般包含以下内容： 虚拟机栈中局部变量表中引用的对象 方法区中的常量引用的对象 方法区中类静态属性引用的对象 本地方法栈中 JNI 中引用的对象 下图中的Object4就处于可被回收状态 引用类型 上面两种算法中判定对象是否可被回收都与引用有关。Java 提供了四种强度不同的引用类型。下面四种类型的引用强度依次减弱 强引用 我们平时用的new 对象创建的就是一个强引用。被强引用关联的对象不会被回收。 12Object obj = new Object();obj = null //通过手动将将栈中obj置为null，就可以被回收 软引用 软引用用来描述一些有用但非必须的对象。被软引用关联的对象只有在内存不够的情况下才会被回收，如果这次回收内存仍然不够，则会出现OOM异常。这种特性常常被用来实现缓存技术 在 JDK1.2 之后，用java.lang.ref.SoftReference类来表示软引用。 123Object obj = new Object();SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj);obj = null; // 使对象只被软引用关联 弱引用 被弱引用关联的对象一定会被回收，也就是说弱引用只能存活到下一次垃圾回收发生之前。 使用 WeakReference 类来创建弱引用。 123Object obj = new Object();WeakReference&lt;Object&gt; wf = new WeakReference&lt;Object&gt;(obj);obj = null;// 使对象只被弱引用关联 虚引用 虚引用并不会决定对象的生命周期。在任何时候都可能被垃圾回收器回收。虚引用主要用来跟踪对象被垃圾回收器回收的活动。 123Object obj = new Object();PhantomReference&lt;Object&gt; pf = new PhantomReference&lt;Object&gt;(obj, null);obj = null; 四大垃圾收集算法1. 标记 - 清除算法 首先标记出所有需要回收的对象，在标记后统一回收所有被标记的对象。 回收对象就是把对象作为分块，连接到被称为 “空闲链表” 的单向链表，之后进行分配时只需要遍历这个空闲链表，就可以找到分块。 在分配时，程序会搜索空闲链表寻找空间大于等于新对象大小 size 的块 block。如果它找到的块等于 size，会直接返回这个分块；如果找到的块大于 size，会将块分割成大小为 size 与 (block - size) 的两部分，返回大小为 size 的分块，并把大小为 (block - size) 的块返回给空闲链表。 不足： 标记和清除过程效率都不高； 会产生大量不连续的内存碎片，导致无法给大对象分配内存。 2.复制算法 将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。 主要不足是只使用了内存的一半。 下面两段话注意，之后在说明这个垃圾回收过程中会用到。现在的商业虚拟机都采用复制算法回收新生代。经研究发现98%的对象都是“朝生夕死”的，所以并不需要划分为大小相等的两块，而是一块较大的 Eden 空间和两块较小的 Survivor 空间。在回收时，将 Eden 和 Survivor 中还存活着的对象全部复制到另一块 Survivor 上，最后清理 Eden 和使用过的那一块 Survivor。 HotSpot 虚拟机的 Eden 和 Survivor0 和 Survivor1大小比例默认为 8:1:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 就不够用了，此时需要依赖于老年代进行空间分配担保，也就是借用老年代的空间存储放不下的对象。 3. 标记 - 整理算法 与标记-清除算法类似，只不过不是直接对对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 4. 分代收集算法 现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。 一般将堆分为新生代和老年代。 新生代使用：复制算法 老年代使用：标记 - 清除 或者 标记 - 整理 算法 七大垃圾收集器上面我们介绍的是垃圾收集的算法，具体实现则是通过垃圾收集器来实现的。 以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。 单线程与多线程：单线程指的是垃圾收集器只使用一个线程，而多线程使用多个线程； 串行与并行：串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序；并行指的是垃圾收集器和用户程序同时执行。除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行。 这里我们重点关注CMS垃圾收集器和G1垃圾收集器，其他的简单了解即可。 Serial 收集器 单线程收集器、Client场景下默认新生代收集器 ParNew 收集器 Serial 收集器的多线程版本、 Server 场景下默认的新生代收集器 Parallel Scavenge 收集器 多线程收集器、“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户程序的时间占总时间的比值。 Serial Old 收集器 Serial 收集器的老年代版本、给 Client 场景下的虚拟机使用 Parallel Old 收集器 Parallel Scavenge 收集器的老年代版本。在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器 接下来重点解释下CMS收集器和G1收集器 CMS收集器 CMS收集器是一种以获得最短回收停顿时间为目标的收集器。 CMS收集器是基于标记-清除算法实现的。 收集器线程都可以与用户线程一起工作，不需要进行停顿 工作过程分为以下四个流程： 初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。 并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。 并发清除：不需要停顿。 在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。 缺点： 吞吐量低：低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。 无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。 标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。 G1收集器 我们知道堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。 G1 把堆划分成多个大小相等的独立区域（Region），新生代和老年代不再物理隔离。从而将原来的一整块内存空间划分成多个的小空间，使得每个小Region可以单独进行垃圾回收。 每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描 G1垃圾收集器的优点 并行与并发 通过并发方式让Java程序在垃圾收集时期继续执行 分代收集 虽然可以将新生代和老年代一同收集，但是分代的概念依然在G1中保留。仍然能够采用不同的方式去处理新创建的对象和已经存活一段时间的旧对象 空间整合 G1从整体来看是基于标记-整理算法，局部(两个Region间)是基于复制算法实现的。两种算法都意味着G1运行期间不会昌盛内存空间碎片 可预测停顿 能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。 如果不计算维护 Remembered Set 的操作，G1 收集器的 运作大致可划分为以下几个步骤： 初始标记 并发标记 最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。 筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。","link":"/2020/03/16/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E4%B9%8B%E5%9B%9B%E5%A4%A7%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%AE%97%E6%B3%95%E5%92%8C%E4%B8%83%E5%A4%A7%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/"},{"title":"深入理解JVM之运行时数据区域","text":"主要内容 JVM运行时数据区域 栈、堆、方法区的关系 还是把这张图放上来，今天我们主要学习下运行时的数据区域，也是JVM的核心 运行时数据区域本地方法栈 为本地方法服务。具体做法是Native Method Stack中登记native方法，在Execution Engine 执行时加载本地方法库。 会抛出StackOverflowError和OutOfMemoryError错误(Error) 这里提一下Native Interface本地方法接口，本地接口的作用是融合不同的编程语言为 Java 所用，它的初衷是融合 C/C++程序。比如我们在Thread类中的很多方法都是native方法。现在已经很少使用 程序计数器 一块较小的内存空间，可以看做是当前线程所执行的字节码的行号指示器。 字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环跳转、异常处理等功能都需要依赖这个计数器完成。 方法区 用于存储已经被虚拟机加载的类的结构信息(Class)、常量、静态常量、即时编译后的代码等数据。注意这里不包含实例变量，实例变量是存在堆内存中的 上面讲的是规范，在不同虚拟机中具体实现是不一样的，最典型的就是永久代和元空间。 从 JDK 1.8 开始，移除永久代，并把方法区移至元空间，它位于本地内存中，而不是虚拟机内存中。元空间存储类的元信息，静态变量和运行时常量池等放入堆中。 Java栈 栈中主要存储8种基本类型变量+引用类型变量+实例方法 每个 Java 方法在执行的同时会创建一个栈帧。栈帧用于存储局部变量表(基本类型+引用类型)、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。 栈的大小和具体JVM的实现有关，通常在256K~756K之间,约等于1Mb左右。 会抛出StackOverflowError和OutOfMemoryError错误(Error) 堆 几乎所有实例对象都在这里分配内存，是垃圾收集的主要区域（”GC 堆”）。 堆不需要连续内存，并且可以动态增加其内存，增加失败会抛出 OutOfMemoryError 异常。 栈、堆、方法区关系 HotSpot是使用指针的方式来访问对象： Java堆中会存放访问类元数据(类模板信息)的地址， reference存储的就直接是对象的地址","link":"/2020/03/15/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9F/"},{"title":"Java多线程之Thread类源码解析","text":"主要内容 Thread类常用API 线程的生命周期 中断interrupt 安全的停止一个线程 Thread类常用API 最常用的两个方法 12Thread.currentThread().getName() //得到当前线程名Thread.sleep(long mills) //线程睡眠 其他的建议看一下Thread类的注释和各个方法的源码，都挺简单的，直接上结论，就不贴图了。 线程能被标记为守护线程，也可以是用户线程setDaemon(boolean on) 每个线程均分配一个name，默认为（Thread-自增数字）的组合set和get方法 每个线程都有优先级.高优先级线程优先于低优先级线程执行. 1-10，默认为5set和get方法 main所在的线程组为main，构造线程的时候没有现实的指定线程组，线程组默认和父线程一样 当线程中的run()方法代码里面又创建了一个新的线程对象时,新创建的线程优先级和父线程优先级一样. 当且仅当父线程为守护线程时,新创建的线程才会是守护线程. 当JVM启动时,通常会有唯一的一个非守护线程(这一线程用于调用指定类的main()方法) 这里提一下守护线程 Daemon 守护线程是程序运行时在后台为其他线程提供服务的线程，不属于程序中不可或缺的部分。（比如JVM的垃圾回收线程就是守护线程） 当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。 main() 属于非守护线程。 在线程启动之前使用 setDaemon(boolean on) 方法可以将一个线程设置为守护线程。 123456789101112131415161718public class DaemonDemo { public static void main(String[] args) { Thread t1 = new Thread(()-&gt;{ try { //让main线程先执行 Thread.sleep(1000); System.out.println(\"t1 run\"); } catch (InterruptedException e) { e.printStackTrace(); } },\"t1\"); t1.setDaemon(true); t1.start(); System.out.println(\"main run\"); }} 运行结果只有main线程执行,说明main线程执行完后，已经没有非守护线程，这时程序终止，也就不会输出守护线程执行。 线程的生命周期在Thread类源码中的State枚举中有以下六种状态，下面我们分别解释下： 12345678public enum State { NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED; } 新建(NEW) 线程刚创建, 尚未启动 可运行(RUNNABLE) 正在 Java 虚拟机中运行。但是在操作系统层面，它可能处于运行状态，也可能等待资源调度（例如处理器资源），资源调度完成就进入运行状态。所以该状态的可运行是指可以被运行，具体有没有运行要看底层操作系统的资源调度。 阻塞(BLOCKED) 请求获取(监视器锁)从而进入synchronized 函数或者代码块，但是其它线程已经占用了该监视器锁，所以处于阻塞状态。要结束该状态进入从而RUNABLE需要其他线程释放监视器锁。 无限期等待(WAITING) 等待其它线程显式地唤醒。进入方法 | 退出方法:-: | :-:没有设置 Timeout 参数的 Object.wait() 方法 | Object.notify() / Object.notifyAll()没有设置 Timeout 参数的 Thread.join() 方法 | 被调用的线程执行完毕LockSupport.park() 方法 | LockSupport.unpark(Thread) 这里要区分 BLOCKED 和 WATING 的区别。阻塞是被动的，它是在等待获取 monitor lock。而等待是主动的，通过调用 Object.wait() 等方法进入。 限期等待(TIMED_WAITING) 无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。 进入方法 退出方法 Thread.sleep() 方法 时间结束 设置了 Timeout 参数的 Object.wait() 方法 时间结束 / Object.notify() / Object.notifyAll() 设置了 Timeout 参数的 Thread.join() 方法 时间结束 / 被调用的线程执行完毕 LockSupport.parkNanos() 方法 LockSupport.unpark(Thread) LockSupport.parkUntil() 方法 LockSupport.unpark(Thread) 调用 Thread.sleep() 方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。调用 Object.wait() 方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。 死亡(TERMINATED) 可以是线程结束任务之后自己结束，或者产生了异常而结束。 所以我们可以画出线程的转换的整个流程图: 注意：这里为了方便解释，将Runnable分成了可运行和运行中。 我们看一下上面用到的几个方法的源码 yield()方法 1public static native void yield(); 因为是native方法，无法看源码。但从注释中我们知道 给调度器一个提示，当前线程愿意让出自己的用的处理器，但是调度器也可以忽略。也就是说使用yield()方法不一定能让出处理器。 因为不一定能让出处理器，所以yield()方法很少使用 sleep()方法 sleep方法有个重载方法，可以设置纳秒数。但两个方法都是直接调用了下面的本地方法。 1public static native void sleep(long millis) throws InterruptedException; 注意：sleep方法会释放cpu的时间片，但是不会释放锁 join()方法 在线程中调用另一个线程的 join() 方法，会将当前线程挂起(底层调用的是Object的wait()方法)。 join方法一共有三个重载方法： 123456//不带时间，实际调用的是第2个方法，只不过参数设置为0public final void join() throws InterruptedException//带时间参数public final synchronized void join(long millis) throws InterruptedException//带时间参数，只不过可以设置纳秒值和2基本相同public final synchronized void join(long millis, int nanos) throws InterruptedException 所以我们看下的源代码： 12345678910111213141516171819202122232425public final synchronized void join(long millis) throws InterruptedException { long base = System.currentTimeMillis(); long now = 0; //如果等待时间&lt;0,则抛出异常 if (millis &lt; 0) { throw new IllegalArgumentException(\"timeout value is negative\"); } //如果等待时间=0,则一直等待，直到线程死亡 if (millis == 0) { while (isAlive()) { wait(0); } } else {//否则等待设定时间结束 while (isAlive()) { long delay = millis - now; if (delay &lt;= 0) { break; } wait(delay);//调用Object的wait方法,让当前线程等待 now = System.currentTimeMillis() - base; } } } demo 1234567891011121314151617181920212223public class T { private int sum; public void add(){ for (int i = 0; i &lt; 1000; i++) { sum++; } } public static void main(String[] args) { T t = new T(); Thread t1 = new Thread(()-&gt;t.add(),\"t1\"); t1.start(); try { t1.join(); } catch (InterruptedException e) { e.printStackTrace(); } //没有join方法让t1线程执行完的话，经常会出现0 System.out.println(t.sum); }} 中断关于中断，Thread类中一共有四个方法： 1234public void interrupt();public static boolean interrupted();public boolean isInterrupted();private native boolean isInterrupted(boolean ClearInterrupted); 接下来我们根据源码分析一下这几个方法。 interrupt()方法 通过调用一个线程的 interrupt() 来中断该线程，注意这里的中断不会真正停止一个线程，而仅仅是设置了一个中断标志(中断状态设为true)。 只能该线程自身调用，否则可能会抛出SecurityException异常。 如果该线程处于阻塞、限期等待或者无限期等待状态，调用interrupt()方法，中断状态会被清除(interrupt()方法会直接将其标记为true,但由于处于阻塞状态，会立即将true改为false即将中断状态清除)，并且抛出InterruptedException异常，从而提前结束该线程。 不能中断 I/O 阻塞和 synchronized 锁阻塞。 源码如下所示 123456789101112131415public void interrupt() { //检查是否有权限 if (this != Thread.currentThread()) checkAccess(); //IO阻塞 synchronized (blockerLock) { Interruptible b = blocker; if (b != null) { interrupt0(); //本地方法，设置中断标志 b.interrupt(this); return; } } interrupt0(); //本地方法，设置中断标志 } 使用中断方式终止处于阻塞、无限期等待、限期等待的状态 123456789101112131415161718192021222324252627public class InterruptDemo { public static void main(String[] args) { Thread t1 = new Thread(()-&gt;{ try { Thread.sleep(500); System.out.println(Thread.currentThread().getName()+\"run\"); } catch (InterruptedException e) { e.printStackTrace(); } },\"t1\"); t1.start(); //调用interrupt方法直接抛异常 t1.interrupt(); //让t1线程先执行 try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(t1.isInterrupted()); System.out.println(\"main run\"); }} 调用interrupt()方法直接终止上述状态，抛出InterruptException异常，同时抛出InterruptException异常后会将标志位置为false。 123456java.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at com.company.MultiThread.MyRunnable.run(MyRunnable.java:13) at java.lang.Thread.run(Thread.java:748)falsemain run interrupted()方法和isInterrupted()方法 interrupted()方法（静态方法） 检测中断并清除中断状态 注意interrupted()方法作用于当前线程而不是调用interrupted方法的线程 isInterrupted()方法 检测中断不清除中断状态 注意interrupted()方法作用于调用此方法的实例的线程 interrupted()方法调用的是带有boolean参数的本地isInterrupted(boolean ClearInterrupted)方法。 123public static boolean interrupted() { return currentThread().isInterrupted(true); } isInterrupted方法同样调用的是带有boolean参数的本地isInterrupted(boolean ClearInterrupted)方法。 1234//isInterrupted()public boolean isInterrupted() { return isInterrupted(false); } 12//isInterrupted(boolean ClearInterrupted)方法private native boolean isInterrupted(boolean ClearInterrupted); 测试这两个方法作用对象的就不写了，贴一篇文章好了Thread类中interrupt（）、interrupted（）和isInterrupted（）方法详解 其实很容易理解，因为interrupted调用时是使用静态方法调用，所以是作用于当前线程，而isInterrupted方法通过对象调用，所以作用于调用此方法的对象。 安全的终止一个线程对于一个线程，可以有暂停，恢复和终止操作，对应的就是Thread类中的suspend()、rusume()和stop()方法。但是看源码知道这些方法因为某些原因(容易死锁、不能正常释放资源等)已经不建议使用了。 对于线程的暂停和恢复，可以使用等待唤醒机制来替代(之后再补上链接) 对于线程的终止，我们有两种方法： 使用上面提到的中断 使用一个boolean变量显式的控制(推荐) 比如一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，如何中断一个线程。 使用中断的demo 12345678910111213public class InterruptDemo { public void m1(){ while(!Thread.currentThread().isInterrupted()){ System.out.println(Thread.currentThread().getName()+\"--run\"); } } public static void main(String[] args) { Thread t1 = new Thread(()-&gt;new InterruptDemo().m1(),\"t1\"); t1.start(); //不设置t1.interrupt()会一直循环，设置了之后直接跳出循环。 //t1.interrupt(); }} 使用boolean变量的demo 1234567891011121314151617181920212223public class FlagStop { //标志位flag private volatile boolean flag; public void m1(){ while(!flag){ System.out.println(\"死循环中\"); } System.out.println(\"跳出了循环\"); } public void setFlag(boolean flag) { this.flag = flag; } public static void main(String[] args) { FlagStop flagStop = new FlagStop(); new Thread(()-&gt;flagStop.m1(),\"t1\").start(); //不设置会一直死循环，设置后跳出死循环 //flagStop.setFlag(true); }}","link":"/2020/03/12/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8BThread%E7%B1%BB%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"title":"Java多线程之线程间通信","text":"主要内容 等待/通知机制 生产者、消费者模式 ThreadLocal 线程间通信包括： volatile和synchronized同步机制(见synchronized锁和显式Lock锁]) 等待/通知机制 生产者、消费者模式 Thread.join()的使用(见Thread类源码解析) ThreadLocal类 等待/通知机制还是把这张图放在这里，方便下面介绍 等待/通知机制使用的方法就是Object类上的wait()/notify()、notifyAll() 等待/通知机制最经典的范式就是生产者/消费者模式，但此模式在使用上还有点需要注意的，原理都是基于wait()/notify()的。 生产者/消费者模式注意： 使用wait()/notify() notifyAll()时要先调用对象加锁否则会报错IllegalMonitorStateException 使用while而不是if的原因是防止虚假唤醒。(以生产者为例，如果是if的话，可能多个线程在wait状态被唤醒后，其中一个线程生产完成，资源不为0，而这时候因为是if，剩余被唤醒的线程则会直接生产，造成超生。 同样，如果是消费者线程会造成超卖) 一定要使用notifyAll而不是notify。notify和notifyAll的区别是notify将等待队列中的一个线程移到同步队列，而notifyAll是将所有等待队列中的线程移到同步队列。比如生产者使用notify唤醒的仍然可能是生产者，这时候只有被唤醒的生产者线程，判断资源不为0则直接wait，导致程序无法继续往下运行。 synchronized方式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class Resource { private int number; public synchronized void increse(){ //1.判断 while(number!=0){ try { this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } //2.干活 number++; System.out.println(Thread.currentThread().getName()+\"--\"+number); //3. 通知 this.notifyAll(); } public synchronized void decrese(){ //1.判断 while(number == 0){ try { this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } //2.干活 number--; System.out.println(Thread.currentThread().getName()+\"--\"+number); //3. 通知 this.notifyAll(); } public static void main(String[] args) { Resource resource = new Resource(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { resource.increse(); } },\"t1\").start(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { resource.decrese(); } },\"t2\").start(); }} 显式Lock锁式 java.util.concurrent 类库中提供了 Condition类来实现线程之间的协调，可以在 Condition 上调用 await()方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.company.MultiThread;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class Resource { private int number; private Lock lock = new ReentrantLock(); Condition condition1 = lock.newCondition(); Condition condition2 = lock.newCondition(); public void increase() { lock.lock(); try { while(number!=0){ try { condition1.await(); } catch (InterruptedException e) { e.printStackTrace(); } } number++; System.out.println(Thread.currentThread().getName()+\"--\"+number); condition2.signalAll(); }finally { lock.unlock(); } } public void decrese(){ lock.lock(); try { while(number==0){ try { condition2.await(); } catch (InterruptedException e) { e.printStackTrace(); } } number--; System.out.println(Thread.currentThread().getName()+\"--\"+number); condition1.signalAll(); }finally { lock.unlock(); } } public static void main(String[] args) { Resource resource = new Resource(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { resource.increase(); } },\"t1\").start(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { resource.decrese(); } },\"t2\").start(); }} 上面的这个只是两个线程间进行通信，如果有多于2个线程，则可以通过设置标志位和多个condition对象进行准确控制 ThreadLocal类变量值之间共享，所有线程可以使用同一个public static变量。但是如果想每一个线程都有自己的局部变量，则需要用到ThreadLocal类。 ThreadLocal主要解决的就是每个线程绑定自己的变量，并且该变量对其他线程而言是隔离的。 可以通过set(T)方法来设置一个值，在当前线程下再通过get()方法获取到原先设置的值。 demo 12345678910111213141516171819202122232425262728293031323334353637383940import java.util.concurrent.TimeUnit;/** * Created by chen on 2020/3/20 */public class ThreadLocalDemo { //static volatile Person person = new Person(); private static ThreadLocal&lt;Person&gt; threadLocal = new ThreadLocal&lt;&gt;(); public static void main(String[] args) { //Person person = new Person(); new Thread(()-&gt;{ try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } //System.out.println(Thread.currentThread().getName()+\"--\"+person.name); System.out.println(Thread.currentThread().getName()+\"--\"+threadLocal.get()); },\"t1\").start(); new Thread(()-&gt;{ try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } threadLocal.set(new Person()); //person.name = \"t2Name\"; //System.out.println(Thread.currentThread().getName()+\"--\"+person.name); System.out.println(Thread.currentThread().getName()+\"--\"+threadLocal.get().name); },\"t2\").start(); }}class Person{ String name = \"haha\";} 从结果可以看到,我们之前使用共享变量person时线程t2修改值后，线程t1中得到的值是t2修改过的值。 而使用ThreadLocal是t2修改name后只在t2修改，相当于在t2线程中添加了一个person对象，而t1线程中没有添加person对象，所以为null 12345t2--t2Namet1--t2Name------------------t2--hahat1--null 想要更深入了解可以看下这两篇文章： https://www.jianshu.com/p/98b68c97df9b https://www.jianshu.com/p/3c5d7f09dfbd","link":"/2020/03/19/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"title":"深入理解JVM之Java堆垃圾回收过程","text":"主要内容 Java堆内存结构 Java堆内存回收过程 GC日志分析 这个本来想上篇文章写的，但是考虑到上篇文章篇幅过长，所以就重新开了一章，上篇文章可以说是我们理解Java垃圾回收过程需要的基本知识，这篇文章才是Java垃圾回收过程的核心。所以没看过上篇文章的可以先去看一下我的上一篇文章 四大垃圾收集算法和七大垃圾收集器 Java堆内存结构为了更清楚的了解Java堆内存垃圾回收过程，我们首先先看下Java堆内存结构。 Java堆内存结构在逻辑上分为新生区、老年区和永久区。其中永久区又分为Eden区、Survivor 0 区和Survivor 1区如下图所示： 对于上面这张图需要注意： Java堆逻辑上分为了新生区、老年区和永久区，但物理上只有新生区和老年区 Java8之后已经将原来的永久区更换为了元空间 Java堆内存回收过程1. 对象在新生代Eden区分配 大多数情况下，我们的对象都是优先分配的Eden区，大对象直接进入老年区。 大对象指的是需要大量连续内存空间的对象，最典型的大对象就是那种很长的字符串和数组。 JVM中通过参数-XX:PretenureSizeThreshold设定，大于这个值的对象为大对象，直接在老年代分配 2. 当Eden区满时，虚拟机发起一次Minor GC Minor GC是使用的复制算法，上篇文章中我们特意提到过这段话 HotSpot 虚拟机的 Eden 和 Survivor0 和 Survivor1大小比例默认为 8:1:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 就不够用了，此时需要依赖于老年代进行空间分配担保，也就是借用老年代的空间存储放不下的对象。 如下图所示，Java堆中新生代占了1/3空间，老年代占了2/3空间，并且新生代中Eden区：From区：To区是8:1:1 Minor GC的具体过程： 1. Eden、SurvivorFrom 复制到 SurvivorTo，年龄+1首先，当Eden区满的时候会触发第一次GC,把还活着的对象拷贝到Survivor From区，当Eden区又满时再次触发GC的时候会扫描Eden区和From区域,对这两个区域进行垃圾回收，经过这次回收后还存活的对象,则直接复制到To区域（如果有对象的年龄已经达到了老年的标准，则赋值到老年代区），同时把这些对象的年龄+1 这里注意： 经研究98%的对象都是朝生夕灭的，也就是说，基本上第一次GC就能把大部分垃圾进行回收。即大部分对象基本只在Eden区就被回收。 如果扫描Eden区和Survivor From区后有多于 10% 的对象存活，那么一块 Survivor To就不够用了，此时需要借用老年代的空间存储放不下的对象 2. 清空 Eden、SurvivorFrom 然后，清空Eden和Survivor From中的对象 3. SurvivorTo和SurvivorFrom互换最后，Survivor To和Survivor From互换，原SurvivorTo成为下一次GC时的SurvivorFrom区。部分对象会在From和To区域中复制来复制去,如此交换15次(由JVM参数MaxTenuringThreshold决定,这个参数默认是15),最终如果还是存活,就存入到老年代 3. 长期存活的对象进入老年代 从上面的了解中我们知道，进入老年代的对象有： 大对象直接进入老年代 Eden区和Survivor From区Minor GC后有多于 10% 的对象存活需要空间分配担保。 存活年龄超过15的进入到老年代(动态年龄判定:并不一定要超过15，只要Survivor中相同年龄所有对象大小总和大于Survivor一般空间，就直接进入老年代) 4. 老年代进行Full GC 触发条件： 老年代空间不足 Minor GC后进入老年代的平均大小大于老年代的可用内存。 Eden区和Survivor From区Minor GC后有多于 10% 的对象存活需要移动到老年代，且老年代可用内存不足。 调用System.gc()时系统建议执行Full GC，但是不一定执行 5. OOM heap Space异常 当老年代进行Full GC后，空间仍然不足，则抛出OOM异常。 上面的整个过程，可以简略的用下图表示：注意：Java8之后已经变成了元空间，而且元空间使用的是本机的物理内存。 Minor GC和Full GC的区别 Minor GC: 回收新生代，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。 Full GC: GC日志分析首先，我们需要先了解下几个参数 Xms : 设置堆初始分配大小，默认为物理内存的1/64 Xmx: 堆最大分配内存，默认为物理内存的1/4 -XX:+PrintGCDetails : 输出详细的GC处理日志 为了产生GC过程，我们可以首先通过下面的Java程序，看下自己电脑默认的堆内存大小和最大堆内存。 123456789101112public class test { public static void main(String[] args){ //返回Java虚拟机堆能使用的最大内存量 Long maxMemory = Runtime.getRuntime().maxMemory(); //返回Java虚拟机中堆初始内存总量 long totalMemory = Runtime.getRuntime().totalMemory(); //格式化输出 System.out.println(\"MAX_MEMORY = \" + maxMemory+ \"字节\" + (maxMemory/1024/1024)+\"MB\"); System.out.println(\"TOTAL_MEMORY = \" + totalMemory+ \"字节\" + (totalMemory/1024/1024)+\"MB\"); }} 我的电脑内存为8G，可以得到如下数据,可以看到最大内存量约为8G的1/4，堆内存大小约为8G的1/64。 12MAX_MEMORY = 1883242496字节1796MBTOTAL_MEMORY = 128974848字节123MB 我们在IDEA的VM option下(或者在命令行下)设置VM参数-Xms1024m -Xmx1024m -XX:+PrintGCDetails将JVM初始堆内存和最大堆内存均设置为1024M,并打印GC日志。再次运行刚才的程序得到下图 可以看到和上一次相比，我们的JVM参数将初始堆内存和最大堆内存变为了981M(981.5M)，约为1024M。 并且，我们可以验证Java堆逻辑上分为新生代、养老代和元空间，实际上只有新生代和养老代(305664/1024+699392/1024=981.5M)。 接下来我们设置-Xms10m -Xmx10m -XX:+PrintGCDetails为10M，并通过下面的程序，在新生代中不断new对象，以查看GC日志 12345678public class test { public static void main(String[] args){ String str = \"Hello World\"; while(true){ str += str; } }} 输出入下图，可以看到经过GC和Full GC后最终产生了java.lang.OutOfMemoryError: Java heap space异常。 GC日志 贴一下我们上面运行的GC日志 1[GC (Allocation Failure) [PSYoungGen: 1965K-&gt;488K(2560K)] 1965K-&gt;768K(9728K), 0.0011237 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 参照下图就可以知道具体含义 Full GC日志 这里贴一下产生OOM前最后一次的Full GC日志 1[Full GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] [ParOldGen: 4825K-&gt;4803K(7168K)] 4825K-&gt;4803K(9728K), [Metaspace: 3189K-&gt;3189K(1056768K)], 0.0057874 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 这里注意下已经从永久区变成了元空间，其他没变 Full GC日志规律：","link":"/2020/03/16/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E4%B9%8BJava%E5%A0%86%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E8%BF%87%E7%A8%8B/"},{"title":"Java多线程之CAS和AQS源码解析","text":"主要内容 CAS思想 AQS实现锁 AQS源码分析 本来这篇文章是打算讲下Lock的子类实现的，但是Lock的子类实现都是基于AQS(AbstractQueuedSynchronizer)的，而AQS中很多地方用到了CAS操作来提高并发效率。所以这篇文章直接撸这两个东东。 CAS什么是CAS CAS(Compare And Swap)：比较并交换，它是实现多线程同步的原子指令。它将主内存内容和给定值进行比较，只有在相同的情况下，才将该内存位置的内容修改为给定值。如果该值在同一时间被另一个线程更新，则写入失败。 操作结果必须说明是否进行替换， 这可以通过一个简单的布尔变量，或通过返回从内存位置读取的值来完成。 CAS在Java中的应用 JAVA1.5开始引入了CAS，主要代码都放在J.U.C的atomic包下 我们以AtomicInteger的getAndIncrement为例，看下它的底层源码，其他的方法和这个方法底层是类似的。了解了这个，其他的方法也就了解了。 我们从源码中可以看到getAndIncrement的底层中调用了unsafe.getAndAddInt()方法。我们从AtomicInteger上面的源码可以看到unsafe是Unsafe类的一个对象。 Unsafe类是位于sun.misc包中,其内部方法(都是native修饰的方法,就不贴图了)操作可以像C指针一样，直接操作内存。 知道了Unsafe类，我们回过头来再看下getAndIncrement方法，它实际上是调用了Unsafe类中的getAndAddInt方法，并且传递了三个参数： this 就是当前类的对象 valueOffset 变量的内存偏移地址 1 就是我们每次+1操作的1 在getAndAddInt中var1 var2 var4对应于上面传递过来的三个参数 通过本地方法getIntVolatile通过当前对象(var1)和对象中变量的内存偏移(var2)得到我们的变量值。(将主内存变量拷贝到工作内存) 进行do-while循环判断。 判断条件中通过compareAndSwapInt进行原子更新操作，将主内存变量和工作内存变量var5进行比较，相同则执行+1操作，并写入主内存，跳出循环。不同则comepareAndSwapInt方法返回false，重新进行循环操作。 注意：上面只是为了解释方便分了1.2.3步，实际上整个过程是原子操作的，即不允许被中断。 这时候我们也就理解了为什么可以用AtomicInteger可以解决volatile的原子性问题。因为AtomicInteger和volatile相比多了比较的步骤，即CAS CAS的ABA问题 CAS有很多优点，比如： 和synchronized相比较，CAS并没有进行加锁，所以并发性得到提高 和volatile相比，则是保证了原子性 但是CAS同时也存在一些缺点: 循环时间长，开销大。(因为如果CAS失败，会一直进行do-while循环，长时间不成功，会给CPU带来很大的开销)。 只能保证一个变量的原子操作。(对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候只能用锁来保证原子性) ABA问题 什么是ABA问题 线程1从内存X中取出A，这时候另一个线程2也从内存X中取出A，并且线程2进行了一些操作将内存X中的值变成了B，然后线程2又将内存X中的数据变成A，这时候线程1进行CAS操作发现内存X中仍然是A，然后线程1操作成功。虽然线程1的CAS操作成功，但是整个过程就是有问题的。比如链表的头在变化了两次后恢复了原值，但是不代表链表就没有变化。 下面的代码中演示了ABA问题，可以看到线程t1将100变为101后又变回100发生ABA问题。而线程t2仍然比较成功，并重新设置为了102. 123456789101112131415161718192021222324252627282930package com.company.MultiThread;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicReference;public class ABADemo { private AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;&gt;(100); public static void main(String[] args) { ABADemo abaDemo = new ABADemo(); new Thread(()-&gt;{ //ABA t1 100--&gt;101--&gt;100 abaDemo.atomicReference.compareAndSet(100,101); abaDemo.atomicReference.compareAndSet(101,100); },\"t1\").start(); new Thread(()-&gt;{ //睡2秒钟，保证线程1发生ABA问题 try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(abaDemo.atomicReference.compareAndSet(100,102) +\"----\"+abaDemo.atomicReference.get()); },\"t2\").start(); }} ABA之后线程t2仍然比较成功，并重新设置为了102。 1true----102 ABA问题的解决JAVA中提供了AtomicStampedReference/AtomicMarkableReference来处理会发生ABA问题的场景，主要思路就是在对象中额外再增加一个标记来标识对象是否有过变更。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.company.MultiThread;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicStampedReference;/** * Created by chen on 2020/3/22 */public class ABADemo { private AtomicStampedReference&lt;Integer&gt; atomicStampedReference= new AtomicStampedReference&lt;&gt;(100,1); //1为标记号 public static void main(String[] args) { ABADemo abaDemo = new ABADemo(); new Thread(()-&gt;{ int stamp = abaDemo.atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName()+\"第一次版本号为\"+stamp); //暂停1秒钟让t2线程拿到第一次版本号 try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } //ABA t1 100--&gt;101--&gt;100 // t1版本号 1 2 3 abaDemo.atomicStampedReference.compareAndSet(100,101, abaDemo.atomicStampedReference.getStamp(),abaDemo.atomicStampedReference.getStamp()+1); System.out.println(Thread.currentThread().getName()+\"第二次版本号为\"+abaDemo.atomicStampedReference.getStamp()); abaDemo.atomicStampedReference.compareAndSet(101,100, abaDemo.atomicStampedReference.getStamp(),abaDemo.atomicStampedReference.getStamp()+1); System.out.println(Thread.currentThread().getName()+\"第三次版本号为\"+abaDemo.atomicStampedReference.getStamp()); },\"t1\").start(); new Thread(()-&gt;{ int stamp = abaDemo.atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName()+\"第一次版本号为\"+stamp); //睡3秒钟，保证线程1发生ABA问题 try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); } boolean flag = abaDemo.atomicStampedReference.compareAndSet(100,102, stamp,stamp+1); int stamp2 = abaDemo.atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName()+\"是否修改成功:\"+flag+\"当前实际版本号为\"+stamp2+\"实际变量值为\"+ abaDemo.atomicStampedReference.getReference()); },\"t2\").start(); }} 12345t1第一次版本号为1t2第一次版本号为1t1第二次版本号为2t1第三次版本号为3t2是否修改成功:false当前实际版本号为3实际变量值为100 AQS讲完了CAS我们再来看下这篇文章的主角AQS，之所以先讲CAS就是因为AQS中用到了CAS。 1. 什么是AQS AQS是位于J.U.C包中的locks子包下面的抽象类AbstractQueuedSynchronizer的简写，顾名思义就是一个抽象的队列同步器。 我们看下它的API文档和注释就可以知道它的作用： 提供了一个框架来实现锁和相关的同步器。如常用的ReentrantLock和同步器Semaphore/CountDownLatch等。 核心是维护了一个state（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列） 支持两种线程模式独占模式和共享模式。在不同模式中的等待线程共享FIFO队列。通常子类实现只支持一种模式，但是ReadWriteLock支持两种模式。子类实现只需要重写对应模式的方法即可，具体线程等待队列的维护AQS已经帮我们实现好了。 定义了一个内部类ConditionObject用来支持独占模式的子类实现Conditon 2. 如何使用AQS 上面我们从源码注释中知道了AQS是一个框架来实现锁和相关的同步器。那怎么使用AQS来实现一把锁呢？ 我们先把实现锁的方法提一下，然后直接看下注释中的独占锁是怎么实现的。 锁和同步器的设计是基于模板方法模式的。我们需要继承同步器并重写相应模式的指定方法，然后将同步器组合在自定义同步组件的实现中，并调用同步器的模板方法，而这些模板方法将会调用我们重写的方法。 重写同步器的指定方法时，需要使用同步器提供的三个方法来访问或修改同步状态： getState() 获取当前同步状态 setState(int newState) 设置当前同步状态 compareAndSetState(int expect,int update) 使用CAS设置当前状态，该方法能够保证状态设置的原子性。 需要重写的方法主要包括： 方法名称 描述 tryAcquire(int) 独占方式。尝试获取资源，成功则返回true，失败则返回false。实现该方法需要查询当前状态并判断同步状态是否符合预期，然后再进行CAS设置同步状态 tryRelease(int) 独占方式。尝试释放资源，成功则返回true，失败则返回false。 等待获取同步状态的线程将有机会获取同步状态 tryAcquireShared(int) 共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int) 共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 isHeldExclusively() 该线程是否正在独占资源。只有用到condition才需要去实现它。 下面是Java注释中提供的一个不可重入的互斥锁的实现。代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041class Mutex implements Lock, java.io.Serializable { // 静态内部类，自定义同步器 private static class Sync extends AbstractQueuedSynchronizer { // 判断是否处于锁定状态 protected boolean isHeldExclusively() { return getState() == 1; } // 当状态为0的时候尝试获取锁 public boolean tryAcquire(int acquires) { assert acquires == 1; //如果传进来的不是1就不执行下面的代码，是1则继续执行 if (compareAndSetState(0, 1)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } // 尝试释放锁，将状态设置为0 protected boolean tryRelease(int releases) { assert releases == 1; // Otherwise unused if (getState() == 0) //既然来释放肯定是已经占有状态，这里只是为了保险，多层判断 throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); //释放资源，放弃占有状态 return true; } //只需要将操作代理到内部类Sync上，其余困难的操作AQS已经帮我们实现好了 private final Sync sync = new Sync(); //lock&lt;--&gt;acquire。两者语义一样：获取资源，即便等待，直到成功才返回。 public void lock() { sync.acquire(1); } //tryLock&lt;--&gt;tryAcquire。两者语义一样：尝试获取资源，要求立即返回。 public boolean tryLock() { return sync.tryAcquire(1); } //unlock&lt;--&gt;release。两者语文一样：释放资源。 public void unlock() { sync.release(1); } //判断是否占有锁 public boolean isLocked() { return sync.isHeldExclusively(); } }} 3.AQS底层源码解析 3.0Node结点 这里我们说下Node。Node结点是对每一个等待获取资源的线程的封装，其包含了需要同步的线程本身(thread)和其等待状态(waitStatus)以及前驱和后继节点 我们看下Node节点中都定义了些什么东东： 注意: 负值表示结点处于有效等待状态，而正值表示结点已被取消。所以源码中很多地方用&gt;0、&lt;0来判断结点的状态是否正常。 nextWaiter 是等待在conditon上的线程所构成的等待队列中的后继节点。 如果当前节点共享，将会是一个SHARED常量。 下面的这幅图中更加详细的描述了AQS的FIFO队列 3.1独占式同步状态获取 acquire(int) 此方法是独占模式下线程获取共享资源的顶层入口。如果获取到资源，线程直接返回，否则进入等待队列，直到获取到资源为止，且整个过程忽略中断的影响。这也正是lock()的语义，当然不仅仅只限于lock()。获取到资源后，线程就可以去执行其临界区代码了。我们看下acquire方法的源码 12345public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} 可以看到上面的acquire方法中调用了tryAcquire()、addWaiter()、acquireQueued()以及selfInterrupt()方法，接下来我们一一看看这些方法。 3.1.1tryAcquire()方法 此方法尝试去获取独占资源。如果获取成功，则直接返回true，否则直接返回false。源码如下： 123protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException();} 还记得我们上面实现自定义锁要重写的方法和java给我们的注释中Mutex锁的实现吗？ 这个tryAcquire()方法，就是我们**实现自定义独占锁需要重写的方法**。 3.1.2addWaiter()方法 此方法用于将当前线程加入到等待队列的队尾，并返回当前线程所在的结点。 1234567891011121314151617181920private Node addWaiter(Node mode) { //以给定模式构造节点。mode有两种：EXCLUSIVE（独占）和SHARED（共享） Node node = new Node(Thread.currentThread(), mode); //快速尝试在尾部添加 Node pred = tail; //如果队列不为空，则用CAS方式将当前节点设为尾结点 if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } //代码执行到这里，只有两种情况 //1. 队列为空 //2. CAS失败 // 注意, 这里是并发条件下, 所以什么都有可能发生, 尤其注意CAS失败后也会来到这里 enq(node); //将节点插入队列 return node; } 在这个方法中，我们首先会尝试直接入队，但是因为目前是在并发条件下，所以有可能同一时刻，有多个线程都在尝试入队，导致compareAndSetTail(pred, node)操作失败——因为有可能其他线程已经成为了新的尾节点，导致尾节点不再是我们之前看到的那个pred了。 如果入队失败了，接下来我们就需要调用enq(node)方法，在该方法中我们将通过自旋+CAS的方式，确保当前节点入队。enq方法的源码： 1234567891011121314151617181920private Node enq(final Node node) { //CAS\"自旋\"，直到成功加入队尾 for (;;) { Node t = tail; // 队列为空，首先进行初始化(可以看出队列是延迟加载的，只有用到的时候再加载，而不是在构造的时候直接初始化) //创建一个空的节点作为head节点，并将tail也指向它。 if (t == null) { //注意，初始化时使用new Node()新建了一个dummy节点 if (compareAndSetHead(new Node())) tail = head; //将尾节点指向dummy节点 } else { //队列不为空，正常入队列 node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 这里尤其要注意的是，当队列为空时，我们初始化队列并没有使用当前传进来的节点，而是：新建了一个空节点！！！ 在新建完空的头节点之后，我们并没有立即返回，而是将尾节点指向当前的头节点，然后进入下一轮循环。在下一轮循环中，尾节点已经不为null了，此时再将我们包装了当前线程的Node加到这个空节点后面。这就意味着，在这个等待队列中，头结点是一个“dummy节点”，它不代表任何等待的线程。head节点不代表任何线程，它就是一个空节点！！！ 尾分叉继续往下分析 12345678} else {// 到这里说明队列已经不是空的了, 这个时候再继续尝试将节点加到队尾 node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; }} 这里将node节点添加到队列中需要三步： 设置node的前驱节点为当前的尾节点：node.prev = t 修改tail属性，使它指向当前节点 compareAndSetTail(t, node) 修改原来的尾节点，使它的next指向当前节点 t.next = node 但是需要注意的，这里的三步并不是一个原子操作，第一步很容易成功；而第二步由于是一个CAS操作，在并发条件下有可能失败，第三步只有在第二步成功的条件下才执行。这里的CAS保证了同一时刻只有一个节点能成为尾节点，其他节点将失败，失败后将回到for循环中继续重试。 所以，当有大量的线程在同时入队的时候，同一时刻，只有一个线程能完整地完成这三步，而其他线程只能完成第一步，于是就出现了尾分叉： 注意，这里第三步是在第二步执行成功后才执行的，这就意味着，有可能即使我们已经完成了第二步，将新的节点设置成了尾节点，此时原来旧的尾节点的next值可能还是null(因为还没有来的及执行第三步)，所以如果此时有线程恰巧从头节点开始向后遍历整个链表，则它是遍历不到新加进来的尾节点的，但是这显然是不合理的，因为现在的tail已经指向了新的尾节点。 另一方面，当我们完成了第二步之后，第一步一定是完成了的，所以如果我们从尾节点开始向前遍历，已经可以遍历到所有的节点。这也就是为什么我们在AQS相关的源码中，有时候常常会出现从尾节点开始逆向遍历链表——因为一个节点要能入队，则它的prev属性一定是有值的，但是它的next属性可能暂时还没有值。 至于那些“分叉”的入队失败的其他节点，在下一轮的循环中，它们的prev属性会重新指向新的尾节点，继续尝试新的CAS操作，最终，所有节点都会通过自旋不断的尝试入队，直到成功为止。 3.1.3acquireQueued()方法 首先看这个方法前，需要先明确几个概念 能执行到该方法, 说明addWaiter 方法已经成功将包装了当前Thread的节点添加到了等待队列的队尾 该方法中将再次尝试去获取锁 在再次尝试获取锁失败后, 判断是否需要把当前线程挂起 acquireQueued的源码如下： 123456789101112131415161718192021222324252627final boolean acquireQueued(final Node node, int arg) { boolean failed = true; //没有拿到资源 try { boolean interrupted = false; //没有被中断过 //CAS自旋 for (;;) { //拿到node节点(因为上面入队，所以此时node节点是尾结点)的前驱节点 final Node p = node.predecessor(); //如果前驱节点是头结点则再次尝试获取同步状态 if (p == head &amp;&amp; tryAcquire(arg)) { //获取成功，则将当前节点设置为头结点(上面已经拿到同步状态，所以不需要进行CAS，普通的set方法即可) setHead(node); p.next = null; //GC failed = false; //标记成功获取资源 return interrupted; //返回等待过程中是否被中断 } //node的前驱节点不是头结点或者获取资源失败 判断是否需要使当前线程挂起(进入WAITING状态) if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { //如果等待过程中没有成功获取资源（如timeout，或者可中断的情况下被中断了），那么取消结点在队列中的等待。 if (failed) cancelAcquire(node); } } 这里我们要注意setHead这个方法 12345private void setHead(Node node) { head = node; node.thread = null; node.prev = null;} 可以看出，这个方法的实际上是丢弃原来的head，将head指向已经获得了锁的node。但是接着又将该node的thread属性置为null了，这某种意义上导致了这个新的head节点又成为了一个dummy节点。某种程度上就是将当前线程从等待队列里面拿出来了，是一个变相的出队操作。 接下来我们再来看看另一种情况，即p == head &amp;&amp; tryAcquire(arg)返回了false，此时我们需要判断是否需要将当前线程挂起： 先看看shouldParkAfterFailedAcquire()和parkAndCheckInterrupt()具体干些什么。 shouldParkAfterFailedAcquire从函数名也可以看出, 该方法用于决定在获取锁失败后, 是否将线程挂起.决定的依据就是前驱节点的waitStatus值。 12345678910111213141516171819202122232425private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; //拿到前驱节点的状态 if (ws == Node.SIGNAL) /* * 如果前驱节点状态为SIGNAL,则表示后继节点即node节点处于WAITING状态 * 这就好比排队时，你告诉前面的人我先去那边歇会，等你进去了release或者不相等了cancel，麻烦你叫醒我 */ return true; if (ws &gt; 0) { //只有CANCELLED状态&gt;0 /* * 前驱节点处于CANCELLED状态即前驱节点不想等了，就一直往前找，直到找到正常等待的状态，并排在它后面。 * 注意：处于CANCELLED的节点形成一个无引用链，稍后就会被GC */ do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { /* * 前驱节点状态既不是SIGNAL,也不是CANCELLED,则用CAS设置为SIGNAL */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } 这里需要注意，只有这个函数在当前节点的前驱节点的waitStatus状态本身就是SIGNAL的时候才会返回true, 其他时候都会返回false。 返回false后会回到循环中再次尝试获取锁。获取成功则直接结束，否则继续判断是否需要挂起，因为上次已经将状态改为SIGNAL,所以这次会直接挂起 当shouldParkAfterFailedAcquire返回true，即当前节点的前驱节点的waitStatus状态已经设为SIGNAL后，我们就可以安心的将当前线程挂起了，此时我们将调用parkAndCheckInterrupt： 1234private final boolean parkAndCheckInterrupt() { LockSupport.park(this);//调用park()使线程进入waiting状态 return Thread.interrupted();//如果被唤醒，查看自己是不是被中断的。} 3.1.4小结 acquireQueued()的源码终于分析完了，我们再贴下它的源码，总结下流程： 12345public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} 函数流程如下： 调用我们自定义同步器时重写的tryAcquire()方法尝试直接去获取资源，如果成功则直接返回； 没成功，则调用addWaiter()方法生成节点加入队列尾部(先快速添加，快速添加失败通过enq函数进行CAS自旋添加)，并标记为独占模式。 acquireQueued()方法使得每个节点(线程)进行CAS自旋，当前驱节点为头结点且能够获取到同步状态，则获取到资源进行返回；否则线程进入WAITING状态。 如果线程在等待过程中被中断，不做响应。只有在获取资源后才进行自我中断。 最后节点的状态如下： 除了头节点，其余节点全部为WAITING状态 除了尾节点，其余节点都满足waitStatus=SIGNAL，表示释放后需要唤醒后继节点 3.2独占式同步状态释放 release(int) 上一小节已经把acquire()说完了，这一小节就来讲讲它的反操作release()吧。此方法是独占模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。这也正是unlock()的语义。下面是release()的源码： 12345678910public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; //找到头结点 //有头结点，并且头结点后面有挂起等待的后继节点(h.waitStatus = 0表示刚初始化，没有后继节点) if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); //唤醒等待队列里的下一个线程 return true; } return false; } 3.2.1tryRelease() 此方法尝试去释放指定量的资源,源码如下： 123protected boolean tryRelease(int arg) { throw new UnsupportedOperationException();} 跟tryAcquire()一样，这个方法是需要独占模式的自定义同步器去实现的。正常来说，tryRelease()都会成功的，因为这是独占模式，该线程来释放资源，那么它肯定已经拿到独占资源了，直接减掉相应量的资源即可(state-=arg)，也不需要考虑线程安全的问题。但要注意它的返回值，release()是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了！所以自义定同步器在实现时，如果已经彻底释放资源(state=0)，要返回true，否则返回false。 3.2.2unparkSuccessor() 1234567891011121314151617181920212223private void unparkSuccessor(Node node) { int ws = node.waitStatus; // 如果当前线程节点状态&lt;0 则直接将其置为0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /** * 当前node是释放锁的node，则在队列中后面的节点，一般是需要唤醒的节点 * 如果后继节点存在且也在等待锁，就直接唤醒它 * 但是有可能存在 后继节点取消等待锁的情况 * 此时从尾结点开始向前找，知道找到有效节点 */ Node s = node.next; //找到下一个需要唤醒的有效节点 if (s == null || s.waitStatus &gt; 0) { s = null;//如果为空或者已取消 进行GC for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) //从后往前找 if (t.waitStatus &lt;= 0) //&lt;=0为有效节点 s = t; } if (s != null) LockSupport.unpark(s.thread); //唤醒 } 这里有一个小问题就是为什么找有效节点时是从尾结点往前面找，而不是直接找head的下一个结点？ 首先我们要看到，从后往前找是基于一定条件的： 1if (s == null || s.waitStatus &gt; 0) 即后继节点不存在，或者后继节点取消了排队，这一条件大多数条件下是不满足的。因为虽然后继节点取消排队很正常，但是通过上面我们介绍的shouldParkAfterFailedAcquire方法可知，节点在挂起前，都会给自己找一个waitStatus状态为SIGNAL的前驱节点，而跳过那些已经cancel掉的节点。 所以，这个从后往前找的目的其实是为了照顾刚刚加入到队列中的节点，这就涉及到我们上面讲的尾分叉了。刚刚加入的节点的prev一定是指向了前面的节点。而由于CAS失败或者虽然CAS成功但unparkSuccessor方法就开始执行，此时pred.next还没有设置值就会造成从前往后遍历遍历不到尾结点。 最后, 在调用了 LockSupport.unpark(s.thread) 也就是唤醒了线程之后, 会发生什么呢? 我们上面讲获取资源的时候，不是到了获取失败被挂起了吗 1234private final boolean parkAndCheckInterrupt() { LockSupport.park(this); // 喏, 就是在这里被挂起了, 唤醒之后就能继续往下执行了 return Thread.interrupted();} 我们现在唤醒s线程后，s线程会返回当前线程的中断状态，并清除它。接着，我们再返回到acquire()函数中调用parkAndCheckInterrupt的地方: 12if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; 可见，如果Thread.interrupted()返回true，则 parkAndCheckInterrupt()就返回true, if条件成立，interrupted状态将设为true;如果Thread.interrupted()返回false, 则 interrupted 仍为false。 再接下来我们重新进入for(;;)循环，进行新一轮的抢锁。 假设这次我们抢到了，我们将从return interrupted处返回，返回到哪里呢？ 当然是acquireQueued的调用处啦: 1234public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} 我们看到，如果acquireQueued的返回值为true, 我们将执行 selfInterrupt(): 123static void selfInterrupt() { Thread.currentThread().interrupt();} 而它的作用，就是中断当前线程。 为什么要这样做呢？ 从上面的代码中我们知道，即使线程在等待资源的过程中被中断唤醒，它还是会不依不饶的再抢锁，直到它抢到锁为止。也就是说，它是不响应这个中断的，仅仅是记录下自己被人中断过。 最后，当它抢到锁返回了，如果它发现自己曾经被中断过，它就再中断自己一次，将这个中断补上。 终于写完了AQS独占锁的获取与释放，接下来我们看看共享锁。其实只要真正看懂了独占锁，共享锁其实也是很容易看懂的。 在独占锁模式中，我们只有在获取了独占锁的节点释放锁时，才会唤醒后继节点。然而，在共享锁模式下，当一个节点获取到了共享锁，我们在获取成功后就可以唤醒后继节点了，而不需要等到该节点释放锁的时候。因此，在共享锁模式下，在获取锁和释放锁结束时，都会唤醒后继节点。 3.3共享式同步状态获取 acquireShared(int) 此方法是共享模式下线程获取共享资源的顶层入口。它会获取指定量的资源，获取成功则直接返回，获取失败则进入等待队列，直到获取到资源为止，整个过程忽略中断。下面是acquireShared()的源码： 1234public final void acquireShared(int arg) { if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);} 3.3.1tryAcquireShared() 123protected int tryAcquireShared(int arg) { throw new UnsupportedOperationException();} 这个方法和tryAcquire方法一样，也是由自定义同步器来实现，只是需要注意它提到的返回值： 如果该值小于0，则代表当前线程获取共享锁失败 如果该值大于0，则代表当前线程获取共享锁成功，并且接下来其他线程尝试获取共享锁的行为很可能成功 如果该值等于0，则代表当前线程获取共享锁成功，但是接下来其他线程尝试获取共享锁的行为会失败 从上面可以看到只要返回值大于0，就表示获取锁成功 接下来我们看看doAcquireShared方法，它对应于独占锁的acquireQueued()方法，两者其实很类似，我们这里只关注不同的部分 3.3.2doAcquireShared() 123456789101112131415161718192021222324252627282930private void doAcquireShared(int arg) { //对应于acquireQueued参数的addWaiter方法 final Node node = addWaiter(Node.SHARED); //对应于acquireQueued方法 boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head) { int r = tryAcquireShared(arg); //成功拿到资源 if (r &gt;= 0) { setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 这里第一点不同就是独占锁的acquireQueued调用的是addWaiter(Node.EXCLUSIVE)，而共享锁调用的是addWaiter(Node.SHARED)，表明了该节点处于共享模式，这两种模式的定义为： 1234/** Marker to indicate a node is waiting in shared mode */static final Node SHARED = new Node();/** Marker to indicate a node is waiting in exclusive mode */static final Node EXCLUSIVE = null; 该模式被赋值给了节点的nextWaiter属性： 1234Node(Thread thread, Node mode) { // Used by addWaiter this.nextWaiter = mode; this.thread = thread;} 我们知道在条件队列中，nextWaiter是指向条件队列中的下一个节点的，它将条件队列中的节点串起来，构成了单链表。但是在同步队列中，我们只用prev,next属性来串联节点，形成双向链表，nextWaiter属性在这里只起到一个标记作用，不会串联节点，这里不要被Node SHARED = new Node()所指向的空节点迷惑，这个空节点仅仅用作判断节点是否处于共享模式的依据 1234// Node#isShard()final boolean isShared() { return nextWaiter == SHARED;} 这里的第二点不同就在于获取锁成功后的行为，对于独占锁而言，是直接调用了setHead(node)方法，而共享锁调用的是setHeadAndPropagate(node, r)： 1234567891011private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // Record old head for check below setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) { Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); }} 在该方法内部我们不仅调用了setHead(node)，还在一定条件下调用了doReleaseShared()来唤醒后继的节点。这是因为在共享锁模式下，锁可以被多个线程所共同持有，既然当前线程已经拿到共享锁了，那么就可以直接通知后继节点来拿锁，而不必等待锁被释放的时候再通知。 这个doReleaseShared方法，我们到下面分析锁释放的时候再看。 3.4共享式同步状态释放 releaseShared(int) 上一小节已经把acquireShared()说完了，这一小节就来讲讲它的反操作releaseShared()吧。此方法是共享模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果成功释放且允许唤醒等待线程，它会唤醒等待队列里的其他线程来获取资源。 1234567public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false;} 3.4.1tryReleaseShared() 123protected boolean tryReleaseShared(int arg) { throw new UnsupportedOperationException();} 和之前的tryRelease()方法一样，需要自定义同步器实现，这里就不多提了。主要看下doReleaseShared()这个方法。 3.4.2doReleaseShared() 在共享锁模式下，头节点就是持有共享锁的节点，在它释放共享锁后，它也应该唤醒它的后继节点，但是值得注意的是，我们在之前doAcquiredShared()方法中的setHeadAndPropagate方法中可能已经调用过该方法了，也就是说它可能会被同一个头节点调用两次，也有可能在我们从releaseShared方法中调用它时，当前的头节点已经易主了，下面我们就来详细看看这个方法： 123456789101112131415161718 private void doReleaseShared() { for (;;) { Node h = head; if (h != null &amp;&amp; h != tail) { int ws = h.waitStatus; if (ws == Node.SIGNAL) { if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); } else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS } if (h == head) // loop if head changed break; }} 该方法可能是共享锁模式最难理解的方法了，在看该方法时，我们需要明确以下几个问题： (1) 该方法有几处调用？ 该方法有两处调用，一处在acquireShared方法的末尾，当线程成功获取到共享锁后，在一定条件下调用该方法；一处在releaseShared方法中，当线程释放共享锁的时候调用。 (2) 调用该方法的线程是谁？ 在独占锁中，只有获取了锁的线程才能调用release释放锁，因此调用unparkSuccessor(h)唤醒后继节点的必然是持有锁的线程，该线程可看做是当前的头节点(虽然在setHead方法中已经将头节点的thread属性设为了null，但是这个头节点曾经代表的就是这个线程) 在共享锁中，持有共享锁的线程可以有多个，这些线程都可以调用releaseShared方法释放锁；而这些线程想要获得共享锁，则它们必然曾经成为过头节点，或者就是现在的头节点。因此，如果是在releaseShared方法中调用的doReleaseShared，可能此时调用方法的线程已经不是头节点所代表的线程了，头节点可能已经被易主好几次了。 (3) 调用该方法的目的是什么？ 无论是在acquireShared中调用，还是在releaseShared方法中调用，该方法的目的都是在当前共享锁是可获取的状态时，唤醒head节点的下一个节点。这一点看上去和独占锁似乎一样，但是它们的一个重要的差别是——在共享锁中，当头节点发生变化时，是会回到循环中再立即唤醒head节点的下一个节点的。也就是说，在当前节点完成唤醒后继节点的任务之后将要退出时，如果发现被唤醒后继节点已经成为了新的头节点，则会立即触发唤醒head节点的下一个节点的操作，如此周而复始。 (4) 退出该方法的条件是什么 该方法是一个自旋操作for(;; )，退出该方法的唯一办法是走最后的break语句： 12if (h == head) // loop if head changed break; 即，只有在当前head没有易主时，才会退出，否则继续循环。 这个怎么理解呢？为了说明问题，这里我们假设目前sync queue队列中依次排列有 dummy node -&gt; A -&gt; B -&gt; C -&gt; D 现在假设A已经拿到了共享锁，则它将成为新的dummy node， dummy node (A) -&gt; B -&gt; C -&gt; D 此时，A线程会调用doReleaseShared，我们写做doReleaseShared[A]，在该方法中将唤醒后继的节点B，它很快获得了共享锁，成为了新的头节点： dummy node (B) -&gt; C -&gt; D 此时，B线程也会调用doReleaseShared，我们写做doReleaseShared[B]，在该方法中将唤醒后继的节点C，但是别忘了，在doReleaseShared[B]调用的时候，doReleaseShared[A]还没运行结束呢，当它运行到if(h == head)时，发现头节点现在已经变了，所以它将继续回到for循环中，与此同时，doReleaseShared[B]也没闲着，它在执行过程中也进入到了for循环中。。。 由此可见，我们这里形成了一个doReleaseShared的”调用风暴“，大量的线程在同时执行doReleaseShared，这极大地加速了唤醒后继节点的速度，提升了效率，同时该方法内部的CAS操作又保证了多个线程同时唤醒一个节点时，只有一个线程能操作成功。 那如果这里doReleaseShared[A]执行结束时，节点B还没有成为新的头节点时，doReleaseShared[A]方法不就退出了吗？是的，但即使这样也没有关系，因为它已经成功唤醒了线程B，即使doReleaseShared[A]退出了，当B线程成为新的头节点时，doReleaseShared[B]就开始执行了，它也会负责唤醒后继节点的，这样即使变成这种每个节点只唤醒自己后继节点的模式，从功能上讲，最终也可以实现唤醒所有等待共享锁的节点的目的，只是效率上没有之前的“调用风暴”快。 由此我们知道，这里的“调用风暴”事实上是一个优化操作，因为在我们执行到该方法的末尾的时候，unparkSuccessor基本上已经被调用过了，而由于现在是共享锁模式，所以被唤醒的后继节点极有可能已经获取到了共享锁，成为了新的head节点，当它成为新的head节点后，它可能还是要在setHeadAndPropagate方法中调用doReleaseShared唤醒它的后继节点。 详细请参考这篇文章https://segmentfault.com/a/1190000016447307 总结 共享锁的调用框架和独占锁很相似，它们最大的不同在于获取锁的逻辑——共享锁可以被多个线程同时持有，而独占锁同一时刻只能被一个线程持有。 由于共享锁同一时刻可以被多个线程持有，因此当头节点获取到共享锁时，可以立即唤醒后继节点来争锁，而不必等到释放锁的时候。因此，共享锁触发唤醒后继节点的行为可能有两处，一处在当前节点成功获得共享锁后，一处在当前节点释放共享锁后。","link":"/2020/03/21/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8BAQS%E5%88%9D%E6%8E%A2/"},{"title":"应用层","text":"主要内容 域名系统DNS 文件传送协议 FTP 电子邮件协议SMTP、POP3、IMAP DHCP协议 最重要的http协议单独写一篇博文啦 使用TCP和UDP的各种常见应用层协议 域名系统DNSDNS 是一个通过分层服务器实现的分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留与它相关的那部分数据。 DNS可以使用UDP或者TCP进行传输，使用的端口号都为 53。大多数情况下DNS使用UDP进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。 在两种情况下会使用TCP进行传输： 如果返回的响应超过的 512 字节（UDP 最大只支持512字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。 DNS工作流程：本地域名服务器采用递归查询 文件传送协议 FTP文件传送协议 FTP (File Transfer Protocol) 是互联网上使用得最广泛的文件传送协议。 FTP 提供交互式的访问，允许客户指明文件的类型与格式，并允许文件具有存取权限 文件传输过程 打开熟知端口（端口号为 21），使客户进程能够连接上。 等待客户进程发出连接请求。 启动从属进程来处理客户进程发来的请求。从属进程对客户进程的请求处理完毕后即终止，但从属进程在运行期间根据需要还可能创建其他一些子进程。 回到等待状态，继续接受其他客户进程发来的请求。主进程与从属进程的处理是并发地进行。 当客户进程向服务器进程发出建立连接请求时，要寻找连接服务器进程的熟知端口 (21)，同时还要告诉服务器进程自己的另一个端口号码，用于建立数据传送连接。 服务器进程用自己传送数据的熟知端口 (20) 与客户进程所提供的端口号码建立数据传送连接。 由于 FTP 使用了两个不同的端口号，所以数据连接与控制连接不会发生混乱。 FTP是使用了两个TCP连接的。好处： 使协议更加简单和更容易实现。 在传输文件时还可以利用控制连接（例如，客户发送请求终止传输）。 电子邮件协议SMTP、POP3、IMAP 注意： 不要将邮件读取协议 POP 或 IMAP 与邮件传送协议 SMTP 弄混。 发信人的用户代理向源邮件服务器发送邮件，以及源邮件服务器向目的邮件服务器发送邮件，都是使用 SMTP 协议。 而 POP 协议或 IMAP 协议则是用户从目的邮件服务器上读取邮件所使用的协议。 DHCP协议为了将软件协议做成通用的和便于移植，协议软件的编写者把协议软件参数化。在软件协议运行之前，必须给每一个参数赋值。在协议软件中给这些参数赋值的动作叫做协议配置。 互联网广泛使用的动态主机配置协议 DHCP (Dynamic Host Configuration Protocol) 提供了即插即用连网(plug-and-play networking) 的机制。 并不是每个网络上都有 DHCP 服务器，这样会使 DHCP 服务器的数量太多。现在是每一个网络至少有一个 DHCP 中继代理，它配置了 DHCP 服务器的 IP 地址信息。 注意： DHCP报文仅为UDP数据报的数据部分 DHCP 服务器分配给 DHCP 客户的 IP 地址的临时的，因此 DHCP 客户只能在一段有限的时间内使用这个分配到的IP 地址。","link":"/2020/03/10/%E5%BA%94%E7%94%A8%E5%B1%82/"},{"title":"Java多线程之synchronized锁和显式Lock锁","text":"主要内容 synchronized锁 volatile关键字 显式Lock锁 synchronized和显式Lock的区别 在多线程编程中，一个非常重要的问题是如何保证线程的安全性问题。非线程安全会在多个线程对同一个对象中的实例变量进行并发访问时发生，产生的问题就是”脏读”，即取到的数据其实是被更改过的。 比如下面这个例子: 123456789101112131415public class MyRunnable implements Runnable { private int count = 0; @Override public void run() { count++; //只是为了显示线程不安全 try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+\"---\"+count); }} 使用两个线程同时操作实例变量count 123456789public class test { public static void main(String[] args) { MyRunnable myRunnable = new MyRunnable(); Thread t1 = new Thread(myRunnable,\"t1\"); Thread t2 = new Thread(myRunnable,\"t2\"); t1.start(); t2.start(); }} 结果如下，理论上应该是一个是1一个是2。但实际上运行的结果两个都是2。 12t1---2t2---2 为了解决上面的问题，Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问 JVM实现的synchronized关键字 JDK1.5之后加入的显式Lock锁 synchronized锁synchronized锁概述 synchronized可以用来修饰方法或者以同步块的形式使用，主要是确保多个线程在同一时刻只能有一个线程处于方法或者同步块中。 synchronized锁锁的是对象，不是代码块。 synchronized锁是互斥锁(一次只能允许一个线程拿到锁) synchronized保证了线程的原子性和可见性 这里提一下原子性和可见性 原子性：某一个操作是不可分割的。 可见性：当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。 比如我们常见的count++就不是一个原子操作，而是需要经过三步：1. 获取count值 2. count值+1 3. +1后的值重新赋值给count。很多线程不安全都是因为某个操作不是原子性的，使数据混乱出错。 对于可见性而言，Java虽然支持多个线程同时访问一个对象或者对象的一个成员变量，但实际上是每个线程拥有这个变量的一个拷贝，所以当某个线程修改了这个变量后，其他线程看到的这个变量并不一定是最新的，这就是不可见。可见性是指这个变量改变后，会同步刷新到共享内存，并告知其他线程访问该变量必须从共享内存中获取。后面要讲的volatile关键字也是可见的。 synchronized保证了原子性和可见性也就是说使用synchronized之后，被保护的代码块是一次被执行的，没有任何线程会同时访问，并且当执行完synchronized之后，修改后的变量对其他的线程是可见的 synchronized锁原理 对使用synchronized修饰方法和代码块的代码进行反编译 1234567891011121314package com.company.MultiThread;public class Main { //修饰方法 public synchronized void test1(){ } public void test2(){ // 修饰代码块 synchronized (this){ } }} 可以看到synchronized在JVM里的实现原理，JVM基于进入和退出Monitor对象来实现的同步 同步代码块：使用monitorenter和monitorexit指令实现的 同步方法（在这看不出来需要看JVM底层实现）方法修饰符上的ACC_SYNCHRONIZED实现。 synchronized用的锁是存在Java对象头里的。每个对象都对象有自己的对象头，存储了很多信息，其中一个信息标示是被哪个线程持有。 这里简单说明下，更加详细的解释可以参考书籍《Java并发编程的艺术》第二章和这篇文章深入分析synchronized的实现原理 如何使用synchronized锁 对于同步方法块，锁是synchronized的括号里配置的对象 对于普通同步方法，锁是当前实例对象 对于静态同步方法，锁是当前类的Class对象 synchronized锁作用于同步方法块对于上面的例子，我们可以把需要同步的代码部分放入synchronized代码块中即可。 123456789101112public class Demo { private int count = 0; //private Object o = new Object(); public void m1() { //synchronized(o) synchronized (this){ count++; System.out.println(Thread.currentThread().getName()+\"---\"+count); } }} 上面synchronized括号中是this，即当前实例对象。但是不一定使用this。可以随便使用一个对象(因为每个对象都有一个监视器锁)。上面注释部分就是使用的一个object锁，但不推荐使用这种方法。 synchronized锁作用于普通同步方法 这里synchronized作用于普通方法increase(),实际上相当于同步代码块中使用this锁。 123456789public class Demo { private int count = 0; //等价于synchronized(this) private synchronized void increase(){ count++; System.out.println(Thread.currentThread().getName()+\"---\"+count); }} synchronized锁作用于静态同步方法如果上面的increase()方法是静态方法,这里就相当于同步代码块中使用当前类的对象，即MyRunnable.class锁 12345678public class Demo { private static int count = 0; //等价于synchronized(MyRunnable.class) private synchronized static void increase(){ count++; System.out.println(Thread.currentThread().getName()+\"---\"+count); }} synchronized锁注意事项 上面几个只是synchronized的最基本使用，对于synchronized仍然有几点需要注意： 同步方法和非同步方法可以同时运行(只有在调用加锁的部分时，才需要看能否拿到锁，不需要锁的部分则是直接执行。容易产生脏读问题) synchronized是可重入锁,即同步方法中可以调用另一个同步方法 死锁问题 脏读问题只对写进行了加锁，没有对读进行加锁。可能在写过程中进行了读操作。解决也很好解决，就是对读使用和写相同的锁，即在读上也加上synchronized。 1234567891011121314151617181920public class Account { private String name; private double balance; public synchronized void set(String name,double balance){ this.name = name; //设定完name后，可能线程会执行getBalance方法 try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } this.balance = balance; } //加上synchronized即可解决 public /*synchronized*/ double getBalace(String name){ return this.balance; }} 1234567891011121314151617181920212223public class test { public static void main(String[] args) { Account account = new Account(); new Thread(()-&gt;account.set(\"a\",100)).start(); //先让线程执行 try { Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(account.getBalace(\"a\")); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(account.getBalace(\"a\")); }} 两次结果不一致，产生脏读问题。 120.0100.0 可重入锁同步方法中可以调用另一个同步方法，也就是说一个线程已经拥有某个对象的锁，再次申请的时候仍然会得到该对象的锁（常见于子类继承父类，子类同步方法调用父类同步方法） 1234567891011121314151617181920public class T { public synchronized void m1(){ System.out.println(\"m1 start\"); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } m2(); } public synchronized void m2(){ System.out.println(\"m2\"); } public static void main(String[] args) { new Thread(()-&gt;new T().m1()).start(); }} 运行结果： 12m1 startm2 死锁问题两个或者多个线程互相持有对方所需要的资源，导致这些线程处于等待状态，无法前往执行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class DeadLockDemo { private Object A = new Object(); private Object B = new Object(); public static void main(String[] args) { new DeadLockDemo().deadLock(); } private void deadLock(){ new Thread(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread().getName()+\"尝试拿锁A\"); synchronized (A){ System.out.println(Thread.currentThread().getName()+\"拿到锁A\"); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+\"尝试拿锁B\"); synchronized (B){ System.out.println(Thread.currentThread().getName()+\"拿到锁B\"); } } } },\"线程1\").start(); new Thread(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread().getName()+\"尝试拿锁B\"); synchronized (B){ System.out.println(Thread.currentThread().getName()+\"拿到锁B\"); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+\"尝试拿锁A\"); synchronized (A){ System.out.println(Thread.currentThread().getName()+\"拿到锁A\"); } } } },\"线程2\").start(); }} 结果如下图所示： 当方法(代码块)执行完毕后会自动释放锁，不需要做任何的操作。 当一个线程执行的代码出现异常时，其所持有的锁会自动释放(要想不释放，需要用try-catch处理异常)。 释放锁的时机 当方法(代码块)执行完毕后会自动释放锁，不需要做任何的操作。 当一个线程执行的代码出现异常时，其所持有的锁会自动释放。 不会由于异常导致出现死锁现象~ volatile关键字之前我们提到过volatile关键字 volatile是一种轻量级的同步机制（效率比synchronized高很多） volatile仅仅用来保证该变量对所有线程的可见性，但不保证原子性 volatile禁止指令重排序 volatile底层原理 需要用到JMM的知识(待补充)，这里先放两张图。当多个线程操作同一个变量时，实际上是每个线程将这个变量从主内存拷贝到线程独有的工作内存，所以当某个线程修改了这个变量后，其他线程看到的这个变量并不一定是最新的，这就是不可见 volatile关键字的作用就在于当其他线程要使用这个变量时，强制其他线程从主内存中读取值，保证每次读取都是公共内存中的值。 验证volatile的可见性 我们之前通过标志位停止一个死循环就用到了volatile的可见性 123456789101112131415161718192021public class FlagStop { private volatile boolean flag; public void m1(){ while(!flag){ System.out.println(\"死循环中\"); } System.out.println(\"跳出了循环\"); } public void setFlag(boolean flag) { this.flag = flag; } public static void main(String[] args) { FlagStop flagStop = new FlagStop(); new Thread(()-&gt;flagStop.m1(),\"t1\").start(); flagStop.setFlag(true); }} 验证volatile没有原子性 还用之前的例子，只不过将共享变量设为volatile，会发现还是会有线程不安全问题 1234567891011121314151617181920212223242526272829303132333435363738package com.company.MultiThread;import java.util.ArrayList;import java.util.List;import java.util.concurrent.atomic.AtomicInteger;public class MyRunnable { //AtomicInteger count = new AtomicInteger(0); private volatile int count = 0; public void increase(){ for (int i = 0; i &lt; 1000; i++) { //count.incrementAndGet(); count++; } } public static void main(String[] args) { MyRunnable myRunnable = new MyRunnable(); List&lt;Thread&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) { list.add(new Thread(()-&gt;myRunnable.increase(),\"Thread\"+i)); } list.forEach((o)-&gt;o.start()); list.forEach((o)-&gt;{ try { o.join(); } catch (InterruptedException e) { e.printStackTrace(); } }); System.out.println(myRunnable.count); }} 19787 多运行几次，可以看到每次结果不一样，偶尔才有可能正好是10000。出现问题的原因在于比如上面每个线程1加到100后由于可见性线程2得到的也是100这是没问题的，但是这个时候线程1在自己内存拷贝加1之后写入共享内存，同时线程2在内存拷贝(这时候内存拷贝的是100)加1，这时候再写入共享内存时，不会检查是不是101，而是直接写入共享内存。所以经常得到的结果是小于10000的。 volatile有序性 有序性是指程序的执行严格按照我们写的代码的顺序进行执行。 一般情况下，CPU和编译器为了提升程序执行的效率，会按照一定的规则允许对指令进行优化，即调整实际指令运行的顺序。指令重排不会对单线程的程序造成任何不利的影响，但是多线程环境下将会产生一些影响。指令重排的前提条件是指令调整后不会影响单线程程序的执行： 1234int i = 2; //statement 1int j = 1;//statement 2int k = i*j;//statement 3 在上面的代码中对于语句1和语句2相互之间没有任何依赖，所以可能发生指令重排，但是语句3和语句1,2都有关系，所以语句3一定是在语句1和语句2之后执行的。所以单线程情况下是绝对不会出现问题的。但是对于多线程可能就发生只是初始化了语句1或者语句2就执行语句3了。 综合volatile的性质，一般来说，volatile大多用于标志位上(判断操作),满足下面的条件才应该使用volatile修饰变量： 修改变量时不依赖变量的当前值(因为volatile是不保证原子性的) 该变量是可变的 在访问变量的时候不需要加锁(加锁就没必要使用volatile这种轻量级同步机制了) 当然对于上面的count++的非原子性问题，除了加锁之外，还可以使用J.U.C包下的atomic包，这些包中提供的类保证了原子性操作。上面的代码中的注释部分就是用的atomic包中的AtomicInteger。 显式Lock锁显式Lock锁是JDK1.5之后才有的位于java.util.concurrent（J.U.C）包中。 读一下源码注释，简单了解下Lock锁： 实现Lock接口的类提供比synchronized更灵活和更多的锁操作功能。 可以绑定多个Condition对象 一般来说一个锁能防止多个线程共享资源，但是有些锁可以允许多个线程并发的访问共享资源如ReadWriteLock读写锁。 与synchronized相比，Lock锁的实现类可以实现synchronized不具备的功能，如尝试非阻塞的获取锁、超时获取锁和能被中断的获取锁 源码注释中也提供给了我们如何使用Lock锁 1234567Lock l = ...;l.lock();try { // access the resource protected by this lock} finally { l.unlock(); }} 注意两点： lock.lock()在try语句块外面，否则如果在获取锁(自定义锁的实现)时发生了异常，会导致锁无故释放。 lock锁一定要手动释放，一般是写在finally语句块中 用lock锁改写下我们之前的例子 12345678910111213141516171819202122232425public class T { private int count = 0; Lock lock = new ReentrantLock(); //等价于private synchronized void m1() public void m1(){ lock.lock(); //加锁 try { count++; Thread.sleep(500); System.out.println(count); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); //注意一定不要忘了手动释放锁 } } public static void main(String[] args) { T t = new T(); new Thread(()-&gt;t.m1(),\"t1\").start(); new Thread(()-&gt;t.m1(),\"t2\").start(); }} Lock接口中的方法： lock和unlock上面已经用过了，Conditon是在线程通信中使用，下篇文章讲，这里讲下tryLock()。 tryLock是尝试获取锁，如果能拿到锁就执行，否则就不执行。方法可以设置尝试获取锁的时间。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class T { Lock lock = new ReentrantLock(); public void m1(){ lock.lock(); try { for (int i = 0; i &lt; 10; i++) { TimeUnit.SECONDS.sleep(1); System.out.println(i); } } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } public void m2(){ boolean locked = false; try { System.out.println(\"m2开始尝试拿锁\"); locked = lock.tryLock(5,TimeUnit.SECONDS); if(locked){ System.out.println(locked+\"拿到锁了，开始执行需要同步的代码\"); }else{ System.out.println(locked+\"没有拿到锁，执行不需要同步的代码\"); } } catch (InterruptedException e) { e.printStackTrace(); } finally { if(locked) lock.unlock(); } } public static void main(String[] args) { T t = new T(); new Thread(()-&gt;t.m1(),\"t1\").start(); try { Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } new Thread(()-&gt;t.m2(),\"t2\").start(); }} 123456789101112m2开始尝试拿锁01234false没有拿到锁，执行不需要同步的代码56789 这里对于lock锁只是简单介绍，之后会详细讲解同步器AQS以及Lock接口常用的实现类ReentrantLock。 synchronized和显式Lock的区别原始构成 synchronized是关键字属于JVM层面，底层通过monitor对象来完成 Lock是J.U.C包中的类，是API层面的锁 使用方法 synchronized不需要用户去手动释放锁，当synchronized代码执行完后系统会自动让线程释放对锁的占用。 ReentrantLock需要用户去手动释放锁，若没有主动释放锁，则有可能产生死锁现象。 等待是否可中断 synchronizd不可中断，除非抛出异常或者正常执行完成。 ReentrantLock可中断，1.设置超时方法tryLock(long timeout,TimeUnit unit)2. lockInterruptibly()放代码块中，调用interrupt()方法可中断 加锁是否公平 synchronized是非公平锁 ReentrantLock是公平锁和非公平锁都支持。默认是非公平锁 锁绑定多个condition synchronized没有，只能随机唤醒一个线程或者唤醒全部线程 ReentrantLock可以绑定多个condition对象，可以实现精准唤醒","link":"/2020/03/18/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8Bsynchronized%E9%94%81%E5%92%8C%E6%98%BE%E5%BC%8FLock%E9%94%81/"},{"title":"ConcurrentHashMap源码解析","text":"主要内容 逐行分析下面5部分的源码解析 Node节点 hash方法spread() 构造方法 put方法 rehash方法tryPresize() Node结点JDK1.8中，和HashMap一样，也是使用Node节点存储键值对。不过与HashMap不同的是由于是并发容器，所以value值和next指针使用volatile修饰，保证线程之间的可见性。 1234567891011121314static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; Node(int hash, K key, V val, Node&lt;K,V&gt; next) { this.hash = hash; this.key = key; this.val = val; this.next = next; } ...} hash方法123static final int spread(int h) { return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;} 构造方法了解了上面的基本的方法，我们先来看下ConcurrentHashMap的构造方法和一些主要参数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class ConcurrentHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements ConcurrentMap&lt;K,V&gt;, Serializable { private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; private static final int DEFAULT_CAPACITY = 16; private static final float LOAD_FACTOR = 0.75f; static final int TREEIFY_THRESHOLD = 8; static final int UNTREEIFY_THRESHOLD = 6; static final int MIN_TREEIFY_CAPACITY = 64; //上面这些变量和HashMap的完全一样，这里就不说了 //主要看看下面这些和并发有关的变量 //数组初始化大小和扩容时的大小控制 //-1表示数组将被初始化 //-(1+活动线程数n)表示n个线程在调整大小 private transient volatile int sizeCtl; //默认并发级别，未使用，是为了兼容之前的版本 private static final int DEFAULT_CONCURRENCY_LEVEL = 16; //定义的数组 transient volatile Node&lt;K,V&gt;[] table; //定义的扩容之后的数组 private transient volatile Node&lt;K,V&gt;[] nextTable; //空构造函数 public ConcurrentHashMap() { } //指定初始容量的构造函数 //同样用tableSizeFor去计算大于初始容量的最小的2的整数次幂 //注意这里最终是将容量赋值给了sizeCtl public ConcurrentHashMap(int initialCapacity) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap; } //指定初始容量和负载因子 //调用的是下面的构造函数 public ConcurrentHashMap(int initialCapacity, float loadFactor) { this(initialCapacity, loadFactor, 1); } //指定初始容量、负载因子和并发级别 public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) { if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins initialCapacity = concurrencyLevel; // as estimated threads long size = (long)(1.0 + (long)initialCapacity / loadFactor); int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); //同样是赋值给了sizeCtl this.sizeCtl = cap; } //通过已有Map构建ConcurrentHashMap public ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) { this.sizeCtl = DEFAULT_CAPACITY; putAll(m); } 总结：和HashMap一样，ConcurrentHashMap的5个构造函数初始化时并没有初始化table。并且也只是初始化了sizeCtl和loadFactor这两个变量。 put方法put方法是ConcurrentHashMap的核心方法，我们接下来看看它是如何实现的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public V put(K key, V value) { return putVal(key, value, false); //false表示覆盖原有值}/** Implementation for put and putIfAbsent */final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) { Node&lt;K,V&gt; f; int n, i, fh; //实际初始化table是放在了put操作中，用时再初始化类似于懒加载 if (tab == null || (n = tab.length) == 0) tab = initTable(); //通过Unsafe类硬件安全的判断主内存目标桶内是否为null //null则新建节点并通过CAS放到目标位置 //这里没有用锁 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) { if (casTabAt(tab, i, null,new Node&lt;K,V&gt;(hash, key, value, null))) break; } //如果检测到数组某个节点的hash值是MOVED，则表示正在进行数组扩容的数据复制阶段 //则当前线程也会参与去复制，通过允许多线程复制，来减少数组的复制所带来的性能损失 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); //到这里说明是目标节点有值，且不是数组扩容 else { V oldVal = null; //这里用的锁为f这一个节点而不是锁定整张表，提高了并发性 synchronized (f) { if (tabAt(tab, i) == f) { //是链表的话 if (fh &gt;= 0) { binCount = 1; //循环链表 for (Node&lt;K,V&gt; e = f;; ++binCount) { K ek; //找到hash和equals都相同的则替换 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } //否则则加入链表尾部 Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) { pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; } } } //到这里说明是树节点 //通过putTreeVal添加到红黑树 else if (f instanceof TreeBin) { Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } //这里已经没有加锁了 //判断链表是否需要树化 //并且返回oldValue if (binCount != 0) { if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount);//计数 return null;} initTable()的源码如下： 1234567891011121314151617181920212223242526private final Node&lt;K,V&gt;[] initTable() { Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) { //sizeCtl小于0，说明别的线程正在进行初始化让出执行权 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin //到这里说明sizeCtl&gt;0,则直接初始化 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { try { if ((tab = table) == null || tab.length == 0) { //sizeCtl&gt;0则初始化一个sizeCtl的数组，否则初始化默认长度(16)数组 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; //sizeCtl设置为数组长度的3/4 sc = n - (n &gt;&gt;&gt; 2); } } finally { sizeCtl = sc; } break; } } return tab;} 初始化数组table的流程如下： 如果sizeCtl小于0，说明别的线程正在进行初始化，则让出执行权 如果sizeCtl大于0的话，则通过CAS初始化一个大小为sizeCtl的数组或者一个默认大小(16)的数组 然后设置sizeCtl的值为数组长度的3/4 看完了初始化，我们再来看下它的链表长度超过8时的树化或者扩容: 123456789101112131415161718192021222324252627282930/*** 当数组长度小于64的时候，扩张数组长度一倍，否则的话把链表转为树*/private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) { Node&lt;K,V&gt; b; int n, sc; if (tab != null) { // 数组扩容 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) //MIN_TREEIFY_CAPACITY 64 tryPresize(n &lt;&lt; 1); //使用synchronized同步器，将该节点出的链表转为树 else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) { synchronized (b) { if (tabAt(tab, index) == b) { TreeNode&lt;K,V&gt; hd = null, tl = null; //hd：树的头(head) for (Node&lt;K,V&gt; e = b; e != null; e = e.next) { TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val,null, null); //把Node组成的链表，转化为TreeNode的链表，头结点任然放在相同的位置 if ((p.prev = tl) == null) hd = p; //设置head else tl.next = p; tl = p; } setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd));//把TreeNode的链表放入容器TreeBin中 } } } }} 从上面我们知道: ConcurrentHashMap扩容调用的是tryPresize方法，这个方法我们放在下面来讲解。 链表转化为树时同样使用了synchronized关键字进行了加锁,并且和添加操作使用的是同一把锁。 到这里我们总结下put方法的流程： 当添加一对键值对的时候，首先会去判断保存这些键值对的数组是不是初始化了，如果没有的话就初始化数组 然后通过计算hash值来确定放在数组的哪个位置，如果这个位置为空则通过CAS直接添加。 如果不为空的话，则判断该节点的hash值是不是MOVED(-1)，是的话则表示当前正在对这个数组进行扩容，复制到新的数组，则当前线程也去帮助复制。 最后一种情况就是，如果这个节点，不为空，也不在扩容，则通过synchronized来对目标位置的节点进行加锁（注意这里只是对节点加锁），进行添加操作 然后判断当前取出的节点位置存放的是链表还是树 如果是链表的话，则遍历整个链表，直到取出来的节点的key来个要放的key进行比较，如果key相等，并且key的hash值也相等的话，则说明是同一个key，则覆盖掉value，否则的话则添加到链表的末尾 如果是树的话，则调用putTreeVal方法把这个元素添加到树中去 最后在添加完成之后，会判断在该节点处共有多少个节点（注意是添加前的个数），如果达到8个以上了的话， 则调用treeifyBin方法来尝试将处的链表转为树(同样使用synchronized加锁，并且和添加时使用的是同一把锁)，或者扩容数组 数组扩容上面我们知道ConcurrentHashMap扩容调用的是tryPresize方法。接下来我们就看看这个方法： 12345678910111213141516171819202122232425262728293031323334353637383940private final void tryPresize(int size) { int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; while ((sc = sizeCtl) &gt;= 0) { Node&lt;K,V&gt;[] tab = table; int n; if (tab == null || (n = tab.length) == 0) { n = (sc &gt; c) ? sc : c; if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { try { if (table == tab) { @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; sc = n - (n &gt;&gt;&gt; 2); } } finally { sizeCtl = sc; } } } else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; else if (tab == table) { int rs = resizeStamp(n); if (sc &lt; 0) { Node&lt;K,V&gt;[] nt; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); } else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); } }} get方法12345678910111213141516171819public V get(Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) { if ((eh = e.hash) == h) { if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; } else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) { if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; } } return null;}","link":"/2020/03/26/ConcurrentHashMap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"title":"深入理解JVM开篇","text":"深入理解Java虚拟机搞起来，哇咔咔!!! 理解JVM的重要性就不用我多说了。理解JVM不管是面试还是对Java的进一步理解都是十分重要的。 之前自己看过一遍《深入理解Java虚拟机》之后，看的自己怀疑人生，所以最近有时间再来读一遍，顺便做一些总结。 JVM体系结构整个JVM的体系结构如下图所示。 上面这张图比较关键，之后几篇文章，我们也主要从上面这张图入手，再去读一遍《深入理解Java虚拟机》这本书。","link":"/2020/03/15/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E5%BC%80%E7%AF%87/"},{"title":"Java多线程之线程池","text":"主要内容 线程池的概念 线程池的基本使用 线程池的7大参数 线程池工作原理 使用自定义线程池 线程池基本概念什么是线程池 线程池可以看做是一个线程的集合。它的工作主要是控制运行的线程数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。 主要特点：线程复用、控制最大并发数、管理线程 为什么使用线程池 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。 线程池的基本使用这里，我们先对这张图有点印象，只需要知道ThreadPoolExecutor是线程池的核心即可。剩下的放到Executor框架来讲。 使用线程池基本上有3步: 新建线程池 向线程池提交任务 关闭线程池 这里我们先写个demo感受一下： 1234567891011121314151617181920212223242526package com.company.MultiThread;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class ThreadPoolDemo { public static void main(String[] args) { //新建线程池 ExecutorService threadPool = Executors.newFixedThreadPool(5); //ExecutorService threadPool = Executors.newSingleThreadExecutor(); //ExecutorService threadPool = Executors.newCachedThreadPool(); try { for (int i = 0; i &lt; 10; i++) { //向线程池提交任务 threadPool.execute(()-&gt;{ System.out.println(Thread.currentThread().getName()+\"办理业务\"); }); } } catch (Exception e) { e.printStackTrace(); } finally { //关闭线程池 threadPool.shutdown(); } }} 1. 新建线程池 我们可以通过两种方式新建线程池： JDK提供的线程池 使用自定义线程池 JDK提供的线程池主要有以下3个： newFixedThreadPool() 固定线程数线程数 newSingleThreadExecutor() 单个线程的线程池 newCachedThreadPool() 根据需求创建线程的线程池 我们用上面的代码验证下这3个线程池有什么不同： 从左到右依次为newFixedThreadPool、newSingleThreadExecutor、newCachedThreadPool()。所有线程池都是添加了10个任务。其中newFixedThreadPool()中设置线程数为5,从最左边的图可以看到5个线程处理完10个任务;newSingleThreadExecutor()只有1个线程处理10个任务;而newCachedThreadPool()中则是直接创建了10个线程完成了10个任务 注意 注意注意 注意注意 注意 虽然上面使用的是JDK给我们提供的线程池，但是阿里巴巴Java开发手册中明确要求实际使用时我们应该使用自定义线程池。原因和示例代码参考下面的使用自定义线程池章节。 2. 向线程池提交任务 可以使用两个方法向线程池提交任务： execute() 用于提交不需要返回值的任务 submit() 用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象的get()方法来获取返回值。 3. 关闭线程池 关闭线程池有两种方法： shutdown shutdownNow 区别:shutdownNow首先将线程池的状态设置成STOP，然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表。shutdown只是将线程池的状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。 它们的原理都是遍历线程池中的工作线程，然后逐个调用线程的interrupt方法来中断线程，所以无法响应中断的任务可能永远无法终止。 线程池七大参数上面我们讲到了JDK提供的3种线程池，我们看下他们的源码： 从上面的源码中我们知道，创建3种线程池时，实际上返回的是一个ThreadPoolExecutor,另外我们也看到，虽然3种不同类型线程池传递的参数值不同，但都是传递了5个参数。 那为什么我们会说7大参数呢？我们看下上面使用的ThreadPool的构造方法： 从源码可以看到实际上是通过this调用了另一个构造方法，并且传递了7个参数。 接下来我们就好好聊聊这7个参数的意义： 参数 意义 corePoolSize 线程池中的常驻核心数 maximumPoolSize 线程池允许的最大线程数。此值必须大于等于1 keepAliveTime 多余的空闲线程的存活时间。当前线程池数量超过corePoolSize时，并且空闲时间达到keepAliveTime时，多余空闲线程会被销毁直至只剩下corePoolSize个线程为止 unit keepAliveTime的单位 workQueue 被提交但尚未被执行的任务会被分配到任务队列任务队列，就是我们前面学习的阻塞队列。 threadFactory 生成线程池中工作线程的线程工厂，用于创建线程，一般用默认的即可 RejectedExecutionHandler 拒绝策略(共4种)，当队列满了并且工作线程大于等于线程池的最大线程数时, 四种拒绝策略： AbortPolicy：(系统默认拒绝策略)。直接抛出RejectedExecutionException异常阻止系统正常运行。 CallerRunsPolicy：”调用者运行”一种调节机制，该策略既不会抛弃任务，也不会抛出异常，而是将某些任务回退到调用者，从而降低新的任务流量。 DiscardOldestPolicy：丢弃队列里等待最久的一个任务，然后把当前任务加入到队列中尝试再次提交当前任务。 DiscardPolicy：直接丢弃任务，不处理也不抛出异常。如果允许任务丢失，这是最好的一种方案 代码验证见下面的自定义线程池部分。 线程池的工作原理只是这几个参数可能还不能很好的理解，我们接下来结合线程池的工作原理来看看这几个参数的意义。 当提交一个新任务到线程池时，线程池的处理流程如下 再结合上面的参数，ThreadPoolExecutor执行execute方法可以分下面4种情况 1）如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）2）如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。3）如果无法将任务加入BlockingQueue（队列已满），则扩展新的线程来处理任务（注意，执行这一步骤需要获取全局锁）4）如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将通过拒绝策略被拒绝 另外对于keepAliveTime这时候我们也就清楚了，就是我们的核心线程池和阻塞队列都已经满了之后，线程池会新建线程执行任务，这些新建的线程执行完任务后处于空闲状态，经过keepAliveTime后会被销毁，直到只剩下corePoolSize个线程。 使用自定义线程池注意 注意注意 注意注意 注意 阿里巴巴Java开发手册中明确规定：不能使用Executors方法创建线程池，应该使用自定义线程池 图片来自《阿里巴巴Java开发手册1.4.0》 自定义线程池原因 原因上面也提到了，我们再贴一下JDK提供的3种线程的代码 可以看到newFixedThreadPool和newSingleThreadExecutor中使用的是没有指明参数的LinkedBlockingQueue&lt;&gt;()，它是一个无界阻塞队列，即最大可以存放Integer.Max_VALUE的任务队列，导致产生OOM异常。这也是为什么我们使用自定义线程池时不能使用无界阻塞队列的原因。而newCachedThreadPool中，虽然使用的是SynchronousQueue(),但是它的最大线程数设置的同样是Integer.MAX_VALUE,所以当线程过多时同样会产生OOM异常。 使用自定义线程池 接下来我们使用自定义线程池，并且验证下上面提到的4种拒绝策略 1234567891011121314151617181920212223242526272829303132333435package com.company.MultiThread;import java.util.concurrent.Executors;import java.util.concurrent.LinkedBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class ThreadPoolDemo { public static void main(String[] args) { //新建线程池 ThreadPoolExecutor threadPool = new ThreadPoolExecutor( 3, //核心线程数3 6, //最大线程数6 2L, //扩展线程保持时间2ms TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;(3), //任务队列容量3 Executors.defaultThreadFactory(), // new ThreadPoolExecutor.AbortPolicy()); //AbortPolicy拒绝策略抛异常 //new ThreadPoolExecutor.CallerRunsPolicy() //new ThreadPoolExecutor.DiscardOldestPolicy() //new ThreadPoolExecutor.DiscardPolicy() try { for (int i = 0; i &lt; 10; i++) { //i&lt;8 i&lt;9 i&lt;10 threadPool.execute(()-&gt;{ System.out.println(Thread.currentThread().getName()+\"办理业务\"); }); } } catch (Exception e) { e.printStackTrace(); } finally { threadPool.shutdown(); } }} 从上面设置的参数我们知道，我们这个自定义的线程池最大容量为6+3=9。 AbortPolocy策略 当提交8个任务时，线程池正常处理完8个任务。当提交9个任务时，线程池也正常处理完9个任务。当提交10个任务，超过最大容量9时AbortPolocy拒绝策略则会直接抛出RejectedExecutionException异常 剩下的3个我们只看拒绝策略的效果(即使用10个线程i&lt;10)时的效果 CallerRunsPolicy 任务回退拒绝策略可以看到当提交10个任务超过最大容量9时CallerRunsPolicy拒绝策略则会自己执行9个任务，多出的任务回退给调用者，我们上面的代码中是main线程，所以是main线程执行多出的任务。 DiscardOldestPolicy 丢弃最久拒绝策略 可以看到当提交10个任务超过最大容量9时DiscardOldestPolicy拒绝策略则会执行9个任务，丢弃掉等待最久的任务。 DiscardPolicy 直接丢弃拒绝策略 可以看到当提交10个任务超过最大容量9时DiscardPolicy拒绝策略则会执行9个任务，直接丢弃新的任务。 自定义线程池参数设置 上面我们写的自定义线程池中的参数都是自己随便设置的，实际生产中对于参数的设置是有要求的，那么如何设置一个合理的参数呢？(这里最重要的也是最大线程数即maximumPoolSize)，这里就先讲下这个参数怎么配 首先通过Runtime.getRuntime().availableProcessors()获得设备的CPU数。 其次分析任务特性，可以从以下几个角度来分析。 任务的性质：CPU密集型任务、IO密集型任务和混合型任务。 任务的优先级：高、中和低。 任务的执行时间：长、中和短。 任务的依赖性：是否依赖其他系统资源，如数据库连接。 CPU密集型任务:指的是该任务需要大量的运算，而没有阻塞，CPU一直全速运行 IO密集型任务:该任务需要大量IO，即大量的阻塞。IO密集型任务并不是一直在执行任务，则应配置尽可能多的线程 混合密集型任务：可以拆分成一个CPU密集型任务和一个IO密集型任务，只要这两个任务执行的时间相差不是太大。如果这两个任务执行时间相差太大，则没必要进行分解。 配置合理参数 CPU密集型任务配置为CPU核数+1，比如8核CPU则应配置最大线程数为8+1=9个 IO密集型任务配置为2*CPU核数 或 CPU核数/(1-阻塞因子) 阻塞因子为0.8~0.9。 比如对于8核CPU则应配置最大线程数为2*8=16个或者8/(1-0.9)=80个。","link":"/2020/03/31/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"title":"leetcode-database题解","text":"主要内容leetcode中关于sql的语法练习题。leetcode SQL练习地址 175.Combine Two Tables12345# 注意下面要求没有地址的个人信息也要显示所以要使用左外联结SELECT p.FirstName,p.LastName,a.City,a.StateFROM Person AS pLEFT JOIN Address AS aON p.PersonId = a.PersonId; 176. Second Highest Salary1234567# 为了没有数据时返回null，则多加一层SELECT子查询SELECT ( SELECT DISTINCT Salary FROM Employee Order BY Salary DESC LIMIT 1,1) AS SecondHighestSalary; 177. Nth Highest Salary上面176题的扩展 12345678CREATE FUNCTION getNthHighestSalary(N INT) RETURNS INTBEGINSET N = N-1; -- 使用SET设置参数值 RETURN ( SELECT (SELECT DISTINCT Salary FROM Employee ORDER BY Salary DESC LIMIT N,1) );END 178. Rank Scores123456SELECT s1.Score, COUNT(DISTINCT s2.Score) RankFROM Scores s1INNER JOIN Scores s2ON s1.Score &lt;= s2.ScoreGROUP BY s1.IdORDER BY s1.Score DESC 180. Consecutive Numbers1234567SELECT DISTINCT l1.Num ConsecutiveNumsFROM Logs l1INNER JOIN Logs l2ON l1.Id+1 = l2.IdINNER JOIN Logs l3ON l2.Id +1 = l3.IdWHERE l1.Num = l2.Num AND l2.Num = l3.Num; 181. Employees Earning More Than Their Managers对于筛选条件是放在on后面还是使用where子句：先执行 ON，后执行 WHERE；ON 是建立关联关系，WHERE 是对关联关系的筛选。参考链接 https://www.jianshu.com/p/d923cf8ae25f 12345SELECT e1.Name AS EmployeeFROM Employee e1INNER JOIN Employee e2ON e1.ManagerId = e2.idWHERE e1.Salary &gt; e2.Salary; 182. Duplicate Emails12345-- GROUP BY之后使用HAVINGSELECT EmailFROM PersonGROUP BY EmailHAVING COUNT(Email) &gt; 1; 183. Customers Who Never Order12345SELECT c.Name AS CustomersFROM Customers AS cLEFT JOIN Orders AS oON c.Id = o.CustomerIdWHERE o.CustomerId IS NULL; 184. Department Highest Salary123456789101112131415161718# 开始是这样写的，问题在于最大值有两个或两个以上时，只会显示一个，因为使用了聚合函数。-- SELECT d.Name AS Department,e.Name AS Employee,MAX(e.Salary)-- FROM Employee AS e-- INNER JOIN Department AS d-- ON e.DepartmentId = d.Id-- GROUP BY e.DepartmentId;# 正确做法SELECT d.Name AS Department,e.Name AS Employee,e.SalaryFROM Department AS dINNER JOIN Employee AS eON d.Id = e.DepartmentIdINNER JOIN ( SELECT DepartmentId,MAX(Salary) AS Salary FROM Employee GROUP BY DepartmentId) AS m ON e.Salary = m.SalaryWHERE e.DepartmentId = m.DepartmentId; 196. Delete Duplicate Emails12345-- delete也可以使用联结DELETE p1 FROM Person p1 INNER JOIN Person p2ON p1.Email = p2.Email WHERE p1.Id &gt; p2.Id; 197. Rising Temperature123456-- TO_DAYS()函数返回一个从年份0开始的天数SELECT w2.IdFROM Weather w2INNER JOIN Weather w1ON TO_DAYS(w2.RecordDate) - TO_DAYS(w1.RecordDate) = 1WHERE w2.Temperature &gt; w1.Temperature; 595. Big Countries123SELECT name,population,areaFROM WorldWHERE area &gt; 3000000 OR population &gt; 25000000; 596. Classes More Than 5 Students12345-- DISTINCT去重SELECT DISTINCT classFROM coursesGROUP BY classHAVING count(DISTINCT student)&gt;=5; 620. Not Boring Movies1234SELECT *FROM cinemaWHERE id%2 != 0 AND description != 'boring'ORDER BY rating DESC; 626. Exchange Seats123456789-- 完整case函数SELECTCASEWHEN id = (SELECT MAX(id) FROM seat) AND id %2=1 THEN idWHEN id%2=0 THEN id -1WHEN id%2 = 1 THEN id +1END AS id, studentFROM seatORDER BY id; 627. Swap Salary1234567-- 简单case函数UPDATE salarySET sex = CASEWHEN sex = 'm' THEN 'f' ELSE 'm'END;","link":"/2020/04/08/leetcode-database%E9%A2%98%E8%A7%A3/"},{"title":"Java并发工具类CountDownLatch、CyclicBarrier、Semaphore","text":"主要内容 CountDownLatch(闩锁) CyclicBarrier(屏障) Semaphore(信号量) JDK1.5之后Java为我们提供了上面三个同步工具类。这几个工具类的目的就是为了能够更好的控制线程间的通信问题 CountDownLatch(闩锁) A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes. 作用:允许一个或多个线程等待其他线程完成操作。 常用的方法就两个await和countDown() 使用说明： 初始化CoutDownLatch的初始值count 需要等待的线程调用await()方法，await方法会一直阻塞直到count=0 其他的线程执行自己的操作，操作完成后调用countDown()方法使得count值-1。 123456789101112131415161718192021222324package com.company.MultiThread;import java.util.concurrent.CountDownLatch;public class CountDownLatchDemo { public static void main(String[] args) { CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 1; i &lt;= 6; i++) { new Thread(()-&gt;{ System.out.println(Thread.currentThread().getName()+\"号同学离开教室\"); countDownLatch.countDown(); },String.valueOf(i)).start(); } new Thread(()-&gt;{ try { countDownLatch.await(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+\"最后离开教室锁门\"); },\"coderchen33\").start(); }} 运行结果： 12345671号同学离开教室6号同学离开教室5号同学离开教室4号同学离开教室2号同学离开教室3号同学离开教室coderchen33最后离开教室锁门 反过来，让多个线程等待一个线程也是一样的： 123456789101112131415161718192021222324package com.company.MultiThread;import java.util.concurrent.CountDownLatch;public class CountDownLatchDemo { public static void main(String[] args) { CountDownLatch countDownLatch = new CountDownLatch(1); for (int i = 1; i &lt;= 6; i++) { new Thread(()-&gt;{ try { countDownLatch.await(); System.out.println(Thread.currentThread().getName()+\"出去玩\"); } catch (InterruptedException e) { e.printStackTrace(); } },String.valueOf(i)).start(); } new Thread(()-&gt;{ System.out.println(Thread.currentThread().getName()+\"离开教室了\"); countDownLatch.countDown(); },\"老师\").start(); }} 1234567老师离开教室了2出去玩3出去玩1出去玩6出去玩5出去玩4出去玩 CyclicBarrier(栅栏) A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point. CyclicBarriers are useful in programs involving a fixed sized party of threads that must occasionally wait for each other. The barrier is called cyclic because it can be re-used after the waiting threads are released. 作用：让一组线程相互等待以达到一个公共的障碍点(屏障)时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被平常拦截的线程才会继续运行。 1234567891011121314151617181920212223242526package com.company.MultiThread;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;public class CyclicBarrierDemo { public static void main(String[] args) { CyclicBarrier cyclicBarrier = new CyclicBarrier(7,()-&gt;{ System.out.println(\"召唤神龙\"); }); for (int i = 1; i &lt;= 7; i++) { final int tempI = i; new Thread(()-&gt;{ System.out.println(Thread.currentThread().getName()+\"收集到了第\"+tempI+\"颗龙珠\"); try { cyclicBarrier.await(); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } },String.valueOf(i)).start(); } }} 只有7个线程都到了屏障点，才打开屏障，召唤神龙。 123456781收集到了第1颗龙珠5收集到了第5颗龙珠3收集到了第3颗龙珠4收集到了第4颗龙珠2收集到了第2颗龙珠7收集到了第7颗龙珠6收集到了第6颗龙珠召唤神龙 Semaphore(信号量) A counting semaphore. Conceptually, a semaphore maintains a set of permits. Each acquire() blocks if necessary until a permit is available, and then takes it. Each release() adds a permit, potentially releasing a blocking acquirer. However, no actual permit objects are used; the Semaphore just keeps a count of the number available and acts accordingly. 作用：控制同时访问特定资源的线程数，它维护了一组许可证 当调用acquire()时会消费一个许可证。如果没有许可证了，线程会阻塞起来 当调用release()时会添加一个许可证。 这些许可证就是一个count变量 12345678910111213141516171819202122232425262728package com.company.MultiThread;import java.util.concurrent.Semaphore;import java.util.concurrent.TimeUnit;public class SemaphoreDemo { public static void main(String[] args) { Semaphore semaphore = new Semaphore(3); for (int i = 0; i &lt; 7; i++) { new Thread(()-&gt;{ try { //抢许可证 semaphore.acquire(); System.out.println(Thread.currentThread().getName()+\"抢到许可证了\"); //抢到了许可证,干3秒自己的活 TimeUnit.SECONDS.sleep(3); System.out.println(Thread.currentThread().getName()+\"干完活了，释放许可证\"); //释放许可证 semaphore.release(); } catch (InterruptedException e) { e.printStackTrace(); } },String.valueOf(i)).start(); } }} 12345678910111213140抢到许可证了1抢到许可证了2抢到许可证了1干完活了，释放许可证0干完活了，释放许可证2干完活了，释放许可证4抢到许可证了3抢到许可证了5抢到许可证了5干完活了，释放许可证3干完活了，释放许可证4干完活了，释放许可证6抢到许可证了6干完活了，释放许可证 源码分析等有时间再写吧，这里可以先参考这位大佬的文章: CountDownLatch源码分析 CyclicBarrier源码分析 Semaphore源码分析","link":"/2020/03/31/Java%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BBCountDownLatch%E3%80%81CyclicBarrier%E3%80%81Semaphore/"},{"title":"Lock锁的子类ReentrantLock和ReadWriteLock源码解析","text":"主要内容 ReentrantLock概述 ReentrantLock源码解析 ReentrantReadWriteLock读写锁使用 ReentrantReadWriteLock源码解析 上一篇已经学过AQS了，因此本篇主要是讲解Lock锁主要的两个子类是如何使用AQS实现相应的特性： ReentrantLock ReentrantReadWriteLock ReentrantLock概述我们这里还是看下它的顶部注释，总结下它的特点： 和synchronized一样都是互斥锁和可重入锁，但更加灵活。注意可重入锁也称为递归锁 可以调用isHeldByCurrentThread和getHoldCount方法判断当前线程是否拿到锁 可以在构造方法中使用true来让锁设置为公平锁,默认为非公平锁。但公平锁一般没有非公平锁效率高 同时也告诉了我们使用ReentrantLock的最标准方法 123456789101112131415class X { private final ReentrantLock lock = new ReentrantLock(); // ... public void m() { //try之前调用lock方法 lock.lock(); // block until condition holds try { // ... method body } finally { //finally中释放锁 lock.unlock() } }} 互斥锁和可重入锁之前已经提到过，这里介绍下公平锁和非公平锁： 公平锁 多个线程按照申请锁的顺序来获取锁 非公平锁 多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程有线获取锁。可能会造成优先级反转或者饥饿现象 ReentrantLock的用法已经在我的这篇文章中写了，这里就不提了。主要看看他底层是如何实现的。 ReentrantLock源码解析上面我们已经提到了，ReentrantLock实际上是由AQS实现的，我们接下来就看看ReentrantLock的源码。 Sync、NonfairSync、FairSync 因为ReentrantLock支持公平锁和非公平锁，所以它抽出了一个抽象类来继承AQS。 1private final Sync sync; 12345abstract static class Sync extends AbstractQueuedSynchronizer { abstract void lock(); //...} 可以看到，在Sync类中定义了一个抽象方法lock，该方法应当由继承它的子类来实现。它的子类实现则包括了我们上面提到的非公平锁和公平锁。其中，FairSync和NonfairSync的定义如下： 123static final class NonfairSync extends Sync { //实现方法先省略，下面讲} 123static final class FairSync extends Sync { //实现方法先省略，下面讲} 我们看一下ReentrantLock的构造方法，验证一下是不是这样。 123456789//默认为非公平锁public ReentrantLock() { sync = new NonfairSync();}//传入true可以使用公平锁public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync();} 可以看到ReerantLock中提供了两种构造方法，默认构造的是非公平锁，通过传入true可以使用公平锁。 非公平锁的lock()方法实现 首先我们先看下ReentrantLock的lock方法： 123public void lock() { sync.lock();} 可以看到lock()方法是调用了sync.lock()，从上面我们知道sync中的lock方法是抽象方法，具体实现是由公平锁和非公平锁自己实现的。 接下来我们就看看非公平锁的实现： 123456final void lock() { if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);} 可以看到实际上ReentrantLock的非公平锁就是调用了AQS的acquire(1)。acquire()方法我们在上一篇已经详细讲过了，这里就不再重复。我们知道AQS是基于模板方法模式的，acquire方法中需要调用tryAcquire方法，使用AQS实现锁只需要重写tryAcquire方法即可，我们看看ReentrantLock的非公平锁是如何重写tryAcquire方法的。 123protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires);} 从上面可以看到tryAcquire方法实际上是调用的nonfairTryAcquire方法： 1234567891011121314151617181920212223242526272829final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); //没有线程占有锁 if (c == 0) { //直接尝试占有锁，体现非公平锁 if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } //上面体现了是互斥锁 //下面体现了可重入锁 //到这里说明有线程占有锁 //判断占有锁的线程是不是就是自己 else if (current == getExclusiveOwnerThread()) { //是自己则可以再次获取锁 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); //将state+1 setState(nextc); return true; } return false;} 公平锁的lock()方法实现 知道了非公平锁，公平锁也就十分简单了。 123456789101112131415161718192021222324final void lock() { acquire(1);}protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { //和非公平锁唯一的不同在于需要先去判断是否有线程排在自己前面 体现公平锁 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; } return false;} 可以看到非公平锁和公平锁的实现基本相同，唯一的不同在于公平锁在抢锁时需要调用hasQueuedPredecessors方法先去判断是否有线程排在自己前面，而非公平锁是直接争锁，其他则完全一样。 unlock()方法 ReentrantLock的unlock()方法如下： 123public void unlock() { sync.release(1);} 可以看到非公平锁和公平锁使用的是都是AQS的release方法,同样我们看看ReentrantLock中tryRelease方法是如何重写的。 123456789101112131415protected final boolean tryRelease(int releases) { //state-1释放一次锁 int c = getState() - releases; //不是当前线程释放锁，则直接抛异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; //锁全部释放 if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free;} 可以看到tryRelease方法的实现也很简单, 总结 ReentrantLock的公平锁和非公平锁的lock方法实际上调用的是AQS中的acquire()方法，并且两种锁的tryAcquire方法的唯一不同在于公平锁需要判断前面是否有线程等待。 ReentrantLock的unlock()方法,实际上调用的是AQS的release()方法。 从上面可以看到AQS在并发编程中的地位。只要弄懂了它，我们在学习其他并发编程工具的时候就会容易很多。 ReentrantReadWriteLock读写锁概述 ReentrantReadWriteLock同样是位于J.U.C的子包locks包中，我们看下它的类结构图。 可以看到ReentrantReadWriteLock实现了ReadWriteLock接口。我们先看一下ReadWriteLock结口顶部的注释，总结下重点： ReadWriteLock维护一对关联的锁，一个用于只读操作(读锁)，一个用于写入操作(写锁)。 读锁是共享锁，写锁是独占锁。(读读高效 | 读写 写读 写写互斥) 获取到读锁的线程将看到在先前释放写锁时所做的所有更新。 与互斥锁相比，读写锁在对于共享数据的读操作时并发性更好。所以适用于读多于写的情况。 ReadWriteLock的接口的源码也非常简单: 1234public interface ReadWriteLock { Lock readLock(); Lock writeLock();} 知道了ReadWriteLock接口,我们再看下它的具体实现类ReentrantReadWriteLock，同样我们还是看下它的顶部注释，除了上面的特性外，ReentrantReadWriteLock还支持如下特性： 公平锁和非公平锁。和ReentrantLock一样，默认是非公平锁，同样可以通过加上true，使用公平锁。 可重入锁。支持重进入，以读写线程为例：读线程获取了读锁后能再次获取读锁。写线程在获取了写锁之后能再次获取写锁，同样也能再次获取读锁。 锁降级。写锁能够降级为读锁，读锁不能升级为写锁。写锁降级为读锁的方式： 1) 获得写锁 2) 获得读锁 3) 释放写锁 读写锁使用 最核心的用法就是在读操作时使用读锁，写操作时使用写锁。下面简单写一个缓存，用读写锁控制线程安全。缓存最基本的三个方法是get、put和clear 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package com.company.MultiThread;import java.util.HashMap;import java.util.Map;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantReadWriteLock;public class Cache { //HashMap非线程安全 private Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); //使用读写锁保证Cache是线程安全的 private ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock(); //获取key对应的value 正常应该返回Object，这里只打印演示效果 public void get(String key){ //读操作使用读锁,并发访问该方法不会被阻塞 rwLock.readLock().lock(); try { System.out.println(Thread.currentThread().getName()+\"正在读取\"); Object res = map.get(key); TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName()+\"读取到了\"+res); } catch (InterruptedException e) { e.printStackTrace(); } finally { rwLock.readLock().unlock(); } } //设置key对应的value,正常应该返回返回旧的value，这里只打印演示效果 public void put(String key,Object value){ //写操作使用写锁，其他线程均被阻塞 rwLock.writeLock().lock(); try { System.out.println(Thread.currentThread().getName()+\"正在写入\"+key); map.put(key,value); System.out.println(Thread.currentThread().getName()+\"写操作完成\"); } finally { rwLock.writeLock().unlock(); } }// //清空缓存中的所有内容// public void clear(){// wLock.lock();// try {// map.clear();// } finally {// wLock.unlock();// }// } public static void main(String[] args) { Cache cache = new Cache(); for (int i = 0; i &lt; 5; i++) { final int tempI = i; new Thread(()-&gt;{ cache.put(tempI+\"\",tempI); },String.valueOf(i)).start(); } for (int i = 0; i &lt; 5; i++) { final int tempI = i; new Thread(()-&gt;{ cache.get(tempI+\"\"); },String.valueOf(i)).start(); } }} 运行结果如下所示: 12345678910111213141516171819202122//可以看到写操作是独占锁，每次只能有一个线程进行写2正在写入22写操作完成1正在写入11写操作完成0正在写入00写操作完成4正在写入44写操作完成3正在写入33写操作完成//读操作是共享锁，5个线程都可以去读2正在读取3正在读取0正在读取4正在读取1正在读取1读取到了13读取到了30读取到了02读取到了24读取到了4 ReentrantReadWriteLock源码解析从下面的图中，可以看到ReentrantReadWriteLock中比ReentrantLock多了两个子类，就是我们ReentrantReadWriteLock中所维护的一对读锁和写锁。 Sync和ReentrantLock一样，也是继承了AQS,然后NonefairSync和FairSync分别继承Sync实现公平锁和非公平锁。这里就不再展开。我们主要看下我们的读锁ReadLock和写锁WriteLock是如何实现的。 锁的状态表示 之前的ReentrantLock是独占锁。所以state直接表示锁的状态即可。但是读写锁中有两把锁，如何只用state表示两种锁的状态呢？ReentrantReadWriteLock的源码中已经告诉了我们: 从上面可以看到是用锁的状态state(这里是c)的高16位表示读锁，低16位表示写锁。sharedCount返回的就是共享锁的数量，即读锁的数量，exclusiveCount返回的是互斥锁的数量，即写锁的数量。 写锁的lock方法 首先我们先看下写锁的源码部分： 12345678public static class WriteLock implements Lock, java.io.Serializable { private final Sync sync; protected WriteLock(ReentrantReadWriteLock lock) { sync = lock.sync; } public void lock() { sync.acquire(1);} 可以看到实际上WriteLock写锁的lock方法，实际上还是调用的AQS的acquire(1),同样调用acquire方法也说明了写锁是独占锁。接着我们看看它是如何实现tryAcquire()方法的。 12345678910111213141516171819202122232425262728protected final boolean tryAcquire(int acquires) { Thread current = Thread.currentThread(); //从上面锁的状态分析知道这里 //c为读锁和写锁的总状态 //w为写锁的状态 int c = getState(); int w = exclusiveCount(c); if (c != 0) { //读锁非0即其他线程正在读(写读互斥) //或者不是当前线程则失败 if (w == 0 || current != getExclusiveOwnerThread()) return false; //超过锁次数的最大限制2^16-1 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); //否则，拿到锁 setState(c + acquires); return true; } //到这里说明c=0,即没有锁 //直接通过CAS尝试占有锁 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true;} 写锁的unLock方法 123public void unlock() { sync.release(1);} 同样WriteLock写锁的unLock方法，实际上还是调用的AQS的`release(1)`,接着我们看看它是如何实现tryRelease()方法的。 12345678910111213protected final boolean tryRelease(int releases) { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int nextc = getState() - releases; //看写锁是否释放完(因为是可重入锁) boolean free = exclusiveCount(nextc) == 0; //释放完，则设置为无独占锁占用 if (free) setExclusiveOwnerThread(null); //否则则写锁状态-1 setState(nextc); return free;} 可以看到写锁的lock和unlock方法实际上还是比较简单的，我们接下来看下共享锁读锁的实现。 读锁的lock方法 123public void lock() { sync.acquireShared(1);} 这里可以看到实际上ReadLock读锁的lock方法，实际上是调用的AQS的acquireShared(1),同样调用acquireShared方法也说明了写锁是独占锁。接着我们看看它是如何实现tryAcquireShared()方法的。 12345678910111213141516171819202122232425262728293031323334protected final int tryAcquireShared(int unused) { Thread current = Thread.currentThread(); int c = getState(); //另一个线程持有写锁 则失败返回-1 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); //获取读锁 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) { //下面这些代码先不用管 //这里是为了方法getReadHoldCount方法写的，目的是返回当前线程获取读锁的次数 //因为读状态是所有线程的state，而每个线程各自获取读锁的次数是能保存在ThreadLocal中 if (r == 0) { firstReader = current; firstReaderHoldCount = 1; } else if (firstReader == current) { firstReaderHoldCount++; } else { HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; } //获取锁成功返回1 return 1; } //首次获取失败则重新尝试 return fullTryAcquireShared(current);} 这里我们只需要知道： 如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。 如果当前线程获取了写锁或者写锁未被获取，则当前线程通过CAS增加读状态，成功获取读锁。 读锁的unLock方法 123public void unlock() { sync.releaseShared(1);} 123456789101112131415161718192021222324252627282930protected final boolean tryReleaseShared(int unused) { Thread current = Thread.currentThread(); if (firstReader == current) { // assert firstReaderHoldCount &gt; 0; if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; } else { HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); int count = rh.count; if (count &lt;= 1) { readHolds.remove(); if (count &lt;= 0) throw unmatchedUnlockException(); } --rh.count; } //上面不用管 //CAS自旋 for (;;) { int c = getState(); //c-1 int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) return nextc == 0; }} 读写锁目前我也只能理解这么多了，不过最终还是要把AQS搞懂啊。。不说了，我再去看两遍AQS的源码。","link":"/2020/03/26/Lock%E9%94%81%E7%9A%84%E5%AD%90%E7%B1%BBReentrantLock%E5%92%8CReadWriteLock/"},{"title":"HTTP和HTTPS","text":"主要内容 HTTPS = HTTP + SSL/TSL HTTPS之混合加密 HTTPS之数字证书 HTTPS之摘要算法 HTTPS连接建立过程 HTTP的不足以及HTTPS的改进我们之前提到HTTP协议是不安全的，主要原因在于： 窃听风险 通信使用明文（不加密），内容可能会被窃听。比如，账号信息容易泄漏。 冒充风险 不验证通信方的身份，因此有可能遭遇伪装。比如，访问假的淘宝、拼多多。 篡改风险 无法证明报文的完整性，所以有可能已遭篡改。比如，网页上植入垃圾广告。 HTTPS在HTTP和TCP层加入了SSL/TLS协议来解决上述风险。 SSL(Secure Socket Layer)指安全套接层，发展到SSL3.0之后IETF对SSL3.0进行了标准化并添加了少数机制，之后更名为TLS1.0(Transport Layer Security 安全传输层协议)。 HTTP+加密+认证+完整性保护=HTTPS HTTPS解决方式： 混合加密的方式实现信息的机密性，解决了窃听的风险。 （加密） 将服务器公钥放入到数字证书中，解决了冒充的风险。 （认证） 摘要算法的方式来实现完整性，摘要算法用于校验数据的完整性，解决了篡改的风险。（完整性保护） 混合加密算法对称密钥加密对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。优点：运算速度快；缺点：无法安全地将密钥传输给通信方。 非对称密钥加密(公开密钥加密)非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥。 公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密。 非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确。 优点：可以更安全地将公开密钥传输给通信发送方；缺点：运算速度慢。 混合加密HTTPS结合了公开密钥安全和对称密钥运算速度快的优点，使用混合加密方式。 在通信建立前采用 非对称加密 的方式交换会话秘钥，后续就不再使用非对称加密。 在通信过程中全部使用对称加密的会话秘钥的方式加密明文数据 数字证书我们从上面知道客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。这里存在一个问题，如何保证公钥不被篡改和信任度？即无法证明公开密钥本身就是货真价实的公开密钥。 所以这里就需要借助第三方权威机构 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。 摘要算法 这部分参考文章硬核！30 张图解 HTTP 常见的面试题 摘要算法用来实现完整性，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，解决了篡改的风险。 客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的「指纹」和当前算出的「指纹」做比较，若「指纹」相同，说明数据是完整的。 HTTPS连接建立过程SSL/TLS 协议基本流程： 客户端向服务器索要并验证服务器的公钥。 双方协商生产「会话秘钥」。 双方采用「会话秘钥」进行加密通信。 前两步也就是 SSL/TLS 的建立过程，也就是握手阶段。 SSL/TLS 的「握手阶段」涉及四次通信，可见下图： SSL/TLS 协议建立的详细流程： ClientHello 首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。 在这一步，客户端主要向服务器发送以下信息： （1）客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。 （2）客户端生产的随机数（Client Random），后面用于生产「会话秘钥」。 （3）客户端支持的密码套件列表，如 RSA 加密算法。 SeverHello 服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello。服务器回应的内容有如下内容： （1）确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。 （2）服务器生产的随机数（Server Random），后面用于生产「会话秘钥」。 （3）确认的密码套件列表，如 RSA 加密算法。 （4）服务器的数字证书。 3.客户端回应 客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。 如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息： （1）一个随机数（pre-master key）。该随机数会被服务器公钥加密。 （2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。 （3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。 上面第一项的随机数是整个握手阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。 服务器的最后回应 服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发生最后的信息： （1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。 （2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。 至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。","link":"/2020/03/10/HTTP%E5%92%8CHTTPS/"},{"title":"索引和查询性能优化简介","text":"主要内容 查询性能优化简介 MySQL索引结构 创建高性能的索引策略 查询性能优化简介这里先整体提一下查询性能优化的结构，好让我们知道之后学习的内容是属于哪个层面的优化。 查询性能优化主要分为以下4个层面: 硬件优化 (硬件层面的优化，比如说增加内存等) 库表结构的优化 (库表结构设计的是否合理,比如是否符合范式等) 索引优化 (索引的建立是否合理高效) 查询优化 (SELECT语句如何写的准确高效) 上面提到的每一层设计或使用的不合理都会影响最终查询的性能，并且这几层从上到下都是层层递进的。 没有良好的硬件，即便我们把表结构、索引和SELECT语句都设计的十分完美都是无济于事的;同样有了良好的硬件，但是库表结构设计的不合理,就会影响我们索引和查询语句的建立和性能;硬件和库表结构设计的合理高效，但是索引建的很烂，最终效果也不会好;上面都建好了，但是我们最终写的SELECT语句很烂,比如在不必要的时候扫描全表等，也会使得查询性能下降。 硬件优化不是我们需要考虑的，库表结构优化和查询优化之后会详细讲。这里我们就看看对查询性能优化最有效的索引优化。 MySQL索引结构在MySQL中索引是在存储引擎层实现，而不是在服务器层。所以，不同的存储引擎的索引工作方式并不一样，也不是所有的存储引擎都支持所有类型的索引。接下来我们先看看MySQL支持的索引类型。 B+树索引 如上图，是一颗B+树，关于B+树的定义可以参考我数据结构里面树的文章，这里只说一些重点。浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。 B+树的查找过程如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的B+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。 B+树性质1.通过上面的分析，我们知道IO次数取决于B+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么B+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。 2.当B+树的数据项是复合的数据结构，比如(name,age,sex)的时候，B+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，B+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，B+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，B+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最佳左前缀法则，这个在之后索引优会详细介绍。 哈希索引哈希索引基于哈希表实现，只有精确匹配索引所有列的查询才有效。对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码，哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。 哈希索引结构如下： 从上面可以看到 哈希索引只包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行。 虽然无法避免读取行，但由于使用了hash，所以在hash冲突很少的情况下，仍然可以以O(1)的时间复杂度读取数据。 哈希索引不是按照索引值顺序存储的，所以无法用于排序(ORDER BY)与分组(GROUP BY) 因为哈希索引是使用索引列的全部内容来计算哈希值，索引不支持部分索引列匹配查找。例如（A,B）列建立索引，如果查询只用数据列A，则无法使用该索引。 只支持精确查找(= IN &lt;=&gt;)，无法用于部分查找和范围查找。 InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。这个是完全自动的、内部的行为，用户无法控制或者配置，不过如果有必要，完全可以关闭这个功能。 全文索引全文索引用于查找文本中的关键词，而不是直接比较是否相等，类似于搜索引擎做的事情。 MyISAM引擎支持全文索引，InnoDB 引擎在5.6.4版本后也开始支持全文索引。 实际上全文索引很少用，我们知道全文索引类似于搜索引擎做的事情，而目前搜索引擎的方案又十分成熟，所以大部分情况下我们使用存储引擎如elasticsearch等而不是全文索引。 空间数据索引(R-Tree)MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。 必须使用 GIS 相关的函数来维护数据。 这个索引也很少使用 InnoDB引擎和MyISAM引擎使用的索引InnoDB引擎使用的索引 以下内容主要来自一篇文章，如果看我解释的不清楚的话，可以去看原文 聚簇索引 聚簇索引并不是一种单独的索引类型，而是一种数据存储的方式。它是指将实际的数据行和索引放到了一块，并且索引结构的叶子节点保存了实际的数据行。因为无法把数据行同时存放在两个地方，所以一个表只能有一个聚簇索引。 上图即为InnoDB引擎中的聚簇索引，它是在同一个结构中保存了B+树索引和实际数据行，体现在两个方面： 1.使用记录 主键 值的大小进行记录和页的排序，这包括三个方面的含义： 页内的记录是按照主键的大小顺序排成一个单向链表。 各个存放用户记录的页也是根据页中记录的主键大小顺序排成一个双向链表。 各个存放目录项的页也是根据页中记录的主键大小顺序排成一个双向链表。 2.B+树的叶子节点存储的是实际的完整的数据行。 从上面知道，InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键，如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。 二级索引(辅助索引)上边介绍的聚簇索引只能在搜索条件是主键值时才能发挥作用，因为B+树中的数据都是按照主键进行排序的。那如果我们想以别的列作为搜索条件该咋办呢？只能从头到尾沿着链表依次遍历记录么? 答案是否定的，不然如果不能快速查找和排序我们还建索引干什么玩意儿。 实际上，我们每新建一个索引就会新建一棵B+树，不同的B+树中的数据采用不同的排序规则。比方说我们在非主键列c2列新建一个索引，则会新建一棵B+树，效果如下图所示： 这个B+树与上边介绍的聚簇索引有几处不同： 1.使用记录 c2列 的大小进行记录和页的排序，这包括三个方面的含义： 页内的记录是按照c2列的大小顺序排成一个单向链表。 各个存放用户记录的页也是根据页中记录的c2列大小顺序排成一个双向链表。 各个存放目录项的页也是根据页中记录的c2列大小顺序排成一个双向链表。 2.B+树的叶子节点存储的并不是完整的用户记录，而只是 c2列+主键 这两个列的值。 3.目录项记录中不再是 主键+页号 的搭配，而变成了 c2列+页号 的搭配。 所以如果我们现在想通过c2列的值查找某些记录的话就可以使用我们刚刚建好的这个B+树了。和上面的步骤一样，从根页面根据c2列的值找到叶子页面后，叶子页面中存储的数据是c2和c1（也就是主键）两个列，所以 我们必须再根据主键值去聚簇索引中再查找一遍完整的用户记录 。 我们根据这个以c2列大小排序的B+树只能确定我们要查找记录的主键值，所以如果我们想根据c2列的值查找到完整的用户记录的话，仍然需要到聚簇索引中再查一遍，这个过程也被称为回表。也就是根据c2列的值查询一条完整的用户记录需要使用到2棵B+树！！！ 上面介绍的是单一索引，实际上更常用的是复合索引。我们知道建立复合索引(c2,c3)后，对记录先是根据c2进行排序，c2相同时再根据c3排序，反映到B+树上，则如下图所示: 如图所示，我们需要注意一下几点： 每条目录项记录都由c2、c3、页号这三个部分组成，各条记录先按照c2列的值进行排序，如果记录的c2列相同，则按照c3列的值进行排序。 B+树叶子节点处的用户记录由c2、c3和主键c1列组成。 MyISAM引擎使用的索引MyISAM的索引方案虽然也使用B+树，但是和InnoDB不同的是在MyISAM中是将索引和数据分开存储。 将表中的记录按照插入时间 顺序 的存储在一块存储空间上，我们可以通过 行号 而快速访问到一条记录。如图所示： 由于在插入数据的时候并没有刻意按照主键大小排序，所以我们并不能在这些数据上使用二分法进行查找。 1.MyISAM会单独为表的主键创建一个B+树索引，只不过在B+树的叶子节点中存储的不是完整的用户记录，而是 主键值 + 行号 的组合。也就是先通过索引找到对应的行号，再通过行号去找对应的记录！ 这一点和InnoDB是完全不相同的，在InnoDB存储引擎中，我们只需要根据主键值对聚簇索引进行一次查找能找到对应的记录，而在MyISAM中却需要进行一次回表操作，意味着 MyISAM中建立的索引全部都是二级索引！ 2.如果有需要的话，我们也可以对其它的列分别建立索引或者建立联合索引，原理和InnoDB中的索引是一样的，只不过在叶子节点处存储的是相应的 列 + 行号 而已。这些索引也全部都是二级索引。 由于索引树是独立的，通过辅助键检索无需访问主键的索引树，即不用回表。 InnoDB引擎和MyISAM引擎的对比相同点: MyISAM和InnoDB引擎使用的都是B+树索引。 不同点: InnoDB引擎是聚簇索引+二级索引，而MyISAM引擎使用的都是二级索引。具体而言体现在： InnoDB引擎将B+树索引和实际的数据行存放在一起，实现索引即数据。 而MyISAM引擎中B+树索引和实际的数据行分开。 InnoDB引擎数据的物理存放顺序与索引顺序是一致的，即有序。而MyISAM表中的记录按照插入时间顺序的存储在一块存储空间上，是无序的。 InnoDB引擎中页节点存放的是主键+实际数据行，而MyISAM引擎中存放的是主键+行号。 如果根据主键查询数据InnoDB引擎可以直接从索引中取到，如果从二级索引中查询时需要进行回表。 而MyISAM引擎中不需要进行回表。所以如果表是只读表，则MyISAM的效率会比InnoDB高 索引的优点和缺点因为我们平时绝大部分时候使用的是InnoDB引擎的B+树结构的索引，并且我们上面知道了B+树的结构，这里也就能更好的的理解索引的优点和缺点了： 索引的优点： 索引大大减小了服务器需要扫描的数据行数 (索引中存储了实际的数据) 索引可以帮助服务器避免排序和分组，以及创建临时表(B+树索引是有序的，所以可以使用ORDER BY和GROUP BY进行排序和分组操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表) 将随机I/O变为顺序I/O (B+树索引是有序的，会将相邻的数据存储在一起) 索引的缺点 索引保存了主键和索引字段的真实数据，所以索引列也是要占用空间的。 虽然索引大大提高了查询速度，但同时会降低更新表的速度，如对表的INSERT、UPDATE和DELETE。因为更新表时,MySQL不仅要保存数据，还要保存索引文件每次更新添加了索引列的字段。 如果MySQL中有大数据量的表，需要花费一定的时间建立优秀的索引。","link":"/2020/04/10/%E7%B4%A2%E5%BC%95%E5%92%8C%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%AE%80%E4%BB%8B/"},{"title":"SQL基本语法(一) 增删改查","text":"主要内容 查询数据SELECT 插入数据INSERT 修改数据UPDATE 删除数据DELET 二维表创建与维护 查询数据SELECT基本查询1234# select基本使用SELECT prod_name FROM products -- 查询单列SELECT prod_id,prod_name,prod_price FROM products -- 查询多列SELECT * FROM products -- 查询所有列，由于速度较慢一般不使用 DISTINCT去重和LIMIT分页123456789######### DISTINCT去重SELECT vend_id FROM products SELECT DISTINCT vend_id FROM products######### LIMIT分页SELECT prod_name FROM products LIMIT 5 -- 查询表的前5行(注意开始是0行)SELECT prod_name FROM products LIMIT 5,5 -- 第5行开始,返回5行数据SELECT prod_name FROM products LIMIT 3,4 -- 第3行开始,返回4行数据SELECT prod_name FROM products LIMIT 4 OFFSET 3 -- 第3行开始,返回4行数据 排序数据ORDER BYASC 升序 DESC降序 不指明默认升序 123456789# 按单列排序SELECT prod_name FROM products ORDER BY prod_name# 按多列排序(先按第一个字段名，再按第二个字段名)SELECT * FROM products ORDER BY prod_price DESC,prod_name -- 价格降序，名字升序SELECT prod_id,prod_name,prod_price FROM products ORDER BY 3,2; --先按第三列排序后按第二列排序# 可以根据不显示的列排序SELECT prod_name FROM products ORDER BY prod_price 过滤数据WHERE 单条件过滤= &lt;&gt;或!= &lt; &lt;= &gt; &gt;= BETWEEN 多条件过滤AND OR IN NOT 通配符(% _)过滤数据LIKE 正则表达式过滤数据REGEXP 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# 单条件过滤 = &lt;&gt;或!= &lt; &lt;= &gt; &gt;= BETWEENSELECT * FROM products WHERE prod_price &gt; 10SELECT prod_id,prod_price FROM products WHERE prod_price &lt;&gt; 3.49;SELECT * FROM products WHERE prod_price BETWEEN 5 AND 10 --价格在5-10之间-- ORDER BY 位于 WHERE 之后，否则将会产生错误SELECT * FROM products WHERE prod_price &gt; 10 ORDER BY prod_name ----------------------------------------------------------------------------# 多条件过滤AND OR IN NOT###注意：AND运算优先级高于OR 所以一般是使用()SELECT * FROM products WHERE prod_price &gt; 10 AND vend_id = 1005-- 可以包含任意数目的AND和ORSELECT * FROM products WHERE prod_price &gt; 10 AND vend_id = 1005 AND prod_id = 'JP1000' SELECT * FROM products WHERE vend_id = 1002 OR vend_id = 1003-- AND的优先级高于OR，一般使用()来明确SELECT * FROM products WHERE prod_price &gt; 10 AND (vend_id = 1002 OR vend_id = 1003)SELECT * FROM products WHERE vend_id IN(1002,1003)-- NOT 否定跟在它之后的条件SELECT * FROM products WHERE NOT prod_price &gt; 10 -- MySQL中NOT对IN 、 BETWEEN 和EXISTS子句取反SELECT * FROM products WHERE vend_id NOT IN(1002,1003) --判断email是否为空SELECT cust_id,cust_email from customers WHERE cust_email IS NULL ---------------------------------------------------------------------------------# 通配符(% _)过滤数据LIKE#### 注意只能用于文本字段，非文本字段不能使用通配符匹配#### 使用通配符查询一般时间较长，所以不要过度使用通配符-- %表示任何字符出现任意次数SELECT * FROM products WHERE prod_name LIKE 'Jet%' -- 产品名称以Jet开头SELECT * FROM products WHERE prod_name LIKE '%Jet' -- 产品名称以Jet结尾SELECT * FROM products WHERE prod_name LIKE '%Jet%' -- 产品名称包含Jet的SELECT * FROM products WHERE prod_name LIKE 's%e' -- 产品名称以s开头，以e结尾-- _匹配单个任意字符SELECT * FROM products WHERE prod_name LIKE '_ ton anvil' -- ton anvil前只能有一个字符## 正则表达式过滤数据REGEXP### REGEXP和LIKE的区别在于LIKE必须使用通配符，否则就是直接找这个值，没有就返回NULLSELECT prod_name FROM products WHERE prod_name REGEXP '.000'SELECT prod_name FROM products WHERE prod_name LIKE '1000' -- 返回null SELECT prod_name FROM products WHERE prod_name REGEXP '1000|2000' -- 1000或2000SELECT prod_name FROM products WHERE prod_name REGEXP '[123] Ton' -- 1或2或3SELECT prod_name FROM products WHERE prod_name REGEXP '[^123] Ton' -- 非1 2 3SELECT prod_name FROM products WHERE prod_name REGEXP '[1-3] Ton' -- 1-3的范围内匹配SELECT prod_name FROM products WHERE prod_name REGEXP '\\\\.' -- 特殊字符使用\\\\转义SELECT prod_name FROM products WHERE prod_name REGEXP '[0-9]{4}' -- 其他正则表达式同理 创建计算字段和拼接CONCAT 计算字段+ - * / CONCAT拼接后通常使用AS指定别名，AS可省略 1234567891011# 拼接字段CONCATSELECT CONCAT(vend_name,'(',vend_country,')') FROM vendors -- 此时列名为CONCAT(vend_name,'(',vend_country,')')SELECT CONCAT(vend_name,'(',vend_country,')') AS 'vend_title' FROM vendors -- 使用别名后为vend_titleSELECT CONCAT(vend_name,'(',vend_country,')') 'vend_title' FROM vendors -- AS可省略# 计算字段 + - * /SELECT prod_id,quantity,item_price,quantity*item_price AS expanded_price FROM orderitems -- 列使用*计算并使用别名# SELECT还支持数据查询SELECT 2*3 #2*3 6SELECT NOW() #显示系统当前时间 数据处理函数数据处理函数 作用于列，主要分为普通函数和聚集函数。 普通函数： 文本处理函数 日期和时间处理函数 数值处理函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 文本处理函数-- Lower() 将串转换为小写-- Upper() 将串转换为大写-- Length() 返回串的长度-- LTrim() 去掉串左边的空格-- RTrim() 去掉串右边的空格-- Left() 返回串左边的字符-- Right() 返回串右边的字符-- Locate() 找出串的一个子串-- Soundex() 返回串的SOUNDEX值-- SubStr() 返回子串的字符SELECT vend_name,UPPER(vend_name) AS 'vendup_name' FROM vendors -- vend_name列返回大写SELECT vend_name,LENGTH(vend_name) AS 'vendname_len' FROM vendors -- vend_name列数据长度SELECT vend_name,SUBSTR(vend_name FROM 1 FOR 5)AS 'vendname_len' FROM vendors -- 子串# 日期和时间处理函数-- AddDate() 增加一个日期（天、周等）-- AddTime() 增加一个时间（时、分等）-- CurDate() 返回当前日期-- CurTime() 返回当前时间-- Date() 返回日期时间的日期部分-- DateDiff() 计算两个日期之差-- Date_Add() 高度灵活的日期运算函数-- Date_Format() 返回一个格式化的日期或时间串-- Day() 返回一个日期的天数部分-- DayOfWeek() 对于一个日期，返回对应的星期几-- Hour() 返回一个时间的小时部分-- Minute() 返回一个时间的分钟部分-- Month() 返回一个日期的月份部分-- Now() 返回当前日期和时间-- Second() 返回一个时间的秒部分-- Time() 返回一个日期时间的时间部分-- Year() 返回一个日期的年份部分SELECT * FROM orders WHERE MONTH(order_date) = '09'SELECT NOW() -- 返回系统当前时间# 数值处理函数-- Abs() 返回一个数的绝对值-- Cos() 返回一个角度的余弦-- Exp() 返回一个数的指数值-- Mod() 返回除操作的余数-- Pi() 返回圆周率-- Rand() 返回一个随机数-- Sin() 返回一个角度的正弦-- Sqrt() 返回一个数的平方根-- Tan() 返回一个角度的正切SELECT ABS(-1) -- 1 聚集函数 函 数 说 明 AVG() 返回某列的平均值 COUNT() 返回某列的行数 MAX() 返回某列的最大值 MIN() 返回某列的最小值 SUM() 返回某列值之和 注意： 因为汇总函数结果只有一行，所以不能和其他字段名一块使用，但可以几个汇总函数一块使用(因为都是一行) AVG()和COUNT()会忽略NULL行 WHERE子句中不允许出现汇总函数 1234567891011121314151617181920212223SELECT AVG(prod_price) AS avg_price FROM products; -- 平均值SELECT MAX(prod_price) AS max_price FROM products; -- 最大值SELECT MIN(prod_price) AS max_price FROM products; -- 最小值-- 可以用COUNTT(*)用来计算行数SELECT COUNT(*) AS prod_count FROM products;SELECT SUM(quantity) AS sum_quatity FROM orderitems; -- 求和SELECT SUM(quantity*item_price) AS sum_money FROM orderitems; -- 求计算式的和-- AVG() COUNT() SUM()可以使用DISTINCT进行去重,MAX()和MIN()去重没有意义SELECT AVG(DISTINCT prod_price) AS avg_price FROM products;-- 5个函数可以一块使用SELECT COUNT(*) AS num_items, MIN(prod_price) AS price_min, MAX(prod_price) AS price_maxFROM products 分组数据GROUP BY 使用了GROUP BY进行分组后,SELECT语句中只允许出现分组字段和多行函数 如果是多字段分组，先按第一字段进行分组，后按照第二字段进行分组，依次类推 使用GROUP BY之后，筛选使用HAVING关键字。一定记清楚HAVING是对分组后进行筛选，WHERE是分组前对字段进行筛选 12345678910-- 查询不同供应商提供的产品总数SELECT vend_id,COUNT(*) FROM products GROUP BY vend_id;-- 查询不同供应商提供的不同价格的产品总数-- 先按第一个字段分组，再按第二个字段分组SELECT vend_id,prod_price,COUNT(*) AS prodtotal FROM products GROUP BY vend_id,prod_price;-- 分组后使用HAVING-- 查询不同供应商提供的产品总数&gt;1的信息SELECT vend_id,prod_price,COUNT(*) AS prodtotal FROM products GROUP BY vend_id,prod_price HAVING prodtotal&gt;1; 子查询 当查询条件不明确时，考虑使用子查询。这里的不明确是指没有具体的数值，需要经过一次或多次查询后才能获得的数值。 因为要进行比较，所以作为子查询的SELECT语句只能查询单个列，查询多个列时会出错。 单列返回多条结果，使用ALL ANY IN处理 1234567891011121314151617181920-- 查询比平均价格高的商品信息SELECT * FROM products WHERE prod_price &gt; (SELECT AVG(DISTINCT prod_price) FROM products);# ALL ANY IN-- 查询产品价格高于1001提供的所有产品信息(&gt;1001提供产品的最大值的产品信息)SELECT * FROM productsWHERE prod_price &gt; ALL(SELECT prod_price FROM products WHERE vend_id = '1001');-- 查询产品价格高于1001提供的任意产品信息(&gt;1001提供产品的最小值的产品信息)SELECT * FROM productsWHERE prod_price &gt; ANY(SELECT prod_price FROM products WHERE vend_id = '1001');-- 查询产品价格与1001提供的产品价格相同且低于4的产品信息SELECT * FROM productsWHERE prod_price IN (SELECT prod_price FROM products WHERE vend_id = '1001') AND prod_price&lt;4;# 子查询还可以作为计算字段SELECT cust_name,cust_state,(SELECT COUNT(*) FROM orders WHERE orders.cust_id = customers.cust_id) AS orders FROM Customers ORDER BY cust_name; 多表联结查询当需要查询的信息位于多张表时，则需要使用多表联结查询 笛卡尔积 CROSS JOIN (CROSS可省略) 自然联结 NATURAL JOIN 内联结(等值联结) INNER JOIN 左外联结 LEFT JOIN，实际是省略了OUTER (LEFT OUTER JOIN) 右外联结 RIGHT JOIN，实际是省略了OUTER (RIGHT OUTER JOIN) 笛卡尔积笛卡尔积也称直积，两个集合X和Y的笛卡尓积表示为X × Y，第一个对象是X的成员而第二个对象是Y的所有可能有序对的其中一个成员。例如集合A={a, b}，集合B={0, 1, 2}，则两个集合的笛卡尔积为{(a, 0), (a, 1), (a, 2), (b, 0), (b, 1), (b, 2)}。 在数据库中即为将多个表中的数据进行一一对应，所得到的结果为多表的笛卡尔积，结果数量为所有表的数量乘积。 12-- vendors6条记录，products14条记录，总共查询出84条记录SELECT vend_name,prod_name FROM vendors CROSS JOIN products 自然联结底层先笛卡尔积，然后按照所有的 同名同值 的字段自动进行 等值筛选 12345-- products表和vendors表有同名同值的vend_id外键,所以会自动根据vend_id进行筛选SELECT vend_name,prod_name FROM vendorsNATURAL JOIN products; -- 如果有多个同名同值的字段，则会按照所有的同名同值字段进行等值筛选 内联结底层先笛卡尔积，然后筛选，筛选条件为等值筛选和自然联结不同的是内联结可以指定筛选条件和筛选字段 指定筛选字段是说：如果有两个或多个外键，但是只想按照部分字段进行筛选，使用 USING 关键字 12345-- 如果有两个或多个外键，但是只想按照部分字段进行筛选，使用USING关键字--这个例子不是很恰当，因为只有一个外键SELECT vend_name,prod_name FROM vendorsINNER JOIN products USING(vend_id); 上面的指定筛选字段还是需要两个表的供应商id表的名称均为vend_id,如果products表中为provend_id,vendors 表中为vend_id使用USING则无法指定，这时候使用 ON 可以更灵活的指定筛选条件 123456-- 指定不同名称筛选字段-- 使用ON自行指定时可以省略INNERSELECT v.vend_name,p.prod_nameFROM vendors AS vINNER JOIN products AS pON v.vend_id = p.provend_id; 如果上面的table1和table2是同一张表。例如一张员工表，包含员工编号、姓名、工作、工资、上级领导，其中员工中包含上级领导。这种也叫自联结 12345# 查询员工姓名，工作，工资及上级领导姓名SELECT e1.ename,e1.job,e1.sal, e2.enameFROM emp e1INNER JOIN emp e2ON e1.mgr=e2.empno; 外联结 许多联结将一个表中的行与另一个表中的行相关联，但有时候需要包含没有关联行的那些行,则需要使用外联结。外联结分为左外联结，右外联结以及全外联结。 这里我们新建两张表，更好的体现左外联结和右外联结的作用。 左外联结左外联结就是保留左表没有关联的行 为了更直观的说明问题，我们新建两个表如下所示： 1234SELECT s.stu_name,m.m_subject,m.m_gradeFROM student sLEFT JOIN mark mON s.stu_id = m.stu_id 左外联结运行结果如下所示，可以看到mark表中没有5号同学，但因为是左外联结，仍然保留了5号同学这行数据。 右外联结右外联结就是保留右表没有关联的行 1234SELECT s.stu_name,m.m_subject,m.m_gradeFROM student sRIGHT JOIN mark mON s.stu_id = m.stu_id 运行结果和左外联结类似，不过这里是保留右表没有关联的行即8号同学的数据。 组合查询 UNION 使用 UNION 来组合两个查询，如果第一个查询返回 M 行，第二个查询返回 N 行，那么组合查询的结果一般为 M+N 行。 每个查询必须包含相同的列、表达式和聚集函数。 默认会去除相同行，如果需要保留相同行，使用 UNION ALL。 只能包含一个 ORDER BY 子句，并且必须位于语句的最后。 12345678910111213141516171819202122232425-- 基本使用SELECT vend_id,prod_id,prod_priceFROM productsWHERE prod_price &lt;=5UNIONSELECT vend_id,prod_id,prod_priceFROM productsWHERE vend_id IN (1001,1002)-- 和下面效果一样SELECT vend_id,prod_id,prod_priceFROM productsWHERE prod_price &lt;=5 OR vend_id IN (1001,1002)-- 使用UNION完成全外联结-- 全外联结是指既保留左侧未关联行，又保留右侧未关联行SELECT s.*,subject,scoreFROM student s LEFT JOIN mark mON s.id=m.id UNION SELECT s.*,subject,scoreFROM student s RIGHT JOIN mark mON s.id=m.id; SELECT语句顺序123456789SELECT 内容 FROM 表名1 别名1INNER JOIN 表名2 别名2ON 连接条件INNER JOIN 表名3 别名3ON 连接条件WHERE 普通筛选条件GROUP BY 分组HAVING 多行函数筛选ORDER BY 排序 插入数据INSERT 插入指定列数据没有指定的列需要在创建表时指明初始值或者可以为null 12INSERT INTO customers(cust_id,cust_name,cust_address,cust_city,cust_state,cust_zip,cust_country)VALUES('1000000006','Toy Land','123 Any Street','New York','NY','11111','USA'); 全字段填充可以省略列名 12INSERT INTO customersVALUES('1000000006','Toy Land','123 Any Street','New York','NY','11111','USA',NULL,NULL); 插入检索出的数据 12345INSERT INTO customers(cust_id,cust_contact,cust_email,cust_name,cust_address,cust_city,cust_state,cust_zip,cust_country)SELECT id,contact,email,name,address,city,state,cust_zip,cust_countryFROM custNew; 从一个表复制到另一个表 12CREATE TABLE custcopySELECT * FROM customers; 修改数据UPDATE1234567891011# 修改顾客contact email和addressUPDATE customersSET cust_contact = 'Sam Roberts',cust_email = 'sam@toyland.com',cust_address = '123 street'WHERE cust_id = '1000000006';# NULL来删除某个数据，与''不同UPDATE customersSET cust_email = NULLWHERE cust_id = '1000000006'; 删除数据DELETE123# 删除ID=10000000006的客户DELETE FROM customersWHERE cust_id = '1000000006'; TRUNCATE TABLE 可以清空表，也就是删除所有行，但表结构仍然保留 1TRUNCATE TABLE mytable; 注意： 对于上面增删改的数据SQL语句执行完毕后，不会立马进行数据的写入。还需要手动对数据进行提交，如果数据有问题还可以回滚。但是在MYSQL中是默认提交的。 12345-- 查看是否是自动提交 ON表示开启自动提交 OFF表示关闭SHOW GLOBAL VARIABLES LIKE 'autocommit' -- ON-- 使用autocommit = 0关闭自动提交，autocommit = 1开启自动提交SET GLOBAL autocommit = 0;SHOW GLOBAL VARIABLES LIKE 'autocommit' -- OFF 使用更新和删除操作时一定要用 WHERE 子句，不然会把整张表的数据都破坏。可以先用 SELECT 语句进行测试，防止错误删除。 二维表的创建与维护二维表的创建123456789101112CREATE TABLE 表名( 字段名1 字段类型 约束条件, 字段名2 字段类型 约束条件, ......)CREATE TABLE student ( stu_id INT AUTO_INCREMENT, stu_name VARCHAR(50) NOT NULL, stu_age INT(3) DEFAULT 18, PRIMARY KEY(stu_id))ENGINE=InnoDB DEFAULT CHARSET=utf8; 字段类型 字符串类型 数值类型 日期和时间数据类型 二进制数据类型 放在这里以供参考 约束条件 主键约束 PRIMARY KEY 外键约束 FOREIGN KEY 非空约束 NOT NULL 唯一约束 UNIQUE 默认约束 DEFAULT 主键约束： 主键非空唯一，一般与AUTO_INCREMENT一块使用 每个表最多只允许一个主键，建立主键约束可以在列级别创建，也可以在表级别创建。 当创建主键的约束时，系统默认会在所在的列和列组合上建立对应的唯一索引。 12345678910111213141516171819202122232425262728293031# 基本模式CREATE TABLE temp ( t_id INT AUTO_INCREMENT, t_name VARCHAR (20), PRIMARY KEY(t_id));# 组合模式CREATE TABLE temp ( t_id INT(10), t_name VARCHAR (20), t_pwd VARCHAR (20), PRIMARY KEY (t_id,t_name));/*注意：组合模式不是设置了两个主键，而是几个字段组合起来作为一个主键比如学生选课系统：学生表student（sno，sname，……）课程表course（cno，cname，……）选课表sc（sno，cno，grade） 学生表的学号sno为主键，课程表的课程号cno为主键，而选课表是以（sno，cno）才能作为主键*/# 删除主键约束ALTER TABLE temp DROP PRIMARY KEY;# 添加主键约束ALTER TABLE temp ADD PRIMARY KEY (t_id, t_name);# 修改主键约束ALTER TABLE temp MODIFY t_id INT PRIMARY key; 外键约束当一张表的某个字段的值需要依赖另外一张表的某个字段的值，则使用外键约束其中主动依赖的表称为子表，被依赖的表称为父表。外键加在子表中 作用：当在子表中插入的数据在父表中不存在，则会自动报错 12345678910111213141516171819202122232425262728293031323334353637383940414243-- 基本模式-- 主表CREATE TABLE temp ( t_id INT AUTO_INCREMENT, t_name VARCHAR (20), PRIMARY KEY(t_id));-- 副表CREATE TABLE temp2 ( t2_id INT AUTO_INCREMENT, t_id INT NOT NULL, t2_name VARCHAR (20) NOT NULL, FOREIGN KEY (t_id) REFERENCES temp (t_id));-- 多列外键组合，必须用表级别约束语法-- 主表CREATE TABLE classes ( c_id INT, c_name VARCHAR (20), c_number INT, PRIMARY KEY (c_name, c_number));-- 副表CREATE TABLE student ( s_id INT auto_increment PRIMARY KEY, s_name VARCHAR (20), c_name VARCHAR (20), c_number INT, /*表级别联合外键*/ FOREIGN KEY (c_name,c_number) REFERENCES classes (c_name, c_number));-- 删除外键约束ALTER TABLE student DROP FOREIGN KEY s_id;-- 增加外键约束ALTER TABLE student ADD FOREIGN KEY ( c_name, c_number) REFERENCES classes (c_name, c_number); 非空约束 非空约束用于确保当前列的值不为空值，非空约束只能出现在表对象的列上。 Null类型特征：所有的类型的值都可以是null，包括int、float 等数据类型 123456789101112131415-- 创建table表，ID 为非空约束，name 为非空约束 且默认值为abcCREATE TABLE temp ( c_id INT(10) NOT NULL, c_name VARCHAR (50) NOT NULL DEFAULT 'abc', c_sex CHAR NULL) ;-- 增加非空约束ALTER TABLE temp c_MODIFY sex VARCHAR (2) NOT NULL;-- 取消非空约束ALTER TABLE temp MODIFY c_sex VARCHAR (2) NULL;-- 取消非空约束，增加默认值ALTER TABLE temp MODIFY c_sex VARCHAR (2) DEFAULT 'abc' NULL; 唯一约束 唯一约束是指定table的列或列组合不能重复，保证数据的唯一性。 唯一约束不允许出现重复的值，但是可以为多个null。 同一个表可以有多个唯一约束，多个列组合的约束。 12345678910111213141516-- 创建表时设置，表示用户名、密码不能重复CREATE TABLE temp ( t_id INT NOT NULL, t_name VARCHAR (20), t_pwd VARCHAR (10), UNIQUE (t_name, t_pwd));-- 添加唯一约束ALTER TABLE temp ADD UNIQUE (t_name, t_pwd);-- 修改唯一约束ALTER TABLE temp MODIFY t_name VARCHAR (25) UNIQUE;-- 删除约束ALTER TABLE temp DROP INDEX t_name; 默认约束 123456-- 名字默认为abcCREATE TABLE temp ( t_id INT NOT NULL, t_name VARCHAR (255) NOT NULL DEFAULT 'abc', t_sex CHAR NULL); 二维表维护 使用 ALTER 关键字 ADD 添加 , DROP 删除, MODIFY 修改(修改字段名使用 CHANGE ) 添加新的字段 12# 添加prod_haha字段ALTER TABLE products ADD prod_haha VARCHAR(10) NOT NULL; 修改原字段 12345# 修改字段名使用CHANGEALTER TABLE products CHANGE prod_haha prod_quatity VARCHAR(10);# 修改字段类型(COLUMN可省略)ALTER TABLE products MODIFY COLUMN prod_quatity VARCHAR(20); 删除原有字段 12# 删除原有字段(COLUMN可省略)ALTER TABLE products DROP COLUMN prod_quatity; 修改表名 1234#方式1ALTER TABLE orders RENAME TO orders2;#方式2RENAME TABLE orders2 TO orders; 删除二维表 1DROP TABLE custcopy;","link":"/2020/04/06/SQL%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E4%B9%8B%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"title":"EXPLAIN关键字详解","text":"主要内容 explain介绍 explain各个列的作用 参考MySQL官网 https://dev.mysql.com/doc/refman/5.7/en/explain-output.html 示例SQL EXPLAIN之前我们学习MySQL架构的时候知道，在第二层服务层中有一个查询优化器(Query Optimizer)用来对我们的SELECT语句进行优化，优化器选择执行最有效查询的一组操作称为查询执行计划。当使用explain时，MySQL就能告诉我们优化器对相关语句的执行计划的信息。 通过explain命令我们可以知道以下信息：表的读取顺序，数据读取操作的类型，哪些索引可以使用，哪些索引实际使用了，表之间的引用，每张表有多少行被优化器查询等信息。 简单来说就是:explain可以让我们知道select语句是如何执行的，是否用到了索引等信息，从而为我们之后优化select语句提供信息。 EXPLAIN的用法非常简单 EXPLAIN+SELECT语句 即可。 1explain select * from film where id = 1; 紧随其后，可以通过show warnings得到优化后的select语句(5.7之前需要使用explain extended + show warnings) 我们下面一一解释下上面explain结果中各个列的含义。 EXPLAIN中的列1. idSELECT的标识符，包含一组数字，有几个 select 就有几个id，用来表示查询中SELECT子句或操作表的顺序。 id相同，执行顺序从上之下 id不同，执行顺序从大到小 2. select_type1）simple：简单查询。不包含子查询和union 2）primary：复杂查询中最外层的 select 3）subquery：子查询中的第一个select 4）derived：包含在 from 子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表（derived的英文含义）奇怪的是在MySQL5.7中竟然只有一个SIMPLE，应该是mysql内部进行了优化。 5）union：在 union 中的第二个和随后的 select 6）union result : 从 union 临时表检索结果的 select 其他还有一些不常见的，这里就不解释了。想要详细看其他的可以参考MySQL官网。 3. table 这一列表示 explain 的一行正在访问哪个表。 当 from 子句中有子查询时，table列是 &lt;derivenN&gt; 格式，表示当前查询依赖 id=N 的查询，于是先执行 id=N 的查询。 当有 union 时，UNION RESULT 的 table 列的值为 &lt;union1,2&gt;，1和2表示参与 union 的 select 行id。 4. partitions显示分区表中的命中情况。非分区表，则该值为NULL 5. type该列称为关联类型或者访问类型，它指明了MySQL决定如何查找表中符合条件的行。这个字段直接反映我们的SQL性能是否高效，是我们优化要重点关注的字段。 依次从最优到最差分别为：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL 最常见的是：const &gt; eq_ref &gt; ref&gt; range &gt; index &gt; ALL NULL:MySQL能在优化阶段分解查询语句，在执行阶段不用再访问表或索引。 比如下面的在索引中选取最小值，可以单独查找索引来完成，不需要在执行时访问表 system和const 1.system：表只有一行记录，这个是const的特例，一般不会出现，可以忽略2.const：const用于比较主键索引或者唯一索引。因为只匹配一行数据，所以很快。 1234SELECT * FROM tbl_name WHERE primary_key=1;SELECT * FROM tbl_name WHERE primary_key_part1=1 AND primary_key_part2=2; eq_ref唯一性索引扫描，对于每个索引键，表中只有1条记录与之匹配。一般是两表关联，关联条件中的字段是主键或唯一索引。 123456SELECT * FROM ref_table tab1,other_table tab2ON tab1.key_column=tab2.column;SELECT * FROM ref_table tab1,other_table tab2ON tab1.key_column_part1=tab2.columnWHERE tab1.key_column_part2=1; ref非唯一性索引扫描，表中有多条记录与之匹配。本质上是一种索引访问，然而可能会找到多个符合条件的行，所以是索引和扫描的混合体。此类型通常出现在使用了非唯一或非主键索引或者使用了最左前缀规则索引的查询。 123456789SELECT * FROM ref_table WHERE key_column=expr;-- 这里和ref的不同在于联结会有多行SELECT * FROM ref_table tab1,other_table tab2ON tab1.key_column=tab2.column;SELECT * FROM ref_table tab1,other_table tab2ON tab1.key_column_part1=tab2.columnWHERE tab1.key_column_part2=1; 非主键索引和非唯一索引 关联表查询仅使用了film_actor的左前缀 ref_or_null类似ref，但是可以搜索值为NULL的行。 index_merge 表示使用了索引合并的优化方法。 range有检索范围的索引扫描范围扫描通常出现在 &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL,BETWEEN, LIKE,IN() 操作中。 index全索引扫描。与ALL差不多都是读全表，但通常比ALL快，因为索引文件通常比数据文件小。主要优点是避免了排序，但是开销仍然非常大。如果在 Extra 列看到 Using index，说明正在使用覆盖索引，只扫描索引的数据，它比按索引次序全表扫描的开销要少很多。 ALL 全表扫描以找到匹配的行。建议进行优化。 6. possible_keys这一列显示MySQL查询可能使用哪些索引来查找。 explain 时可能出现 possible_keys 有值，而 key 显示 NULL 的情况，这种情况是因为表中数据不多，mysql认为索引对此查询帮助不大，选择了全表查询。 如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查 where 子句看是否可以创造一个适当的索引来提高查询性能，然后用 explain 查看效果。 7. key这一列显示mysql实际采用哪个索引来优化对该表的访问。如果想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用 force index、ignore index。 8. key_len列这一列显示了MySQL在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列。 9. ref列显示了在key列记录的索引中，表查找值时哪一列被使用了。常见的有：const（常量），func，NULL，字段名（例:film.id），如果可能的话，是一个常数。 从下面可以看出是使用了reviewmysql数据库中的film表的id列来查找film_actor中的记录。 10. rows列这一列是MySQL认为查询要扫描的行数，注意这个不是结果集里的行数。 11. filtered列该列表示根据条件过滤的表行的估计百分比，和 rows 相乘，表示和查询计划里下一个表关联的行数。 12. Extra列这一列展示的是额外信息。常见的重要值如下： Using index：使用覆盖索引，表示查询索引就可查到所需数据，不用扫描表数据文件，往往说明性能不错。 Using Where：在存储引擎检索行后再进行过滤，使用了where从句来限制哪些行将与下一张表匹配或者是返回给用户。 Using filesort：对结果使用一个外部索引排序，而不是按索引次序从表里读取行，一般有出现该值，都建议优化去掉，因为这样的查询 CPU 资源消耗大。 因为actor中id建了索引，所以是using index，而name中没有建，则需要进行文件排序。 Using temporary：在查询结果排序时会使用一个临时表，一般出现于排序、分组和多表 join 的情况，查询效率不高，建议优化。 EXPLAIN总结从上面我们知道了explain各个列的作用，其中比较重要的有: id列 (id不同从大到小执行，id相同则顺序执行) type列 (效率：const &gt; eq_ref &gt; ref &gt; range &gt; index &gt;all) key列 (实际用到的索引) rows列 (MySQL的扫描行数) Extra列 (Using index、Using filesort、Using temporary、Using Where) 以上sql使用的表和数据： 123456789101112131415161718192021222324252627282930DROP TABLE IF EXISTS `actor`;CREATE TABLE `actor` ( `id` int(11) NOT NULL, `name` varchar(45) DEFAULT NULL, `update_time` datetime DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `actor` (`id`, `name`, `update_time`) VALUES (1,'a','2017-12-22 15:27:18'), (2,'b','2017-12-22 15:27:18'), (3,'c','2017-12-22 15:27:18');DROP TABLE IF EXISTS `film`;CREATE TABLE `film` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(10) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_name` (`name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `film` (`id`, `name`) VALUES (3,'film0'),(1,'film1'),(2,'film2');DROP TABLE IF EXISTS `film_actor`;CREATE TABLE `film_actor` ( `id` int(11) NOT NULL, `film_id` int(11) NOT NULL, `actor_id` int(11) NOT NULL, PRIMARY KEY (`id`), KEY `idx_film_actor_id` (`film_id`,`actor_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `film_actor` (`id`, `film_id`, `actor_id`) VALUES (1,1,1),(2,1,2),(3,2,1);","link":"/2020/04/11/EXPLAIN%E5%85%B3%E9%94%AE%E5%AD%97%E8%AF%A6%E8%A7%A3/"},{"title":"分布式MySQL","text":"","link":"/2020/04/23/%E5%88%86%E5%B8%83%E5%BC%8FMySQL/"},{"title":"深入理解MySQL","text":"主要内容 MySQL系统架构图 MyISAM引擎和InnoDB引擎 MySQL系统架构图和其他数据库相比，MySQL有点与众不同，它的架构可以在多种不同的场景中应用并发挥良好作用。主要体现在存储引擎的架构上。插件式的存储引擎架构将查询处理和其它的系统任务以及数据的存储提取相分离。这种架构可以根据业务的需求和实际需要选择合适的存储引擎。 下图为MySQL的逻辑架构图： 我们简要分析下每层的作用：支持接口是第三方语言对数据库的操作接口，比如Java的JDBC等，这里不再赘述。 (1)连接层 最上层的连接池是提供一些连接服务，包含本地socket通信和大多数基于C/S工具实现的类似于TCP/IP的通信。我们常用的c3p0和druid连接池就是这一层的。连接池主要完成一些类似于连接处理、授权认证及相关的安全方案。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全连接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。 (2)服务层 第二层架构主要完成大多数的核心服务功能，如SQL接口、缓存的查询、SQL的分析和优化、内置函数等。所有跨存储引擎的功能也在这一层实现，如存储过程、触发器、视图等。在该层，服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化如确定查询表的顺序，是否利用索引等，最后生成相应的执行操作。如果是select语句，服务器还会查询内部的缓存，如果缓存空间足够大，这样在频繁读操作的环境中能够很好的提升系统的性能。 (3)引擎层 存储引擎真正的负责MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信，不同的存储引擎具有的特性不同，我们可以根据实际需进行选取。MySQL中支持10多种的存储引擎，比较常用的就是MyISAM和InnoDB。下文会做具体介绍。 (4)存储层数据存储层，主要是将数据存储在物理机的文件系统，并完成与存储引擎的交互。 MySQL存储引擎MySQL中支持10多种的存储引擎，比较常用的就是MyISAM和InnoDB。MySQL在5.1版本之前默认存储引擎为MyISAM，在此版本之后默认为InnoDB。 可以使用如下命令查看MySQL中默认安装的存储引擎 1SHOW ENGINES; 使用如下命令查看正在使用的存储引擎 1SHOW VARIABLES LIKE '%storage_engine%'; 可以看到，我们正在使用的是InnoDB引擎 接下来我们就对比下我们常用的两个存储引擎InnoDB引擎和MyISAM引擎。 InnoDB引擎和MyISAM引擎对比这里把两种最常用的存储引擎基本的提点通过表格的形式对比如下: 除了上面常用的两种存储引擎外，MySQL中还有一些特殊用途的存储引擎，比如只支持INSERT和SELECT的Archive引擎等，这里就不再赘述，有需要可以去官网查看文档。 另外MySQL从2007年开始提供了插件式的存储引擎API，所以出现了很多第三方存储引擎，如InnoDB的改进版Percona等。 如何选择存储引擎从上面我们知道，MySQL中的存储引擎有非常多，那么如何选择适合业务需求的存储引擎呢? 主要从以下几方面考虑: 使用场景是否需要事务支持； 是否需要支持高并发，InnoDB的并发度远高于MyISAM； 是否需要支持外键； 是否需要支持在线热备； 高效缓冲数据，InnoDB对数据和索引都做了缓冲，而MyISAM只缓冲了索引； 索引，不同存储引擎的索引并不太一样； 总之可以简单的归纳为一句话:除非需要用到某些InnoDB不具备的特性，并且没有其他办法可以替代，否则都应该优先选择InnoDB引擎。","link":"/2020/04/10/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3MySQL/"},{"title":"索引优化策略和SQL语句优化","text":"主要内容 建立合理高效的索引 索引优化策略(最佳左前缀法则) 建议看这篇文章之前，先看下我之前写的两篇文章： 索引和查询性能的优化 explain关键字详解 建立合理高效的索引什么情况需要建索引 主键自动建立唯一索引 查询中与其他表的关联字段，即外键建立索引，左外联右表建索引，右联结左表建索引 频繁作为查询条件的字段(WHERE字段)应该建立索引 查询中排序的字段，排序字段(ORDER BY字段)通过索引访问将大大提高排序速度 查询中统计或者分组字段(GROUP BY字段) 什么情况不需要建索引 表记录太少不需要建索引(MySQL官方支持500-800w条记录,但实际300w条记录MySQL性能会明显下降) 频繁增删改的表不需要建索引(每次更新不仅仅是更新记录，也会更新索引) 数据重复且分布平均的列不需要建索引(比如性别列只有男女,且男女比例分布为50%,那么建立索引一般不会提高数据库的查询速度。 这里涉及到一个索引的选择性问题。索引选择性是指索引列中不同值的数目与表中记录数的比。这个值越接近于1，索引的效率就越高。) demo参考文章 https://www.cnblogs.com/developer_chan/p/9219239.html 这里就不再演示。 单列索引还是复合索引？这个问题是什么意思呢？就以我们下面建的staff表为例，表中有属性： id、name、age、pos、salary。id这里就不说了，主键自动建立索引。比如我们发现经常通过name、age、pos查，那么是为每个列单独创建一个索引，即name列、age列、pos列分别建一个索引，一共三个索引，还是建立一个复合索引(name,age,pos)呢?(这里先不讨论复合索引的顺序) 答案是能复合索引就复合索引 原因在于多个单列索引在多条件查询时只会生效第一个索引(5.0版本后，虽然MySQL会同时使用几个单列索引做扫描并将结果合并，但是索引合并时会消耗大量的cpu和内存资源。另一方面也说明我们自己建的索引糟糕)。 而使用复合索引进行多条件查询时，只要复合最佳左前缀法则，那么就会用到多个索引列，从而增加查询的速度。所以多条件联合查询时最好使用联合索引！ 具体的demo这里也就不演示了，可以参考这篇文章(只看看实验就好了)。 索引优化策略这里先准备我们的测试用例： 1234567891011121314151617# 建表DROP TABLE IF EXISTS staff;CREATE TABLE IF NOT EXISTS staff ( id INT PRIMARY KEY auto_increment, name VARCHAR(50), age INT, pos VARCHAR(50) COMMENT '职位', salary DECIMAL(10,2));# 插入数据INSERT INTO staff(name, age, pos, salary) VALUES('Alice', 22, 'HR', 5000);INSERT INTO staff(name, age, pos, salary) VALUES('Bob', 22, 'RD', 10000);INSERT INTO staff(name, age, pos, salary) VALUES('David', 22, 'Sale', 120000);# 建立name、age、pos的复合索引CREATE INDEX idx_staff_nameAgePos ON staff(name,age,pos); WHERE子句的优化(到GROUP BY之前) 1.全值匹配全值匹配是指和索引中的所有列进行匹配。比如我们上面建立了name，age，pos的复合索引，查询时用到索引中的所有列，即name，age，pos三个列都用到。 2.最佳左前缀法则 如果索引了多列，要遵守最佳左前缀法则。即查询从索引的最左前列开始并且不跳过索引中的列。 带头大哥不能死 中间兄弟不能断 下面的例子中很好的体现了正确使用最佳左前缀法则的例子，并且从explain中看到都是使用到了我们建立的索引,并且随着条件的进一步准确，用到的索引列也就越多。 但是如果不是按照索引的最左列开始查找(这个例子中是name列)，则会使我们的索引失效,即开头大哥不能死。 同样，如果我们只用到了1和3列，跳过了索引中的第2列，那么索引中只用到了第1列(只有一个const)。即中间兄弟不能断 3.不在索引列上做任何操作(计算、函数、自动类型转换) 下面的例子中对id列做了计算操作，从而使得索引失效，转而执行全表扫描。 4.存储引擎不能使用索引中范围右边的列 下面的例子中也可以看出来，从=变为&gt;则会使索引访问从ref降低为range。但是从key列中我们也可以看到，范围中也使用到了索引。其实这里索引使用到了name列和age列两列（从key_len可以看出来），其中name列用于查询，age列用于排序。 5.尽量使用覆盖索引，减少select * 覆盖索引：只访问索引的查询(查询列覆盖索引列)，即查询只需要访问索引，而无需访问数据行。 当然一般不可能全部覆盖，都是只覆盖一部分 6.mysql使用！= 或者&lt;&gt;会导致索引失效 7.is null和is not null会导致索引失效 is null之前的版本中是无法使用索引的，这次使用的5.7版本中可使用到索引，应该是mysql底层做了优化。而is not null 还是不能够使用索引 8.like也是范围匹配的另一种形式。%号要加在右边才能用到索引。不会使右边的索引失效。 和范围右边的索引列失效不同的是，如果%放在右边不会使之后的索引列失效 我们知道%a% 和%a 以及 a%可能匹配到的数据是不一样的，如果我们必须要使用%在前面的即%a% 和 %a才能查出准确的数据，那如何解决%必须放在前面的问题? 使用覆盖索引解决： 9.varchar类型的字段不加单引号，mysql会进行自动类型转换(参考第3点)，导致索引失效。 10.or会导致索引失效 到这里，基本对于where的优化，基本就讲完了，但是看一下接下来这两个例子可能让你怀疑人生： 第一个SQL语句中，并没有按照索引列的顺序使用索引，但是为什么我们的复合索引(name,age,pos)都用到了呢？ 我们的最佳左前缀法则呢？其实这里是MySQL内部对我们的SQL语句进行了优化，找到最合适的索引。同样下面的范围查找也是同理。 但是，我们实际写的时候为了语义明确尽量按复合索引的索引列顺序进行书写。 where优化总结 《高性能MySQL》中对于索引的说明，已经包含在了上面的例子中，这里给出参考: 索引对如下类型有效：-全值匹配（参考1.）-匹配最左前缀（参考2.）-匹配列前缀（参考8.like）-匹配范围值（参考4.范围匹配和8.like）-精确匹配某一列并范围匹配另外一列（参考4. 8.）-只访问索引的查询（参考5.覆盖索引） B+树本身的机构问题导致的索引失效-如果不是按照索引的最左列开始，则无法使用索引(参考2)-不能跳过索引中的列（参考2）-如果查询中某个列有范围，则其右边所有列都无法使用索引（参考4. 8.） MySQL优化器和存储引擎使用索引方式导致的索引失效(参考3.6.7.9.10)这些可能会在之后的MySQL优化中取消.比如上面的is null之前是不能使用索引，5.7版本后就可以使用了。 从上面我们也可以看到对于索引的使用，关键还是要注意：全值匹配、最佳左前缀法则、范围匹配(&gt; &lt; 以及like)、覆盖索引这几个关键部分。 分组(GROUP BY)和排序(ORDER BY)的优化到目前为止，我们上面的例子都是针对where字句之后，group by和order by之前进行的优化。我们知道索引不仅仅能用来查询，还能用来分组(GROUP BY)和排序(ORDER BY)，接下来我们就看看这一部分的优化吧。 使用索引来做排序，我们只需要关注一个重点就是是否会产生filesort文件内排序。 ORDER BY中只有两种方式可以使用索引进行排序： 1. ORDER BY语句使用索引最左前缀法则 正确使用最佳左前缀法则，避免了文件排序 错误使用最佳左前缀用于排序，产生了文件内排序，降低了效率。 2. WHERE子句中前导列为常量时或者join子句中对这些列指定了常量从而构成最佳左前缀 前两个SQL语句中where子句中都是指定了常量和order by子句中的列组成了最左前缀，避免了filesort。对于第3条SQL语句，我们知道范围右边失效，所以同样由name age pos构成最左前缀，避免filesort。而第4条中由于where子句中不是常量，无法构成最佳左前缀所以产生filesort。 另外对于排序而言，全升序或全降序不会产生file sort，而只要有一个不同则会产生file sort 分组(GROUP BY)和排序(ORDER BY)优化总结1.ORDER BY子句尽可能避免using filesort方式排序2.尽可能在索引列上完成排序操作，遵照最佳左前缀法则。下表是对上面例子的总结。 3.如果不在索引列上，filesort有两种算法：双路排序和单路排序。 双路排序：在MySQL4.1之前使用双路排序。简单的讲就是从磁盘读取排序字段、在buffer进行排序、再按照buffer中拍好的序从磁盘中读取其他字段。总的来说进行了两次磁盘扫描，得到最终数据。 单路排序：从磁盘中查询所需的列，按照order by列在buffer中对它们进行排序，然后按照排序后的列表进行输出。它避免了第二次读取数据，并且把随机I/O变成了顺序I/O，但是会使用更多的空间，因为它把所有字段都保存在内存中了。 如果使用双路排序，取一批数据要对磁盘进行两次扫描，众所周知，I/O操作是很耗时的，因此出现了改进的算法：单路排序。 但是在单路排序中，当读取数据超过sort_buffer的容量时，就会导致多次读取数据，并创建临时表，最后多路合并，产生多次I/O，反而增加其I/O运算。 解决方法： 避免select * 增大sort_buffer_size参数的设置 增大max_length_for_sort_data参数的设置。 原因在于： 4.group by与order by很类似，其实质是先排序后分组， 遵照索引创建顺序的最佳左前缀法则 当无法使用索引列的时候，也要对sort_buffer_size和max_length_for_sort_data参数进行调整。 注意where高于having，能写在where中的限定条件就不要去having限定了","link":"/2020/04/16/%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5/"},{"title":"查询性能优化","text":"主要内容 MySQL的查询过程 常见优化策略 查询过程 客户端发送一条查询给服务器 服务器先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段。 服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划。 MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询。 将结果返回给客户端。 常见优化策略","link":"/2020/04/22/%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"title":"查询截取分析","text":"查询截取分析流程1. 慢查询的开启并捕获2. explain+慢SQL分析3. show profile查询SQL在MySQL服务器里面的执行细节和生命周期情况4. SQL数据库服务器的参数调优 如果我们发现是SQL语句导致的我们系统变慢，首先需要做的是通过我们的慢查询日志定位我们的问题SQL语句，然后通过explain分析原因，并进行优化。如果无法找到原因，则需要借助更加详细的show profile进行分析和优化。最终都找不到原因，则考虑进行数据库服务器的参数调优。 之前我们学习索引的时候已经学习了explain，接下来我们就主要看看使用慢查询日志以及show profile。 慢查询日志分析之前我们学习了explain来分析SQL语句，但是我们写了很多条SQL语句，哪条语句导致的系统变慢呢？我们是不是需要把所有的SQL语句都分析一遍呢？答案肯定是不可能的。问题在于如何找出我们出问题的SQL语句，这时候就需要用到我们的慢查询日志。 慢查询日志是MySQL提供的一种日志记录，它记录MySQL中响应时间超过阈值的语句，具体指运行时间超过long_query_time值的sql语句，该sql语句会被记录到慢查询日志中。 1.查看是否开启慢查询默认情况下MySQL没有开启慢查询日志，需要我们手动设置。当然，如果不是调优需要的话，一般不建议启动该参数。 可以通过下面的命令查看是否开启慢查询日志： 1show variables like '%slow_query_log%'; 可以看到，MySQL没有开启慢查询日志，并且慢查询日志信息保存在主机名-slow.log文件下。 手动开启慢查询日志： 1set global slow_query_log = 1; 这种使用命令的方式只对当前数据库有效，如果MySQL重启后则会失效。如果需要永久生效，则必须修改mysql的配置文件my.cnf的配置文件。[mysqld]下添加参数： 12slow_query_log=1slow_query_log_file=/var/lib/mysql/centos7-slow.log 2. 查看和设置慢查询的阈值时间上面我们已经开启了慢查询日志，但是多慢的SQL语句会被记录下来呢？ 可以通过如下命令查看： 1show variables like 'long_query_time%'; 可以看到MySQL中默认是10s。这里需要注意是寻找大于 long_query_time 而不是大于等于 我们可以手动进行设置这个时间（在my.cnf中也可以修改）。 1set global long_query_time=3; 上面我们设置查询时间超过3秒为慢查询，但是我们看到sql语句执行成功，但是我们再次查询后还是初始时的10s。难道我们设置的无效吗？实际上这时候已经生效了。我们可以通过show global variables like 'long_query_time%';或者新开一个会话进行查看。 这里我们新开一个会话，执行一个4秒钟的sql语句: 接着我们去var/lib/mysql/centos7-slow.log下面查看： 可以看到慢查询日志中记录了超过阈值的mysql语句，这样我们就知道了哪条sql语句执行较慢，从而针对这条sql语句进行分析和优化。 这里贴一下配置文件中如何配置吧。在[mysqld]下进行如下配置就和我们上面通过命令行的方式相同了。 1234slow_query_log=1;slow_query_log_file=/var/lib/mysql/centos7-slow.log;long_query_time=3;log_output=FILE 3.慢查询日志分析工具mysqldumpslow上面只是做了个演示，实际上在生产环境中，如果要手工分析日志，查找分析SQL语句显然是个体力活，MySQL也给我们提供了日志分析工具mysqldumpslow。 使用时可以通过下面命令查询参数： 1mysqldumpslow --help 比较常用的参数有： s：是表示按照何种方式排序 c: 访问次数 l：锁定时间 r: 返回记录 t：查询时间 al: 平均锁定时间 ar: 平均返回记录数 at: 平均查询时间 t: 返回前面多少条的数据 g: 后面搭配一个正则表达式，大小写不敏感的 使用时可以参照下例： 1234567891011得到返回记录集最多的10个SQLmysqldumpslow -s r -t 10 /var/lib/mysql/centos7-slow.log得到访问次数最多的10个SQLmysqldumpslow -s c -t 10 /var/lib/mysql/centos7-slow.log得到按照时间排序的前10条里面含有左连接的查询语句mysqldumpslow -s t -t 10 -g &quot;left join&quot; /var/lib/mysql/centos7-slow.log另外建议在使用这些命令是结合|和more使用，否则可能会爆屏mysqldumpslow -s r -t 10 /var/lib/mysql/centos7-slow.log | more 批量插入数据，方便后边演示 一、首先我们创建两张表： 1.tb_dept_bigdata（部门表） 1234567# 部门表create table tb_dept_bigdata(id int unsigned primary key auto_increment,deptno mediumint unsigned not null default 0,dname varchar(20) not null default '',loc varchar(13) not null default '')engine=innodb default charset=utf8; 2.tb_emp_bigdata（员工表） 1234567891011create table tb_emp_bigdata(id int unsigned primary key auto_increment,empno mediumint unsigned not null default 0,/*编号*/empname varchar(20) not null default '',/*名字*/job varchar(9) not null default '',/*工作*/mgr mediumint unsigned not null default 0,/*上级编号*/hiredate date not null,/*入职时间*/sal decimal(7,2) not null,/*薪水*/comm decimal(7,2) not null,/*红利*/deptno mediumint unsigned not null default 0 /*部门编号*/)engine=innodb default charset=utf8; 3.打开log_bin_trust_function_creators参数 简单介绍一下，当二进制日志启用后，这个变量需要启用。它控制是否可以信任存储函数创建者，不会创建写入二进制日志引起不安全事件的存储函数。如果设置为0（默认值），用户不得创建或修改存储函数，除非它们具有除CREATE ROUTINE或ALTER ROUTINE特权之外的SUPER权限。 当开启二进制日志后，如果不开启这个参数，我们创建或修改函数会报错“ERROR 1418 (HY000): This function has none of DETERMINISTIC, NO SQL, or READS SQL DATA in its declaration and binary logging is enabled (you *might* want to use the less safe log_bin_trust_function_creators variable)” 同样，这个参数对于触发器也适用。 12345# 查看是否关闭show variables like 'log_bin_trust_function_creators';# 开启参数set global log_bin_trust_function_creators=1; 二、其次我们创建两个函数:1.随机生成字符串的函数 12345678910111213delimiter $$drop function if exists rand_string;create function rand_string(n int) returns varchar(255)begindeclare chars_str varchar(52) default 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';declare return_str varchar(255) default '';declare i int default 0;while i&lt;n doset return_str=concat(return_str,substring(chars_str,floor(1+rand()*52),1));set i=i+1;end while;return return_str;end $$ 2.创建随机生成编号的函数 123456789# 生成100-110的部门编号delimiter $$drop function if exists rand_num;create function rand_num() returns int(5)begindeclare i int default 0;set i=floor(100+rand()*10);return i;end $$ 三、然后我们创建两个存储过程用来往表中批量插入数据1.插入部门表的存储过程 123456789101112131415delimiter $$drop procedure if exists insert_dept;create procedure insert_dept(in start int(10),in max_num int(10))begindeclare i int default 0;set autocommit=0; -- 关闭自动提交repeatset i=i+1;-- 调用了上面定义的rand_string函数来随机产生部门名称和部门位置insert into tb_dept_bigdata (deptno,dname,loc) values((start+i),rand_string(10),rand_string(8)); until i=max_numend repeat;commit;end $$ 2.插入员工表的存储过程 123456789101112131415delimiter $$drop procedure if exists insert_emp;create procedure insert_emp(in start int(10),in max_num int(10))begindeclare i int default 0;set autocommit=0; -- 关闭自动提交repeatset i=i+1;-- 同样调用上面的rand_string和rand_num来产生员工名称和部门编号insert into tb_emp_bigdata (empno,empname,job,mgr,hiredate,sal,comm,deptno) values((start+i),rand_string(6),'developer',0001,curdate(),2000,400,rand_num());until i=max_numend repeat;commit;end $$ 四、调用存储过程批量插入数据 调用存储过程往部门表中插入10个部门 12delimiter ;call insert_dept(100,10); 调用存储过程往emp表中添加50万条记录 123delimiter ;-- 100002-600001call insert_dept(100001,500000); show profile我们上面提到，通过慢查询日志找到执行时间比较长的SQL语句之后，就会使用explain来分析SQL语句并进行优化。如果还是无法解决问题，就需要用到我们的show profile。 show profile是MySQL提供可以用来分析当前会话中语句执行的资源消耗情况。可以用于我们SQL的调优的测量。 MySQL中默认是关闭的，并且记录15条记录。可以通过下面的命令查看： 1234# 查看是否开启show variables like 'profiling';# 设置开启set profiling = on; 本来一开始是打算使用这两条sql语句进行测试，但是却出现了问题 12select *from tb_emp_bigdata group by id%10 limit 150000;select *from tb_emp_bigdata group by id%20 order by 5; 这里的意思是说MySQL处于only_full_group_by SQL模式(5.7.5之后的默认情况，我用的是5.7.26),在这种模式下需要select列中都要在group by中,或者本身是聚合列(SUM,AVG,MAX,MIN) 才行，所以去掉就好。 解决方法：首先查看sql_mode模式，可以看到是包含only_full_group_by模式的。 我们直接去掉它即可 注意上面只是对本次会话有效，如果需要一直有效，则需要在my.cnf的[mysqld]下进行配置 1sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION 配置完成后重启MySQL即可。 错误解决后，我们回来继续看show profile。开启profiling后，我们随便写几条sql语句 123456789select * from staff;select name,age,pos from staff where name = 'Alice';select * from staff group by age;-- 当然还有我们要测试的SQL语句-- 这两个语句本身并没有意义，只是为了增加查询时间select *from tb_emp_bigdata group by id%10 limit 150000;select *from tb_emp_bigdata group by id%20 order by 5;select * from staff group by age;select *from tb_emp_bigdata group by id%20 order by 5; 接着我们看下下面的sql语句的执行结果 1show profiles; 可以看到show profiles的结果中记录了我们开启profiling后的每一条sql语句，默认是15条。(我这里是为了解决上面说的sql_mode问题，如果一开始就设置好了，那么应该是从序号1开始的) 我们看到这个表中有三列:Query_ID：是我们开启profiling后执行的每条SQL语句idDuration：是我们每条SQL语句的执行时间Query：不用说就是我们的SQL语句 通过上面的表中得到Query_ID后，才是show profile真正发挥作用的时候了： 123-- 这里只是写了比较常用的cpu,block io进行显示-- 其他参数参考下表show profile cpu,block io for query 上面表中的Query_ID 这里我们先看下简单的10号SQL的信息： 可以看到左边Status列就是我们这条SQL语句的完整的生命周期。Duration列是SQL每个步骤耗费时间。 CPU 和Block列则是CPU和IO耗费情况。 我们在来看下上面特意准备的执行时间比较长的SQL语句： 从上面我们可以看到具体执行时间比较长的有创建临时表creating tmp table和我们的sending data。这样我们就可以根据这两点来对我们的SQL语句进行优化。 如果在show profile诊断结果中出现了下面结果中的任何一条，则sql语句需要优化。①converting HEAP to MyISAM：查询结果太大，内存不够，数据往磁盘上搬了。②Creating tmp table：创建临时表。先拷贝数据到临时表，用完后再删除临时表。③Copying to tmp table on disk：把内存中临时表复制到磁盘上，危险！！！④locked。⑤sending data时间过长 比如常见的sending data时间过长的原因可能是因为没有索引或者没有正确使用索引。 总结如果发现是SQL语句执行的慢，导致系统变慢的话，我们需要做的有：1. 首先开启慢查询并捕获执行的慢的SQL语句2. 找出SQL语句后通过explain进行分析(一般在这里就能解决)3. 如果explain解决不了，则通过show profile进行更细致的分析，从而对SQL进行优化。(到这里基本95%的问题能解决)4. 最后还是解决不了，则需要与DBA沟通进行SQL数据库服务器的参数调优 到这里，我们的SQL调优的基本知识算是了解了。但要知道实际生产上的调优远比我们上面写的demo要复杂的多，所以还是多多积累吧。","link":"/2020/04/22/%E6%9F%A5%E8%AF%A2%E6%88%AA%E5%8F%96%E5%88%86%E6%9E%90/"},{"title":"Java多线程之并发容器","text":"主要内容 集合容器的安全性问题 并发容器分类 集合容器的安全问题Java的集合容器框架中，主要有四大类别：List、Set、Queue、Map，大家熟知的这些集合类ArrayList、LinkedList、HashMap这些容器都是非线程安全的。如果有多个线程并发地访问这些容器时，就会出现问题。比如下面这个例子： 1234567891011121314151617package com.company.MultiThread;import java.util.ArrayList;import java.util.List;import java.util.UUID;public class ListUnsafeDemo { public static void main(String[] args) { List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) { new Thread(()-&gt; { list.add(UUID.randomUUID().toString().substring(0,6)); System.out.println(list); },\"t\"+i).start(); } }} 输出结果中会抛出并发修改异常 1java.util.ConcurrentModificationException set、Map、Queue同理,这里就不演示了。 如何解决并发修改异常以ArrayList为例(set、Map、Queue同理，具体参照下面的表格),解决方法如下 1.使用同步容器Vector List&lt;String&gt; list = new Vector&lt;&gt;(); 2.使用Collections.synchronizedArrayList List&lt;String&gt; list = Collections.synchronizedList(new ArrayList&lt;&gt;()); 3.使用JUC包中的并发容器CopyOnWriteArrayList List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); 我们先看下Vector和Collections.synchronizedArrayList的源码： Vector中的方法 12public synchronized boolean add(E e) public synchronized E get(int index) Collections.synchronizedArrayList去翻一下源码，也可以知道： 1234567public boolean add(E e) { synchronized (mutex) {return c.add(e);}}public E get(int index) { synchronized (mutex) {return list.get(index);}} 可以看到无论是Vector还是Collections.synchronizedArrayList都是通过synchronized关键字加锁来保证多线程下的集合安全。但是这样做的代价是降低了并发性，当多个线程共同竞争容器级的锁时，吞吐量就会降低 并发容器的分类为了解决同步容器的性能问题，所以在JDK1.5之后有了并发容器，这些并发容器位于J.U.C包中。 我们对上面的并发容器做个简单的说明： CopyOnWriteArrayList 底层是一个volatile修饰的数组 1private transient volatile Object[] array; add操作 1234567891011121314public boolean add(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; } finally { lock.unlock(); } } get操作 123public E get(int index) { return get(getArray(), index);} 总结： 底层是volatile修饰的数组 写操作加锁，读操作不加锁。 写操作过程：先复制一份新的数组，在新的集合上面修改，然后将新数组赋值给旧的引用。 CopyOnWriteArraySet 底层基于CopyOnWriteArrayList实现 1private final CopyOnWriteArrayList&lt;E&gt; al; add操作 12345678public boolean add(E e) { return al.addIfAbsent(e);}public boolean addIfAbsent(E e) { Object[] snapshot = getArray(); return indexOf(e, snapshot, 0, snapshot.length) &gt;= 0 ? false : addIfAbsent(e, snapshot);} add时调用的是CopyOnWriteArrayList的addIfAbsent方法，其遍历当前Object数组，如Object数组中已有了当前元素，则直接返回，如果没有则放入Object数组的尾部，并返回。 ConcurrentHashMap、ConcurrentSkipListMap、ConcurrentSkipListSet 因为比较重要，所以放在下篇文章讲。 ConcurrentLinkedQueue和ConcurrentLinkedDeque ConcurrentLinkedQueue底层是基于链表实现的FIFO队列ConcurrentLinkedDeque底层是基于链表实现的双端队列 BlockingQueue 因为线程池中用到了，比较重要，也会新开一篇","link":"/2020/03/26/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8B%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/"},{"title":"SQL基本语法(二) 高级特性","text":"主要内容 索引、视图、存储过程、游标、触发器 MySQL事务管理 MySQL权限管理 索引、视图、存储过程、游标、触发器索引首先声明，索引这个东西十分复杂也十分重要，尤其是对于查询性能优化，写一本书都不过分，所以这里只写索引最最基本的使用。之后会详细介绍索引和查询性能优化。 索引是存储引擎用于快速找到记录的一种数据结构。主要作用就是在数据量比较大时，可以提高我们的查询效率。可以简单的把索引类比成我们书的目录。 索引主要包括： 单值索引：即一个索引只包含单个列，一个表可以有多个单值索引 唯一索引： 索引列的值必须唯一，但允许有空值。 复合索引： 即一个索引包含多个列。 索引的基本使用： 1234567891011# 创建索引-- 加UNIQUE则为唯一索引，不加就是单值索引CREATE [UNIQUE] INDEX indexName ON mytable(columname);-- 复合索引CREATE INDEX indexName ON mytable(col1,col2);# 删除索引DROP INDEX indexName ON mytable;# 查看索引SHOW INDEX FROM mytable; 视图视图是一个虚表，即视图包含的不是数据而是根据需要检索数据的SQL语句。视图提供了一种封装SELECT语句的层次，可用来简化数据处理，重新格式化和保护基础数据。 使用视图的好处： 重用SQL语句，对于复杂点的SQL语句将它创建为视图后可以方便的重用 因为视图可以使用表的一部分而不是整个表，所以可以保护原来表中的一些重要数据。 视图可以更改数据格式和表示。 视图的基本使用 12345678910111213141516171819202122232425# 基本模板CREATE VIEW myview AS-- SELECT语句# 使用视图简化复杂联结CREATE VIEW productcustomers ASSELECT c.cust_name,c.cust_contact,oi.prod_idFROM customers AS cINNER JOIN orders AS oON c.cust_id = o.cust_idINNER JOIN orderitems AS oiON o.order_num = oi.order_num;-- 这时候就可以直接查询不用再写上面复杂的联结SELECT * FROM productcustomers;# 使用视图保护表中数据-- 只给出3列数据，products表中其他数据不给CREATE VIEW productsview ASSELECT prod_id,prod_name,vend_idFROM products;-- 这时候只有上面的3列数据SELECT * FROM productsview;-- 可以看到每个VIEW的作用取决于SELECT语句是如何定义的 更新视图上面的都是对视图进行查询，我们之前提到过可以把视图可以看成表来进行操作，那么如果对视图进行增删改，原来的表中的数据会发生变化吗？ 通常，视图是可更新的（即，可以对它们使用 INSERT、UPDATE 和 DELETE ），更新一个视图将更新其基表。 并非所有视图都是可更新的。如果MySQL不能正确地确定被更新的基数据，则不允许更新（包括插入和删除） 比如如果SELECT语句中使用了下面这些条件就不能进行视图的更新： 分组（使用 GROUP BY 和 HAVING ) 联结； 子查询； 并； 聚集函数（ Min() 、 Count() 、 Sum() 等）； DISTINCT； 导出（计算）列。 绝大部分情况下,视图只用于检索（ SELECT 语句）而不用于更新（ INSERT 、 UPDATE 和 DELETE ） 存储过程之前我们都是使用的是1条SQL语句，但有的操作需要针对许多表的多条MySQL语句这时就需要用到存储过程。存储过程可以看成是对一系列 SQL 操作的批处理。（可以理解为我们封装了一个方法） 使用存储过程的好处： 代码封装，保证了一定的安全性； 代码复用； 由于是预先编译，因此具有很高的性能。 存储过程基本使用： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# 创建存储过程CREATE PROCEDURE productpricing() -- 没有接收参数BEGIN SELECT AVG(prod_price) AS priceaverage FROM products; -- 分号;不可省END;-- 调用存储过程CALL productpricing();-- 删除存储过程DROP PROCEDURE productpricing;# 创建存储过程使用参数-- 此存储过程接收3个参数-- OUT表示从存储过程传出 还有 IN传入存储过程 INOUT对存储过程传入和传出-- pmin存储产品最低价格 类型为DECIMAL类型（创建表的类型都能用）其他同理-- 通过INTO关键字保存到响应变量中CREATE PROCEDURE productpricing( OUT pmin DECIMAL(8,2), OUT pmax DECIMAL(8,2), OUT pavg DECIMAL(8,2))BEGIN SELECT MIN(prod_price) INTO pmin FROM products; SELECT MAX(prod_price) INTO pmax FROM products; SELECT AVG(prod_price) INTO pavg FROM products;END;-- 调用存储过程-- 需要传递3个参数，使用@CALL productpricing( @pricelow, @pricehigh, @priceaverage);-- 查询SELECT @pricelow,@pricehigh,@priceaverage-- # 再看另外一个例子使用INCREATE PROCEDURE ordertotal( IN onumber INT, OUT ototal DECIMAL(8,2))BEGIN SELECT SUM(item_price*quantity) FROM orderitems WHERE order_num = onumber INTO ototal;END;-- 和调用函数相同，可以传递不同的值CALL ordertotal(20005,@total);SELECT @total;CALL ordertotal(20009,@total);SELECT @total; 智能存储过程使用 12345678910111213141516171819202122232425262728293031323334353637# 获得订单合计，但需要对合计增加营业税-- 1. 获得合计-- 2. 把营业税有条件的添加到合计-- 3. 返回合计(带或不带税)CREATE PROCEDURE ordertotal( IN onumber INT, IN taxable BOOLEAN, OUT ototal DECIMAL(8,2))BEGIN -- 声明total变量 DECLARE total DECIMAL(8,2); -- 声明上税百分比 DECLARE taxrate INT DEFAULT 6; -- 获得订单合计 SELECT SUM(item_price*quantity) FROM orderitems WHERE order_num = onumber INTO total; -- 判断是否要上税 IF taxable THEN -- true 需要上税 SELECT total+(total/100*taxrate) INTO total; END IF; -- 直接将total赋给ototal SELECT total INTO ototal;END;CALL ordertotal(20005,FALSE,@total);SELECT @total;CALL ordertotal(20005,TRUE,@total);SELECT @total; 游标游标的主要作用是对一个结果集进行移动遍历（可以理解为是一个指针，指向查出的结果的每一行）。主要用于交互式应用，其中用户需要对数据集中的任意一行或多行进行浏览和修改。 注意：游标只能在存储过程中使用 游标的基本使用： 声明游标 2. 打开游标 3. 取出数据 4. 关闭游标123456789101112131415CREATE PROCEDURE processorders()BEGIN -- 声明游标为ordernumbers DECLARE ordernumbers CURSOR FOR SELECT order_num FROM orders; -- 打开游标 OPEN ordernumbers; -- ...具体操作 -- 关闭游标 CLOSE ordernumbers;END; 接下来看个具体的例子 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 每个订单加上上税后的金额CREATE PROCEDURE processorders()BEGIN -- 声明局部变量 DECLARE done BOOLEAN DEFAULT 0;-- 声明循环终止符 DECLARE o INT; -- 声明局部变量o 用于存储每行数据 DECLARE t DECIMAL(8,2); -- 存储每个订单合计 -- 声明游标为ordernumbers DECLARE ordernumbers CURSOR FOR SELECT order_num FROM orders; -- 声明句柄用于条件出现时(即SQLSTATE=02000时)设置done为1，结束循环） DECLARE CONTINUE HANDLER FOR SQLSTATE '02000' SET done=1; -- 创建一个表来存储结果 CREATE TABLE IF NOT EXISTS ordertotals(order_num INT,total DECIMAL(8,2)); -- 打开游标 OPEN ordernumbers; -- 循环所有行 REPEAT -- FETCH 用来检索当前行的 order_num 列 -- 自动从第一行开始,并存储到一个名为 o 的局部声明的变量中 FETCH ordernumbers INTO o; -- 得到订单总量 CALL ordertotal(o,1,t); -- （之前创建的存储过程）计算每个订单上税合计 INSERT INTO ordertotals (order_num,total) VALUES(o,t); -- 结束循环 UNTIL done END REPEAT; -- 关闭游标 CLOSE ordernumbers;END;CALL processorders();SHOW TABLES;SELECT * FROM ordertotals; 触发器触发器：监视某种情况，并触发某种操作，它是提供给程序员来保证数据完整性的一种方法。 触发器是与表事件相关的一种特殊的存储过程，它的执行不是由程序调用，也不是手工启动，而是由事件来触发。触发器会在某个表执行以下语句时而自动执行：DELETE、INSERT、UPDATE。 触发器创建语法四要素： 监视地点(table) 监视事件(INSERT/UPDATE/DELELTE) 触发时间(BEFORE/AFTER) 触发事件(INSERT/UPDATE/DELELTE) 这里对BEFORE和AFTER进行一下说明 BEFORE 在监视事件之前执行触发事件。则主要用于数据校验和净化。 AFTER 在监视事件之后执行触发事件。主要用于审计跟踪，将修改记录到另外一张表中。 触发器的基本使用 123456789101112131415161718# 基本语法CREATE TRIGGER 触发器名BEFORE/AFTER INSERT/UPDATE/DELETE ON 表名FOR EACH ROW -- 这句话在MySQL中是固定(指的是操作的每一行)BEGIN sql语句;END;# 简单的例子-- 在插入vendors表中一条记录后，在products表中插入一条记录CREATE TRIGGER newvendorsAFTER INSERT ON vendorsFOR EACH ROWBEGIN INSERT INTO products VALUES ('ANNNNNN',1009,'jdfks',9.99,'插入时的描述');END;-- 测试一下INSERT INTO vendors VALUES (1009,'haha','haha','haha','aa','dfsfs','USA'); INSERT触发器INSERT触发器内可以引用一个名为NEW的虚拟表，访问被插入的行。 12345678910111213141516171819202122232425262728-- 比如还是上面的例子，vend_id就可以使用NEW.vend_id-- 这里NEW就表示vendors表中插入的一条记录DROP TRIGGER IF EXISTS `newvendors`;CREATE TRIGGER newvendorsAFTER INSERT ON vendorsFOR EACH ROWBEGIN INSERT INTO products VALUES ('ANNNNNN',NEW.vend_id,'jdfks',9.99,'插入时的描述');END;-- 测试一下INSERT INTO vendors VALUES (1009,'haha','haha','haha','aa','dfsfs','USA');# 也可以使用IF判断-- 判断供应商国家是不是USA，是的话执行，否则不执行CREATE TRIGGER newvendorsAFTER INSERT ON vendorsFOR EACH ROWBEGIN IF NEW.vend_country = 'USA' THEN INSERT INTO products VALUES ('ANNNNNN',NEW.vend_id,'jdfks',9.99,'插入时的描述'); END IF;END;-- 测试一下-- 插入成功，两张表都更新INSERT INTO vendors VALUES (1009,'haha','haha','haha','aa','dfsfs','USA'); -- 插入失败,因为是AFTER,所以只有vendors表中更新INSERT INTO vendors VALUES (1010,'haha','haha','haha','aa','dfsfs','France'); DELETE触发器在 DELETE触发器代码内，你可以引用一个名为OLD的虚拟表，访问被删除的行 1234567891011-- 将删除的数据保存到另一张表中CREATE TRIGGER deletesaveorderBEFORE DELETE ON ordersFOR EACH ROWBEGIN INSERT INTO deleteorder (order_num,order_date,cust_id) VALUES(OLD.order_num,OLD.order_date,OLD.cust_id);END;-- 测试DELETE FROM orders WHERE order_num = 20010; UPDATE触发器在 UPDATE触发器代码内可以引用一个名为OLD的虚拟表，访问被删除的行也可以引用一个名为 NEW 的虚拟表访问新更新的值 12345678910DROP TRIGGER updatevendor;CREATE TRIGGER updatevendorBEFORE UPDATE ON vendorsFOR EACH ROWBEGIN -- 一种简便的写法因为是BEFORE,所以可以直接SET SET NEW.vend_state = UPPER(NEW.vend_state);END;-- 测试一下UPDATE vendors SET vend_state = 'ab' WHERE vend_id = 1006 MySQL事务管理事务处理是一种机制，通过确保成批的 SQL 操作要么完全执行，要么完全不执行，来维护数据库的完整性，保证数据库不包含不完整的操作结果。 事务（transaction）指一组 SQL 语句； 回退（rollback）指撤销指定 SQL 语句的过程； 提交（commit）指将未存储的 SQL 语句结果写入数据库表； 保留点（savepoint）指事务处理中设置的临时占位符（placeholder），你可以对它发布回退（与回退整个事务处理不同）。 注意： 事务不能回退 SELECT 语句，回退 SELECT 语句也没意义 事务也不能回退 CREATE 和 DROP 语句。 MySQL中事务是默认自动提交的，MySQL会把每一条INSERT、UPDATE、DELETE语句都看做是一个事务自动提交。 123456-- 查看是否是自动提交 ON表示开启自动提交 OFF表示关闭SHOW VARIABLES LIKE 'autocommit' -- ON-- 使用autocommit = 0关闭自动提交，-- autocommit = 1开启自动提交SET autocommit = 0;SHOW VARIABLES LIKE 'autocommit' -- OFF 事务使用的基本方法： 如果没有设置保留点，ROLLBACK 会回退到 START TRANSACTION 语句处； 如果设置了保留点，并且在 ROLLBACK 中指定该保留点，则会回退到该保留点。 保留点在事务处理完成（执行一条 ROLLBACK 或 COMMIT）后自动释放。1234567START TRANSACTION-- ...SAVEPOINT delete1 -- ...ROLLBACK TO delete1-- ...COMMIT 我们先按照上面关闭自动提交，再来看下面的实验结果 12345678910111213141516171819# ROLLBACK 和SAVEPOINT测试-- SELECT * FROM ordertotals;START TRANSACTION;DELETE FROM ordertotals WHERE order_num = 20005;SAVEPOINT delete1;-- SELECT * FROM ordertotals;DELETE FROM ordertotals;-- SELECT * FROM ordertotals;ROLLBACK TO delete1; --回滚到delete1点，只是删除了order_num = 20005的列-- SELECT * FROM ordertotals;ROLLBACK;-- SELECT * FROM ordertotals; --回滚到开始处，20005行也没有删除# COMMIT测试-- 彻底删除了20005行，无法回滚了START TRANSACTIONDELETE FROM ordertotals WHERE order_num = 20005;SAVEPOINT delete1;COMMIT; MySQL权限管理到目前为止我们使用的都是MySQL的root账户，它对整个MySQL服务器具有完全的控制。不过实际使用时决不能使用root,应该创建一系列的账号，有的用于管理，有的供用户使用，有的供开发人员使用。 MySQL的权限管理就是管理用户以及用户访问数据的权限管理。比如哪些用户可以创建表，哪些用户只能读和写表;哪些用户只能添加数据不能删除数据等等。 MySQL用户账号和信息存储在名为 mysql 的MySQL数据库中,可以使用下面的命令查看用户： 12USE mysql;SELECT user FROM user; 用户管理12345678910111213# 创建账户-- 新创建的账户没有任何权限。-- Vic用户名 mypassword密码CREATE USER Vic IDENTIFIED BY 'mypassword'; # 修改账户名RENAME USER Vic TO coderchen;# 删除账户DROP USER coderchen;# 修改密码SET PASSWORD FOR coderchen = Password('chenpassword'); 权限管理新创建的用户账号没有访问权限。它们能登录MySQL，但不能看到数据，不能执行任何数据库操作。比如上面的新建用户coderchen。 因此新创建用户后需要给用户赋予权限。 授予权限使用 GRANT 撤销权限使用 REVOKE 123456789101112131415161718192021222324252627# 查看用户权限-- 又重新创建了coderchen账号SHOW GRANTS FOR myuser;-- 运行结果如下所示：表示coderchen没有任何权限-- GRANT USAGE ON *.* TO 'coderchen'@'%'# 设置访问权限-- 授予coderchen对reviewmysql中的所有表具有SELECT和INSERT权限GRANT SELECT, INSERT ON reviewmysql.* TO coderchen;-- 验证一下SHOW GRANTS FOR coderchen;-- 运行结果如下：可以看到多了一行我们设置的权限-- GRANT USAGE ON *.* TO 'coderchen'@'%'-- GRANT SELECT, INSERT ON `reviewmysql`.* TO 'coderchen'@'%'-- 这时候也可以用coderchen连接数据库进行测试-- 查询和插入都没问题-- 更新会出现UPDATE command denied to user 'coderchen'@'localhost' for table 'orders'错误# 撤销访问权限-- 撤销插入权限REVOKE INSERT ON reviewmysql.* FROM coderchen;-- 验证一下SHOW GRANTS FOR coderchen;-- 运行结果如下：可以看到第二行中已经少了INSERT权限-- GRANT USAGE ON *.* TO 'coderchen'@'%'-- GRANT SELECT ON `reviewmysql`.* TO 'coderchen'@'%' GRANT 和 REVOKE 可在几个层次上控制访问权限： 整个服务器，使用 GRANT ALL 和 REVOKE ALL； 整个数据库，使用 ON database.*； 特定的表，使用 ON database.table； 特定的列； 特定的存储过程。 详细的权限说明参考下表","link":"/2020/04/06/SQL%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E4%B9%8B%E7%B4%A2%E5%BC%95%E3%80%81%E8%A7%86%E5%9B%BE%E3%80%81%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E3%80%81%E8%A7%A6%E5%8F%91%E5%99%A8%E3%80%81%E6%B8%B8%E6%A0%87%E3%80%81%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E3%80%81%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86%E3%80%81%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%B4%E6%8A%A4/"},{"title":"树的基本概念和前中后序遍历","text":"主要内容 树的基本概念 二叉树概念和常见性质 二叉树的前中后序遍历 树的基本概念树(Tree)是n(n&gt;=0)个结点的有限集。n=0时称为空树。在任意一颗非空树中： 有且仅有一个特等的称为根(Root)的结点; 当n&gt;1时，其余结点可分为m(m&gt;0)个互不相交的有限集T1、T2、……Tm,其中每一个集合本身又是一棵树，并且称为根的子树(SubTree) 结点分类 树的结点包含一个数据元素及若干指向其子树的分支。结点拥有的子树数称为结点的度(Degree)。度为0的结点称为叶结点(Leaf)或终端结点;度不为0的结点称为非终端结点或分支结点。除根结点外，分支结点也称为内部结点。树的度是树内各结点的度的最大值。 以下图为例，A为根结点，B、C、D、E为分支结点，也叫内部结点。F、G、H、I、J为叶结点。由于D的度最大为3，所以数的度为3。 结点间的关系 结点的子树的根称为该结点的子结点，相应的，该结点称为子节点的父结点。同一个父结点的子结点之间互称为兄弟结点。结点的祖先是从根结点到该结点所经分支上的所有结点。反之，以某结点为根的子树中的任一结点都称为该结点的子孙。 还是以上图为例，C结点的子结点为E、F，父结点为A，兄弟结点为B。H结点祖先为A、B、D。C的子孙为E、F、J 树的其他概念 结点的层次(Level)从根开始定义起，根为第一层，跟的子结点为第二层，依次类推。父结点在同一层的结点互为堂兄弟结点。树中结点的最大层次称为树的深度(Depth)或高度。 二叉树二叉树(Binary Tree)是n(n&gt;=0)个结点的有限集合，该集合或者为空集(称为空二叉树),或者是由一个根结点和两颗互不相交的、分别称为根结点的左子树和右子树的二叉树组成。 注意：1.二叉树的每个结点最多有两颗子树，所以二叉树中不存在度大于2的结点2.左子树和右子树是有顺序的，次序不能任意颠倒3.即使树中某结点只有一颗子树，也要区分它是左子树还是右子树 二叉树的常见性质： 特殊二叉树：斜树所有的结点都只有左子树的二叉树叫左斜树。所有结点都只有右子树的二叉树叫右斜树 满二叉树 在一颗二叉树中，如果所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树 满二叉树的特点： 1.叶子结点只能出现在最下一层，出现在其它层就不可能达到平衡。2.非叶子结点的度一定是23.在同样深度的二叉树中，满二叉树的结点个数最多，叶子数最多 完全二叉树对一颗具有n个结点的二叉树按层序编号，如果编号为i(1&lt;=i&lt;=n)的结点与同样深度的满二叉树中编号为i的结点在二叉树中位置完全相同，则这棵二叉树称为完全二叉树 完全二叉树的特点： 1.叶子结点只能出现在最后两层2.最下层的叶子一定集中在左步连续位置3.倒数第二层若有叶子，一定集中在右部连续位置4.如果结点度为1，那么该结点一定只有左孩子，不存在只有右子树的情况5.同样结点数的二叉树，完全二叉树的深度最小 二叉树的存储结构顺序存储: 链式存储: 由于顺序结构的使用性不强，所以考虑链式结构。二叉树的链式存储结构是通过二叉链表来实现的。结点结构图如下图所示。其中data为数据域，lchild和rchild为指针域，分别指向左孩子结点和右孩子结点。 二叉树的前中后序遍历 前中后序遍历的区别在于根节点的位置。前序遍历为根左右，中序遍历为左跟右，后序遍历为左右根。 二叉树的前中后序遍历实际上用处不是很大，只是让我们了解二叉树可以以不同的方式进行遍历。唯一有用的一点是如果这个二叉树是二叉搜索树(BST)的话，中序遍历出来为递增序列","link":"/2020/04/29/%E6%A0%91%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E5%89%8D%E4%B8%AD%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86/"},{"title":"数据结构与算法概述","text":"主要内容 数据结构概述 算法时间复杂度分析 数据结构概述数据结构主要从三个方面理解和学习: 按照分类角度的不同，数据结构包括逻辑结构和物理结构。 逻辑结构指的是数据对象中数据元素之间的关系，有以下四种： 集合 结构中的数据元素除了同属于一种类型外，别无其它关系。 线性结构 结构中的数据元素之间是一对一的关系。 树结构 结构中的数据元素之间存在一对多的多层关系。 图结构 结构中的数据元素之间是多对多的关系。 物理结构也叫存储结构，指的是数据的逻辑结构在计算机中的存储方式。有以下两种： 顺序存储:把数据元素存放在地址连续的存储单元里，其数据间的逻辑关系和物理关系是一致的。 链式存储结构：把数据元素存放在任意存储单元里，这组存储单元可以是连续的也可以是不连续的。但是需要在每一个数据元素中增加一个存放地址的指针，用此指针来表示数据元素之间的逻辑关系 算法概述算法定义 ：算法是解决特定问题求解步骤的描述，在计算机中为指令的有限序列，并且每条指令表示一个或多个操作 算法的特性： 输入：有0个或多个输入 输出：至少有1个或多个输出 有穷性：算法在有限的步骤后应该自动结束而不会无限循环。 确定性：算法中的每个步骤都有确定的含义，不会出现二义性 可行性：算法的每一步都是可行的 算法的设计要求： 正确性：算法对于合法数据能够得到满足要求的结果，能够处理非法输入，并得到合理的结果。 可读性：算法要便于阅读、理解和交流 健壮性：算法不应该得到莫名其妙的结果 性价比：利用最少的资源得到满足要求的结果 算法的时间复杂度算法的时间复杂度定义 在进行算法分析时，语句总的执行次数T(n)是关于问题规模n的函数，进而分析T(n)随n的变化情况并确定T(n)的数量级。算法的时间复杂度，也就是算法的时间量度，记作:T(n)=O(f(n)) [大O表示法]。它表示随问题规模n的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐近时间复杂度，简称为时间复杂度。其中f(n)是问题规模n的某个函数。 推导大O阶方法 1.用常数1取代运行时间中的所有加法常数2.在修改后的运行次数函数中，只保留最高阶项。3.如果最高阶项存在且不是1，则去除与这个项目相乘的常数。得到的结果就是大O阶 注意有时候，算法中基本操作重复执行的次数还随问题的输入数据集不同而不同，如在冒泡排序中，输入数据有序而无序，其结果是不一样的，通常我们看平均时间复杂度。 有时候，算法中基本操作重复执行的次数还随问题的输入数据集不同而不同，如在冒泡排序中，输入数据有序而无序，其结果是不一样的。此时，我们计算平均值。 以下面几个例子为例,简单介绍下推倒大O阶的方法： demo1 ：（1）执行1次，（2）执行1次, （3）执行1次 T(n) = 1+1+1= 3=O(1) 也称为常数阶 123int sum = 0; //(1)sum = (1+i)*i/2; //(2)System.out.println(sum); //(3) demo2: （1）执行1次，（2）执行n次（3）执行n次 T(n) = 1+2n =O(n) 也称为线性阶 1234int sum=0; //(1)for (int i = 0; i &lt;=n ; i++) { //(2) sum = sum + i; //(3)} demo3：（1）执行1次， （2）执行n次（3）执行n2次,（4）执行n2次 T(n)=1+n+2n2=O(n2),称为n方阶 123456int sum=0; //(1)for (int i = 0; i &lt;=n ; i++) { //(2) for(int j = 0; j&lt;=n ; j++){ //(3) sum = sum + i; //(4) } } demo4：(1)的频度是1,设(2)的频度是f(n)，则：2f(n)&lt;=n;f(n)&lt;=log2n，取最大值f(n)= log2n, T(n)=O(log2n) 也称为对数阶 1234int i = 1; //(1) while (i &lt;= n){ i = i*2; //(2) } 常见时间复杂度 O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(n^2)&lt; O(n^3) &lt;O(2n)&lt;O(n!)&lt;O(n^n) O(1)、O(logn)、O(n)、O(n2)上文都已经介绍过比较经典的例子，O(nlog n)在之后排序算法会介绍到（归并排序和快排）。 O(n^3)、 O(2n)、O(n!)、O(n^n)等除非是很小的n，否则哪怕n=100，运行时间也会非常大。所以对于这种复杂度的算法一般没有讨论的意义。 算法的空间复杂度空间复杂度：算法所需存储空间的度量，记作： S(n)=O( f(n) ) ,其中 n 为问题的规模。 1234567891011int x;for(int i=0;i&lt;n;i++){ x = 10; //O（1） //使用x}for(int i=0;i&lt;n;i++){ int x = 10; //O(n) //使用a} 一个算法在计算机存储器上所占用的存储空间，包括三个方面: 存储算法本身所占用的存储空间 算法的输入输出数据所占用的存储空间 算法在运行过程中临时占用的存储空间 我们知道代码本身多几行少几行所占用的空间可以忽略不计，而算法的输入输出无论用什么算法都是一定的，所以我们需要关注的应该是3,即算法在运行过程中临时占用的存储空间。 另外如果额外空间相对于输入数据量来说是个常数，则称此算法是原地工作。","link":"/2020/04/29/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/"},{"title":"二叉排序树、平衡二叉树、红黑树、B树、B+树","text":"主要内容 二叉排序树(BST树) 平衡二叉树(AVL树) 红黑树(R-B Tree) B/B+树 二叉排序树(BST树)二叉排序树（Binary Sort Tree）又称二叉查找树、二叉搜索树。它或者是一棵空树；或者是具有下列性质的二叉树： 1. 若左子树不空，则左子树上所有结点的值均小于它的根结点的值；2. 若右子树不空，则右子树上所有结点的值均大于它的根结点的值；3. 左、右子树也分别为二叉排序树 我们以数组{3,2,1,5,4,6}构建一个二叉排序树如下: 可以看到BST树因为有排序，所以检索的时间复杂度为O(logn)。但是BST树还有一个问题:如果我们的数组是{2,1,3,4,5…},或者甚至如果我们的数组为{1,2,3,4,5..}或者{5,4,3,2,1…},那么我们的数组就会退化成一个单链表。查询的时间复杂度从O(logn)退化为O(n) 所以对于BST树而言: 平均时间复杂度为O(logn),最坏时间复杂度为 O(n) 另外，二叉排序树的中序遍历是一个递增序列。(上面中序遍历为1,2,3,4,5,6) 我们知道,BST树主要是用来进行检索，但是由于它会退化成线性表，使得检索的时间复杂度为O(logn)，所以一般情况下很少使用。 平衡二叉树(AVL树)为了避免上述二叉排序树退化成链表，出现了平衡二叉排序树，又叫AVL树。那么是怎么定义的呢？ 首先平衡二叉树是二叉排序树。那么它或者为空树，或者满足上面BST中提到的三点要求。 其次和普通二叉排序树不同的是二叉平衡树要求左右的子树高度之差绝对值不超过1。 通常我们将二叉树上结点的左子树深度减去右子树深度的值称为平衡因子BF(Balance Factor),那么平衡二叉树的平衡因子只能是-1,0,1。上面的小的数字就是那个节点的BF。 左旋和右旋上面我们看到AVL树是自平衡的，那么AVL树是如何保证它的平衡性呢?实际上平衡二叉树在每次插入元素时都会做相应的旋转操作。旋转的四种情况如下： 插入点位于x的左孩子的左子树中。 左左LL 需要进行右旋。 插入点位于x的右孩子的右子树中。 右右RR 需要进行左旋。 插入点位于x的左孩子的右子树中。 左右LR 需要较低的先左旋，转换为LL问题，再右旋。 插入点位于x的右孩子的左子树中。 右左RL 需要较低的先右旋，转化为RR问题。再左旋。 当插入一个节点破坏了树的平衡状态时，我们需要做的有两点: 找出最小不平衡子树(距离插入节点最近，且BF不在[-1,1]范围内的节点为根的子树)。 通过旋转操作维持二叉树的平衡状态(LL、RR、LR、RL) 我们以数组a[9]={3,2,1,4,5,6,7,10,9}构建二叉排序树的过程来详细介绍上面的四种调整关系: 首先3,2先正常的构建，但是在插入1时，应该插入到2的左子树，这时3的BF因子为2，不满足平衡条件，最小平衡子树为3,2,1。由于BF=2 &gt; 0 所以是LL型调整，所以进行右旋。 接着插入4，平衡因子没有被破坏。接着插入5,这时3的BF因子为-2,2的BF因子也是-2，但是3离插入节点4最近，所以最小非平衡子树为3,4,5,由于由于BF=-2 &lt; 0 所以是RR型调整，所以进行左旋。 接着插入6,7 相信看懂了上面的过程，插入6,7的过程就非常简单了。 接着我们插入10，平衡状态未被破坏。但是插入9时，最小不平衡子树为7,10,9,但是如果直接进行左旋会出现9成为10的右子树，不符合排序二叉树的要求。这时候其实7的BF为-2,10的BF为1，符号不同（之前都是相同）所以需要先统一符号，首先9,10右旋，使得7和9的符号统一为负，再进行7,9,10的左旋。 对于LR型调整，在这个例子中不好描述，我们直接上一个新的例子： 插入节点5时，导致失衡。首先调整3,1,4,5使得BF因子和10同号转化为LL问题，之后再进行右旋。 对于AVL树而言: 因为AVL树中树是完全平衡的，所以平均检索复杂度和最坏检索复杂度都为O(logn) 虽然解决了最坏检索复杂度的问题，但是每次插入和删除时AVL树都会做调整，所以插入和删除效率相对较低。 红黑树(R-B Tree)和平衡二叉树一样，红黑树也是一种自平衡的二叉排序树。也就是说红黑树满足二叉排序树的三点要求，并且和AVL树一样，通过旋转操作进行自身的平衡。但是和AVL树不同的是， 红黑树不严格要求BF=-1,0,1,而是通过对任何一条从根到叶子的路径上各个节点着色的方式的限制,确保左右子树树高差不超过一倍因此它是一种弱平衡二叉树(由于是弱平衡,可以推出,相同的节点情况下,AVL树的高度低于红黑树), 红黑树在每个节点增加一个存储位表示节点的颜色,可以是红色或黑色。它必须满足下面性质： 节点非黑即红。 根节点是黑色。 所有叶子节点都是黑色，并且是NULL节点 每个红色节点的两个子节点都是黑色。（从每个叶子到根的所有路径上不能有两个连续的红色节点） 任意一节点到其每个叶子节点的所有路径都包含相同数目的黑色节点。 红黑树为了维持自身的平衡性主要有两大操作: 1. 重新染色 (重新标记黑色或红色)2. 旋转 (就是我们上面提到的左旋和右旋) 注意这里是有先后顺序的，我们会先尝试重新染色，如果重新染色不能达到红黑树的5点要求，然后我们尝试旋转操作。 这里我们看下重新染色和旋转的规则: 将新插入的节点标记为红色 如果 X 是根结点(root)，则标记为黑色 各种情况的讨论 情况的讨论参考文章:https://zhuanlan.zhihu.com/p/79980618?utm_source=cn.wiz.notehttps://www.cnblogs.com/LiaHon/p/11203229.htmlhttps://www.jianshu.com/p/e136ec79235c 我们以插入 10，20，30，15 到一个空树中，简单介绍一下: AVL树和红黑树对比: 理论上来说相对于要求严格平衡的AVL树来说,红黑树因为不是严格平衡，所以查找的时间复杂度虽然为O(logn),但可能在某些时候不如AVL树。但是也正是由于其弱平衡，并且通过染色的方式对自己进行平衡调整，所以相对来说插入和删除效率比AVL树高。 所以对于只进行查询的操作,肯定是AVL树好，但是除了查询操作外，还要进行插入和删除操作，综合考虑还是选择红黑树。这也是为什么hashmap中使用红黑树而不是AVL树的原因。 多路查找树上面我们提到的树主要用来在内存内进行排序，考虑的是内存那种运算的时间复杂度。但是如果数据达到内存中放不下需要存到硬盘上，或者比如我们的MySQL数据库，数据本身就存储在硬盘上。那么我们更多的需要考虑的就是如何减少对磁盘的IO访问。 之前我们学习的树中一个节点只能存储一个元素，在元素非常多的时候，要么树的度非常大，要么树的高度非常大，甚至两个必须都必须足够大才行。(AVL树和红黑树度为2，树高非常高) 这就使得需要进行IO访问的次数增多，因此需要打破每一个节点只存储一个元素的限制，因此引入了多路查找树。 多路查找树，其每一个节点的孩子数可以多于两个，且每一个节点处可以存储多个元素。由于它是查找树，所有元素之间存在某种特定的排序关系 这里，每一个节点可以存储多少个元素，以及它的孩子数的多少是非常关键的。其中比较特殊的就是2-3树、2-3-4树、B树、B+树。 2-3树2-3树是这样一棵多路查找树: 每一个节点都是2节点(具有两个孩子)或3节点(三个孩子)。 一个2节点包含一个元素和两个孩子(或没有孩子) 一个3节点包含一小一大两个元素和三个孩子(或没有孩子)。 其中左子树包含小于较小元素的元素 右子树包含大于较大元素的元素 中间子树包含结余两元素之间的元素 2-3树中所有叶子节点位于同一层。 2-3-4树有了2-3树的理解，对于2-3-4树就很好理解了，它其实是2-3树的扩展，包括了4节点的使用。 一个4节点包含小中大三个元素和四个孩子(或没有孩子。如果某个4节点有孩子的话:-左子树包含小于最小元素的元素-第二子树包含大于最小元素，小于第二元素的元素-第三子树包含大于第二元素，小于最大元素的元素-右子树包含大于最大元素的元素 B树B树是一种平衡的多路查找树，2-3树和2-3-4树都是B树的特例。节点最大的孩子数目称为B树的阶，因此2-3树是3阶B树，2-3-4树是4阶B树。 一个m阶B树具有如下性质: 根节点的儿子数量范围[2,m] 每个中间节点包含 k-1 个关键字和 k 个孩子，孩子的数量 = 关键字的数量 +1，k 的取值范围为 [ceil(m/2), m]。 叶子节点位于同一层，且叶子节点包括 k-1 个关键字（叶子节点没有孩子），k 的取值范围为 [ceil(m/2), m]。 假设中间节点节点的关键字为：Key[1], Key[2], …, Key[k-1]，且关键字按照升序排序，即 Key[i]&lt;Key[i+1]。此时 k-1 个关键字相当于划分了 k 个范围，也就是对应着 k个指针，即为：P[1], P[2], …, P[k]，其中 P[1] 指向关键字小于 Key[1] 的子树，P[i] 指向关键字属于 (Key[i-1], Key[i]) 的子树，P[k] 指向关键字大于 Key[k-1] 的子树。 图片来自文章 https://mp.weixin.qq.com/s/k4-RaW4ROlo6chSXsO_4AA 举个例子上图为三阶图，查看磁盘3，关键字为20，30.三个孩子分别是(18,19),(22,25),(32,36).其中(18,19)小于20，(22,25)在(20,30)之间，(32，36)大于30. 如图所示，如果要查找数据项22，那么B树的查找过程如下: 首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确22大于18小于20，得到指向磁盘块3的P2指针。 通过磁盘块3的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，22在20和30之间，得到指向磁盘块9的P2指针。 通过磁块9的P2指针加载磁盘块9到内存，发生第三次IO，同时内存中做二分查找找到22，结束查询，总计三次IO。 上面还是一个简单的例子，假设我们每个磁盘块可以存储1000个数据，那么一个三层的B树能存储的数据量是1000*1000=100w条数据。进行查找时也只需要进行3次IO。 如果是红黑树或者AVL树的话，树高则会非常大，IO次数也无法想象。 B+树从上面可以看到B树优点非常多，但是B树还有一个问题，就是如果我们要对数据进行中序遍历，那么需要在硬盘的页面间进行多次访问，发生多次IO影响效率。比如上面的例子中需要先定位到磁盘块5，得到7 8 发生3次IO，接着读磁盘块2，得到9，又发生一次IO，接着读磁盘块6…. 最终IO次数会非常大，严重影响效率。 因此应文件系统的需要而提出了一种B+树结构。严格意义上来讲B+树已经不是一种树。 一棵m阶B+树和一个m阶B树的差别: 有n棵子树的节点中包含有n个关键字 所有叶子节点包含全部关键字信息，及指向含这些关键字记录的指针，叶子节点本身依关键字的大小自小二大顺序连接 所有非叶子节点中不包含真实数据仅含有其子树中的最大最小关键字。 图片来自文章 https://mp.weixin.qq.com/s/k4-RaW4ROlo6chSXsO_4AA 这样对于中序遍历来说我们需要做的是首先发生3次IO找到最小值10，因为关键字全部在叶子节点，所以就不用访问上层的非叶子节点。找到10之后，直接通过指针直接顺序访问就能得到中序遍历的结果。 上面提到的中序遍历最终还是用来进行排序和范围查找。比如我们要找18到32之间的数据，首先发生3次IO定位到18所在的磁盘块8，然后顺序读取到32即可。只发生3+2=5次IO，这也是为什么MySQL数据库中使用B+树结构来做索引的原因。","link":"/2020/04/29/%E4%BA%8C%E5%8F%89%E6%8E%92%E5%BA%8F%E6%A0%91%E3%80%81%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%E3%80%81%E7%BA%A2%E9%BB%91%E6%A0%91%E3%80%81B%E6%A0%91%E3%80%81B-%E6%A0%91/"},{"title":"数据结构的时间复杂度总结","text":"基本数据结构的复杂度总结表格 之前我们学习了基本的数据结构，但是我很少提到时间复杂度，是因为每个都写一下，实在是太麻烦了，而且有时候容易忘。所以这里给一个表格总结。 需要的时候过来查一查就好了。 注意: Access是访问，Search是查找。不要弄混了哦","link":"/2020/05/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%80%BB%E7%BB%93/"},{"title":"线性表之数组、链表、栈、队列、堆","text":"主要内容 线性表的基本概念 数组和链表 栈和队列 优先队列和堆 线性表的基本概念线性表：零个或多个数据元素的有限序列 这里需要注意的是有限序列，是说线性表是有顺序的。比如下面的线性表中，a1为a2的直接前驱元素，a2为a1的直接后继元素。并且除了开始元素(只有一个后继元素)和结束元素(只有一个前驱元素)外每个元素有且只有一个前驱元素和一个后继元素。 线性表是逻辑结构，根据其物理结构的不同分为顺序结构（数组）和链式存储结构（链表） 数组和链表数组线性表的顺序存储结构，指的是用一段地址连续的存储单元依次存储线性表的数据元素 Java中ArrayList和数组的主要区别在于ArrayList是可变长度，数组是不可变长度。 数组很简单，这里简单介绍下: 内存空间连续 通过下标可以直接获取元素(初始下标为0)，时间复杂度为O(1)。 插入和删除元素，则需要进行数组内元素的移动，因此插入和删除的时间复杂度为O(n)。 简单手工实现一下ArrayList 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class MyArrayList &lt;E&gt;{ private Object[] elementData; private int size; private final int DEFAULT_SIZE = 10; public MyArrayList(int initsize){ if(initsize&gt;=0){ elementData = new Object[initsize]; }else{ throw new IllegalArgumentException(\"初始长度不正确\"+ initsize); } } public MyArrayList(){ elementData = new Object[DEFAULT_SIZE]; } //添加元素 public boolean add(E element){ ensureCapacity(); //扩容机制 elementData[size] = element; size++; return true; } //指定位置添加元素 public boolean add(int index,E element){ rangeCheck(index); ensureCapacity(); //需要进行数组的拷贝工作，效率较低 System.arraycopy(elementData,index,elementData,index+1,size-index); elementData[index] = element; size++; return true; } //通过下标删除 public E remove(int index){ rangeCheck(index); E oldValue = (E) elementData[index]; System.arraycopy(elementData,index+1,elementData,index,size-index); size--; return oldValue; } //通过元素删除 public boolean remove(Object o){ for (int i = 0; i &lt; elementData.length; i++) { if (o.equals(elementData[i])){ System.arraycopy(elementData,i+1,elementData,i,size-i); size--; return true; } } return false; } //查找 public E get(int index){ rangeCheck(index); return (E) elementData[index]; } //数组长度 public int size(){ return size; } //是否为空 public boolean isEmpty(){ return size==0?true:false; } //******************************************** //扩容过程 先创建新数组，然后复制原数组，最后让原数组指向新数组 private void ensureCapacity(){ if(elementData.length-1&gt;=size){ Object[] newArray = new Object[elementData.length+(elementData.length&gt;&gt;1)]; //右移一位相当于除以2 System.arraycopy(elementData,0,newArray,0,elementData.length); //数组拷贝 elementData = newArray; } } //索引检查 private void rangeCheck(int index){ if(index&lt;0||index&gt;=size){ throw new IndexOutOfBoundsException(\"索引不合法\"+index); } } } 单链表 由节点构成，每个节点包含数据元素和指向下一个节点的指针。 内存空间可以连续，也可以不连续。 查找时，需要从头结点开始遍历链表，时间复杂度O(n) 插入和删除时，时间复杂度O(1) 123456789101112131415161718192021222324252627282930313233343536public class MySingleLinkedList&lt;E&gt; { //结点内部类 private class Node&lt;E&gt; { public E element; //元素 private Node&lt;E&gt; next; //指向下一个节点的指针 public Node(){ } public Node(E element){ this.element = element; } } private Node&lt;E&gt; head; //头结点 private int size; //元素总数 public MySingleLinkedList(){ head = new Node&lt;E&gt;(); //默认初始化为null }``` 上面提到的是链表中的节点的插入和删除操作，涉及到链表头和链表尾的特殊情况，操作是相同的。&lt;div align=\"center\"&gt;&lt;img src=\"http://coderchen33.life/2020-04-29-基本数据结构之数组、链表、栈、队列-2020-05-02-16-52-09\"&gt;&lt;/div&gt;&lt;br&gt;添加元素```javapublic void add(E element){ Node&lt;E&gt; newNode = new Node&lt;E&gt;(element); Node&lt;E&gt; temp = head; while(temp.next!=null){ temp = temp.next; } newNode.next = temp.next; //注意顺序 temp.next = newNode; size++;} 删除元素 12345678910111213public E remove(){ if (size==0){ throw new IndexOutOfBoundsException(\"链表为空\"); } Node&lt;E&gt; temp = head; while(temp.next.next!=null){ temp = temp.next; } E oldElement = temp.next.element; temp.next = null; size--; return oldElement;} 双向链表单链表虽然有很多优点，但是也存在一些问题，比如上面的a,b,c,d,e链表，如果我们遍历到d时，想往回走去找c，那么单链表只能重新从头开始遍历到c。为了解决单链表的单向性，才有了双向链表。 双向链表和单向链表基本相同，唯一区别在于在单向链表的基础上，每个节点增加了一个指向前驱节点的指针。 123456789101112131415161718192021public class MyDoubleLinkedList&lt;E&gt; { private class Node&lt;E&gt;{ public E element; //元素值 private Node&lt;E&gt; prior; //直接前驱指针 private Node&lt;E&gt; next; //直接后继指针 public Node(){ } public Node(E element) { this.element = element; } } private Node&lt;E&gt; head; //头结点 private int size; //链表长度 默认初始化为0 public MyDoubleLinkedList(){ head = new Node&lt;E&gt;(); head.prior = head; //初始全为空 head.next = head; } 双向链表进行插入和删除时需要改变两个指针变量: 添加元素 123456789public void add(E element){ Node&lt;E&gt; newNode = new Node&lt;&gt;(element); Node&lt;E&gt; temp = head.prior; newNode.prior = temp; newNode.next = temp.next; temp.next.prior = newNode; temp.next = newNode; size++;} 删除元素 1234567public E remove(){ Node&lt;E&gt; temp = head.prior; temp.prior.next = temp.next; temp.next.prior = temp.prior; size--; return temp.element;} 栈和队列栈栈是限定近在表位进行插入和删除操作的线性表。栈最重要的性质就是后进先出，即LIFO(Last In First Out)。 顺序栈 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//静态栈的顺序存储public class MyStack&lt;E&gt; { private Object[] elements; //使用数组存储栈 private int top; //栈顶标识 private int size; //当前栈的大小 private final int DEFAULT_CAPACITY = 30; //默认初始化长度为30 /** * 初始化一个空栈 */ public MyStack(){ elements = new Object[DEFAULT_CAPACITY]; top = -1; //top=-1时表示空栈 } /** * 入栈 * @param element 元素值 */ public void push(E element) { if (size&lt;DEFAULT_CAPACITY) { elements[top + 1] = element; top++; }else{ throw new OutOfMemoryError(\"栈内存不足\"); } } /** * 出栈 */ public void pop(){ if(top==-1){ throw new NullPointerException(\"栈为空栈\"); }else{ top--; } } /** * 获取栈顶元素 * @return 栈顶元素值 */ public E peek(){ if(top==-1){ throw new NullPointerException(\"栈为空栈\"); }else{ return (E)elements[top]; } } /** * 栈实际大小 * @return */ public int size(){ return top+1; }} 链栈 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//静态链栈public class MyLinkStack&lt;E&gt; { private class Node&lt;E&gt;{ public E element; private Node&lt;E&gt; next; public Node(E element){ this.element = element; } } private Node&lt;E&gt; top; private int size; public MyLinkStack(){ top = null; } /** * 入栈 * @param element 栈元素值 */ public void push(E element){ Node&lt;E&gt; newNode = new Node&lt;&gt;(element); newNode.next = top; top = newNode; size++; } /** * 出栈 * @return 出栈元素 */ public E pop() { if(top==null){ throw new NullPointerException(\"栈为空栈\"); }else{ Node&lt;E&gt; temp = top; top = top.next; temp.next = null; size--; return temp.element; } } /** * 取得栈顶元素 * @return 栈顶元素值 */ public E peek(){ if(top==null){ throw new NullPointerException(\"栈为空栈\"); }else{ return top.element; } } /** * 获得链栈长度 * @return 链栈长度 */ public int getSize(){ return size; }} 队列队列是只允许在一端进行插入操作，另一端进行删除操作的线性表。 队列最重要的性质就是先进先出，即FIFO(First In First Out)。 顺序循环队列 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class MyCircleQueue&lt;E&gt; { private final int MAX_SIZE = 10; //最大长度为10(为了演示方便) private Object[] elements; //定义一个数组用来存储元素 private int front; //头指针 private int rear; //尾指针 public MyCircleQueue(){ elements = new Object[MAX_SIZE]; front = 0; rear = 0; } /** * 入队列 */ public void EnQueue(E element){ if((rear+1)%MAX_SIZE==front){ //判断队列是否已满条件 throw new IndexOutOfBoundsException(\"队列已满\"); }else{ elements[rear] = element; rear = (rear+1)%MAX_SIZE; //队列满的话移到数组开始位置 } } /** * 出队列 */ public E DeQueue(){ if(rear==front){ throw new NullPointerException(\"队列为空\"); }else{ E OldElement = (E)elements[front]; front = (front+1)%MAX_SIZE; return OldElement; } } /** * 获得队列长度 */ public int getSize(){ return (rear-front+MAX_SIZE)%MAX_SIZE; //队列长度通用公式 } /** * 获得队列头部元素 */ public E get(){ return (E)elements[front]; } /** * 队列是否为空 */ public boolean isEmpty(){ return rear==front; }} 链队列 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class MyLinkQueue&lt;E&gt; { private class Node{ private E element; private Node next; public Node(){ } public Node(E element){ this.element = element; } } private Node front; private Node rear; private int size; public MyLinkQueue(){ front = new Node(); rear = front; } /** * 入队 */ public void EnQueue(E element) { Node newNode = new Node(element); rear.next = newNode; rear = newNode; size++; } /** * 出队 */ public E DeQueue(){ if(front==rear){ throw new NullPointerException(\"队列为空\"); }else{ Node OldNode = front.next; front.next = OldNode.next; if(rear==OldNode){ rear = front; } size--; return OldNode.element; } } /** * 获得链队列长度 */ public int getSize(){ return size; } /** * 返回队列头部元素 */ public E get(){ return front.next.element; }} 优先队列和堆优先队列(priority queue)优先队列:优先队列也是队列，正常入队列，但是出队列按照优先级出 (优先级通常是最大、最小值，当然其他的优先级比如出现次数等也可以) 优先队列的操作也很简单: 删除优先级最高的元素 插入带有优先级的元素 优先队列的实现: 无序数组 插入O(1),查找O(n) (了解即可) AVL树或者红黑树 插入删除O(logn) 查找O(1) 构建O(nlogn) (有时会用) 更加常用的是使用堆来实现 插入删除O(logn) 查找O(1) 构建O(n) 因为经常是堆来实现优先队列，所以人们经常弄错堆和优先队列的关系。这里贴上维基百科的解释: While priority queues are often implemented with heaps, they are conceptually distinct from heaps. A priority queue is a concept like “a list” or “a map”; just as a list can be implemented with a linked list or an array, a priority queue can be implemented with a heap or a variety of other methods such as an unordered array. 也就是说优先队列是我们的list和map级别，而堆就是我们的arrayList、linkedList以及hashMap级别。 堆(heap)堆是一棵具有特定性质的二叉树: 每个结点的值都大于或等于其左右孩子结点的值(大顶堆）或者每个结点的值都小于或等于其左右孩子结点的值(小顶堆)。 当h=0时，所有叶子节点都处于第h或h-1层，所以堆是一棵完全二叉树 当每个节点最多只有两个孩子时称为二叉堆，下面的就是二叉小顶堆和二叉大顶堆 1234567891011121314151617181920212223242526272829303132333435363738public class Heap&lt;T&gt; { private T[] heap; private int N = 0; public Heap(int maxN) { this.heap = new T[maxN]; } //添加元素 public void insert(T t){ heap[++N] = t; shiftUp(N); } //删除元素 public T delMax(){ T max = heap[1]; //从根节点得到最大元素 swap(1,N--); //将其和最后一个节点交换 heap[N+1] = null; //防止越界 shiftDown(1); //进行下沉操作 return max; } public int size() { return N; } private boolean less(int i, int j) { return heap[i]&lt;(heap[j]); } private void swap(int i, int j) { T t = heap[i]; heap[i] = heap[j]; heap[j] = t; }} 关于堆的插入和删除操作时的维护过程简单概括下就是:1.堆插入时进行上浮操作 12345678910//上浮操作就是不断跟父节点比较，从而交换到合适位置// 这里要注意一下//1. k是新插入元素在数组中的下标//2. less（）函数是比较堆中两个数的大小private void shiftUp(int k) { while (k &gt; 1 &amp;&amp; less(k / 2, k)) { //k节点的父节点位置为k/2 swap(k / 2, k); k = k / 2; }} 2.堆删除时进行下沉操作 12345678910111213//下沉操作就是比较其跟孩子节点的大小private void shiftDown(int k) { while (2 * k &lt;= N) { int j = 2 * k; //和两个孩子节点中值大的交换 if (j &lt; N &amp;&amp; less(j, j + 1)) j++; if (!less(k, j)) break; swap(k, j); k = j; }} 详细过程图片可以参考下面的文章: https://en.wikipedia.org/wiki/Heap_(data_structure) https://www.cnblogs.com/wmyskxz/p/9301021.html 我们上面学习的二叉堆效率不是很高，实际上还有很多类型的堆，他们的效率非常高高。下表以最小堆为例，给出了各种堆结构的时间复杂度: 我们知道堆查找时都是O(1),主要性能的差异就在插入和删除后的维护过程。从上面我们可以看到二叉堆的效率相对较差，而斐波那契堆等的效率最好。","link":"/2020/04/29/%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E6%95%B0%E7%BB%84%E3%80%81%E9%93%BE%E8%A1%A8%E3%80%81%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97/"},{"title":"数据库设计","text":"函数依赖异常三大范式第一范式(1NF)第二范式(2NF)第三范式(3NF)ER图数据库设计流程按照规范设计，将数据库的设计过程分为六个阶段： 系统需求分析阶段 概念结构设计阶段 逻辑结构设计阶段 物理结构设计阶段 数据库实施阶段 数据库运行与维护阶段 需求分析和概念结构设计独立于任何数据库管理系统。","link":"/2020/04/27/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1/"},{"title":"leetcode哈希表练习","text":"哈希表相关tips:1.哈希表主要作用有两个：(1)去重 (2)检索时间复杂度O(1)2.需要存储key的次数或者索引时使用HashMap 1.两数之和1. Two Sum (Easy) 1234567891011121314class Solution { public int[] twoSum(int[] nums, int target) { int[] res = new int[2]; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for(int i=0;i&lt;nums.length;i++){ int temp = target-nums[i]; if(map.containsKey(temp)){ res[0] = map.get(temp); res[1] = i; }else map.put(nums[i],i); } return res; }} 2.判断数组是否含有重复元素217. Contains Duplicate (Easy) 12345678910class Solution { public boolean containsDuplicate(int[] nums) { Set&lt;Integer&gt; set = new HashSet&lt;&gt;(); for(int num: nums){ if(set.contains(num)) return true; set.add(num); } return false; }} 3.判断数组是否含有重复元素II219. Contains Duplicate II 12345678910class Solution { public boolean containsNearbyDuplicate(int[] nums, int k) { Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for(int i=0;i&lt;nums.length;i++){ if(map.containsKey(nums[i]) &amp;&amp; Math.abs(i-map.get(nums[i]))&lt;=k) return true; map.put(nums[i],i); } return false; }} 4.有效的字母异位词242. Valid Anagram (Easy) 12345678910class Solution { public boolean isAnagram(String s, String t) { //hashset不能解决ab、a问题 int[] alphabet = new int[26]; for (int i = 0; i &lt; s.length(); i++) alphabet[s.charAt(i) - 'a']++; for (int i = 0; i &lt; t.length(); i++) alphabet[t.charAt(i) - 'a']--; for (int i : alphabet) if (i != 0) return false; return true; }} 5.最长和谐序列594. Longest Harmonious Subsequence (Easy) 123456789101112131415class Solution { public int findLHS(int[] nums) { int res = 0; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for(int num:nums){ map.put(num,map.getOrDefault(num,0)+1); } for(int num:map.keySet()){ if(map.containsKey(num+1)){ res = Math.max(res,map.get(num)+map.get(num+1)); } } return res; }} 6.最长连续序列128. Longest Consecutive Sequence (Hard) 123456789101112131415161718192021class Solution { public int longestConsecutive(int[] nums) { int res = 0; Set&lt;Integer&gt; set = new HashSet&lt;&gt;(); for(int num:nums){ set.add(num); } for(int num:set){ //从之前不连续的第一个开始才可能是最长序列 if(!set.contains(num-1)){ int count = 1; while(set.contains(num+1)){ count++; num++; } res = Math.max(res,count); } } return res; }}","link":"/2020/05/16/leetcode%E5%93%88%E5%B8%8C%E8%A1%A8%E7%BB%83%E4%B9%A0/"},{"title":"leetcode图结构练习","text":"","link":"/2020/06/06/leetcode%E5%9B%BE%E7%BB%93%E6%9E%84%E7%BB%83%E4%B9%A0/"},{"title":"leetcode树结构练习","text":"树结构练习题的tips: 整体而言，因为树结构是递归定义的，所以涉及到树的问题一般可以用递归进行解决。 对于树的前中后序遍历一定要掌握递归方法和非递归方法(深搜DFS使用栈解决)。 二叉树的层次遍历的 非递归方法(广搜BFS使用队列解决) 也需要掌握(因为是层次遍历,所以不存在递归地方法)。 对于二叉查找树BST而言，主要考点就两个: (1)BST的定义（①左子树节点均小于根节点的值 ②右子树的节点均大于根节点的值 ③左右子树也是一个平衡二叉树）(2)二叉查找树的中序遍历是一个递增序列。也正是因为定义的递归性，涉及到BST的问题，通常也是用递归解决。 建议练习前先看我的关于树的文章: 树的基本概念和前中后序遍历 二叉排序树、平衡二叉树、红黑树、B树、B+树 二叉树前中后序遍历 前序遍历144. Binary Tree Preorder Traversal (Medium) 后续遍历:145. Binary Tree Postorder Traversal (Hard) 中序遍历:94. Binary Tree Inorder Traversal (Medium) 1.递归实现二叉树的前中后序遍历① 前序 12345678910111213class Solution { public List&lt;Integer&gt; preorderTraversal(TreeNode root) { List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); helpPre(root,res); return res; } private void helpPre(TreeNode root,List&lt;Integer&gt; res){ if(root ==null) return; res.add(root.val); //访问根节点 helpPre(root.left,res); //访问左子树 helpPre(root.right,res); //访问右子树 }} ② 后序 12345678910111213class Solution { public List&lt;Integer&gt; postorderTraversal(TreeNode root) { List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); helpPost(root,res); return res; } private void helpPost(TreeNode root,List&lt;Integer&gt; res){ if(root == null) return; helpPost(root.left,res); //访问左子树 helpPost(root.right,res); //访问右子树 res.add(root.val); //访问根节点 }} ③ 中序 12345678910111213class Solution { public List&lt;Integer&gt; inorderTraversal(TreeNode root) { List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); helpInorder(root,res); return res; } private void helpInorder(TreeNode root,List&lt;Integer&gt; res){ if(root ==null) return; helpInorder(root.left,res); //左子树 res.add(root.val); //根节点 helpInorder(root.right,res); //右子树 }} 2.非递归实现二叉树的前中后序遍历前中后序遍历使用深度优先搜索DFS实现 ① 前序 12345678910111213141516class Solution { public List&lt;Integer&gt; preorderTraversal(TreeNode root) { List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(root == null) return res; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); while(!stack.isEmpty()){ TreeNode node = stack.pop(); res.add(node.val); //先入栈右子树，保证左子树能够先被遍历 if(node.right !=null) stack.push(node.right); if(node.left != null) stack.push(node.left); } return res; }} ② 后序前序遍历为 root -&gt; left -&gt; right，后序遍历为 left -&gt; right -&gt; root。可以将前序遍历的代码改为root -&gt; right -&gt; left，那么这个顺序就和后序遍历正好相反，再反转链表即可得到后序遍历的结果。 12345678910111213141516class Solution { public List&lt;Integer&gt; postorderTraversal(TreeNode root) { List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(root==null) return res; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); while(!stack.isEmpty()){ TreeNode node = stack.pop(); res.add(node.val); if(node.left!=null) stack.push(node.left); if(node.right!=null) stack.push(node.right); } Collections.reverse(res); //反转链表 return res; }} ③ 中序 123456789101112131415161718class Solution { public List&lt;Integer&gt; inorderTraversal(TreeNode root) { List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); if(root == null) return res; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); TreeNode cur = root; while (cur != null || !stack.isEmpty()) { while (cur != null) { stack.push(cur); cur = cur.left; } TreeNode node = stack.pop(); res.add(node.val); cur = node.right; } return res; }} 二叉树层次遍历层次遍历使用 广度优先搜索(BFS)实现，利用的就是 BFS 一层一层遍历的特性 1.二叉树的层次遍历102. Binary Tree Level Order Traversal (Medium) 1234567891011121314151617181920class Solution { public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) { List&lt;List&lt;Integer&gt;&gt; list = new ArrayList&lt;&gt;(); if(root == null) return list; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while(!queue.isEmpty()){ int levNum = queue.size(); List&lt;Integer&gt; subList = new ArrayList&lt;&gt;(); for(int i=0;i&lt;levNum;i++){ TreeNode node = queue.poll(); subList.add(node.val); if(node.left != null) queue.offer(node.left); if(node.right != null) queue.offer(node.right); } list.add(subList); } return list; }} 2.二叉树每层节点的平均数637. Average of Levels in Binary Tree(easy) 12345678910111213141516171819class Solution { public List&lt;Double&gt; averageOfLevels(TreeNode root) { List&lt;Double&gt; res = new ArrayList&lt;&gt;(); Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while(!queue.isEmpty()){ int levNum = queue.size(); double sum = 0; for(int i=0;i&lt;levNum;i++){ TreeNode node = queue.poll(); sum+=node.val; if(node.left != null) queue.offer(node.left); if(node.right != null) queue.offer(node.right); } res.add(sum/levNum); } return res; }} 3.得到二叉树左下角的值513.Find Bottom Left Tree Value(Medium) 1234567891011121314class Solution { public int findBottomLeftValue(TreeNode root) { int res = 0; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while(!queue.isEmpty()){ TreeNode node = queue.poll(); res = node.val; if(node.right!=null) queue.offer(node.right); if(node.left!=null) queue.offer(node.left); } return res; }} 平衡二叉树BST1.判断是否是二叉搜索树98. Validate Binary Search Tree (Medium) 12345678910class Solution { public boolean isValidBST(TreeNode root) { return isBSTHelper(root,Long.MIN_VALUE,Long.MAX_VALUE); } private boolean isBSTHelper(TreeNode node,long lower,long upper){ if(node == null) return true; if(node.val &lt;= lower || node.val &gt;= upper) return false; return isBSTHelper(node.left,lower,node.val) &amp;&amp; isBSTHelper(node.right,node.val,upper); }} 2.二叉搜索树最近公共祖先235. Lowest Common Ancestor of a Binary Search Tree (Easy) 递归法： 1234567class Solution { public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { if(root.val&gt;p.val &amp;&amp; root.val&gt;q.val) return lowestCommonAncestor(root.left,p,q); if(root.val&lt;p.val &amp;&amp; root.val&lt;q.val) return lowestCommonAncestor(root.right,p,q); return root; }} 迭代法： 1234567891011class Solution { public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { TreeNode cur = root; while(cur != null){ if(cur.val&gt;p.val &amp;&amp; cur.val&gt;q.val) cur = cur.left; else if(cur.val&lt;p.val &amp;&amp; cur.val&lt;q.val) cur = cur.right; else return cur; } return null; }} 3.二叉树最近公共祖先236. Lowest Common Ancestor of a Binary Tree (Medium) 123456789class Solution { public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { if(root ==null || root == p || root == q) return root; TreeNode left = lowestCommonAncestor(root.left,p,q); TreeNode right = lowestCommonAncestor(root.right,p,q); if(left != null &amp;&amp; right !=null) return root; return left==null?right:left; }} 4. 修剪二叉查找树669.Trim a Binary Search Tree (Easy) 12345678910111213class Solution { public TreeNode trimBST(TreeNode root, int L, int R) { if(root == null) return null; //节点值小于L，则该节点整个左子树的值小于L，丢弃左子树，返回右子树。 if(root.val &lt; L) return trimBST(root.right,L,R); //节点值大于R，则该节点整个右子树的值大于R，丢弃右子树，返回左子树。 if(root.val &gt; R) return trimBST(root.left,L,R); //节点值符合要求，则向下传递递归调用 root.left = trimBST(root.left, L, R); root.right = trimBST(root.right, L, R); return root; }} 5.寻找二叉查找树的第k小的元素230.Kth Smallest Element in a BST (Medium) 123456789101112131415class Solution { private int res; private int count; public int kthSmallest(TreeNode root, int k) { inorder(root,k); return res; } private void inorder(TreeNode root,int k){ if(root==null) return; inorder(root.left,k); count++; if(count==k) res = root.val; inorder(root.right,k); }} 6.把二叉查找树每个节点的值都加上比它大的节点的值538. Convert BST to Greater Tree(Easy) 1234567891011class Solution { private int sum=0; public TreeNode convertBST(TreeNode root) { if(root==null) return null; convertBST(root.right); sum+=root.val; root.val = sum; convertBST(root.left); return root; }} 7.从有序数组中构造平衡二叉树108.Convert Sorted Array to Binary Search Tree (Easy) 123456789101112131415class Solution { public TreeNode sortedArrayToBST(int[] nums) { return helper(nums,0,nums.length-1); } private TreeNode helper(int[] nums,int lo,int hi){ if(lo &gt; hi) return null; int mid = lo + (hi - lo)/2; TreeNode left = helper(nums,lo,mid-1); TreeNode root = new TreeNode(nums[mid]); TreeNode right = helper(nums,mid+1,hi); root.left = left; root.right = right; return root; }} 8.从有序链表中构造二叉查找树109. Convert Sorted List to Binary Search Tree (Medium) 123456789101112131415161718192021222324class Solution { private ListNode head; public TreeNode sortedListToBST(ListNode head) { this.head = head; int length = 0; ListNode cur = head; while(cur != null){ cur = cur.next; length++; } return helper(0,length-1); } private TreeNode helper(int lo,int hi){ if(lo&gt;hi) return null; int mid = lo + (hi-lo)/2; TreeNode left = helper(lo,mid-1); TreeNode root = new TreeNode(head.val); head = head.next; //注意对当前元素操作完成后需要指向下一个元素 TreeNode right = helper(mid+1,hi); root.left = left; root.right = right; return root; }} 9.在二叉查找树中寻找两个节点，使它们的和为一个给定值653. Two Sum IV - Input is a BST (Easy) 123456789101112class Solution { public boolean findTarget(TreeNode root, int k) { Set&lt;Integer&gt; set = new HashSet&lt;&gt;(); return helper(root,k,set); } private boolean helper(TreeNode root,int k,Set&lt;Integer&gt; set){ if(root == null) return false; if(set.contains(k-root.val)) return true; set.add(root.val); return helper(root.left,k,set) || helper(root.right,k,set); }} 10.在二叉查找树中查找两个节点之差的最小绝对值530.Minimum Absolute Difference in BST (Easy) 123456789101112class Solution { private int min = Integer.MAX_VALUE; private TreeNode prev = null; public int getMinimumDifference(TreeNode root) { if(root == null) return min; getMinimumDifference(root.left); if(prev != null) min = Math.min(min,root.val-prev.val); prev = root; getMinimumDifference(root.right); return min; }} 递归1.二叉树的最大深度104. Maximum Depth of Binary Tree (Easy) 123456789101112131415/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public int maxDepth(TreeNode root) { if(root==null){return 0;} return Math.max(maxDepth(root.left),maxDepth(root.right))+1; }} 2.二叉树的最小深度111. Minimum Depth of Binary Tree (Easy) 1234567891011121314151617/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public int minDepth(TreeNode root) { if(root == null){return 0;} int left = minDepth(root.left); int right = minDepth(root.right); return (left==0 || right==0)? left+right+1 : Math.min(left,right) + 1; }} 3.平衡二叉树110. Balanced Binary Tree (Easy) 12345678910111213141516171819/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public boolean isBalanced(TreeNode root) { if(root == null) return true; return isBalanced(root.left) &amp;&amp; isBalanced(root.right) &amp;&amp; (Math.abs(maxDepth(root.left)-maxDepth(root.right))&lt;=1); } private int maxDepth(TreeNode root){ if(root == null) return 0; return 1+Math.max(maxDepth(root.left),maxDepth(root.right)); }} 4.二叉树翻转226. Invert Binary Tree (Easy) 12345678910111213141516171819/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public TreeNode invertTree(TreeNode root) { if(root == null) return null; TreeNode left = invertTree(root.left); TreeNode right = invertTree(root.right); root.left = right; root.right = left; return root; }} 5.归并两个二叉树617. Merge Two Binary Trees (Easy) 12345678910111213141516171819/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public TreeNode mergeTrees(TreeNode t1, TreeNode t2) { if (t1 == null) return t2; if (t2 == null) return t1; t1.val = t1.val + t2.val; t1.left = mergeTrees(t1.left,t2.left); t1.right = mergeTrees(t1.right,t2.right); return t1; }} 6.路径和112. Path Sum (Easy)递归求解： 12345678910111213141516/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public boolean hasPathSum(TreeNode root, int sum) { if(root==null) return false; if(root.left==null &amp;&amp; root.right==null &amp;&amp;sum-root.val==0) return true; return hasPathSum(root.left,sum-root.val) || hasPathSum(root.right,sum-root.val); }} 非递归求解： 1234567891011121314151617181920212223242526272829303132333435/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public boolean hasPathSum(TreeNode root, int sum) { if(root==null) return false; Stack&lt;TreeNode&gt; nodeStack = new Stack&lt;&gt;(); Stack&lt;Integer&gt; sumStack = new Stack&lt;&gt;(); nodeStack.push(root); sumStack.push(root.val); while(!nodeStack.isEmpty()){ TreeNode node = nodeStack.pop(); int nodeVal = sumStack.pop(); if(node.left==null &amp;&amp; node.right==null &amp;&amp; nodeVal==sum){ return true; }else{ if(node.left!=null){ nodeStack.push(node.left); sumStack.push(node.left.val+nodeVal); } if(temp.right!=null){ nodeStack.push(node.right); sumStack.push(node.right.val+nodeVal); } } } return false; }} 7.路径和II113. Path Sum II (Medium) 1234567891011121314151617181920class Solution { public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int sum) { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); helper(root,sum,new ArrayList&lt;&gt;(),res); return res; } private void helper(TreeNode root,int sum,List&lt;Integer&gt; subList,List&lt;List&lt;Integer&gt;&gt; res){ if(root == null) return; subList.add(root.val); if(root.left==null &amp;&amp; root.right==null &amp;&amp; sum-root.val==0){ res.add(new ArrayList&lt;&gt;(subList)); } helper(root.left,sum-root.val,subList,res); helper(root.right,sum-root.val,subList,res); //如果路径和等于目标值会直接将subList加入到最终的结果中 //但是如果执行两个子递归后仍无法得到目标值，则说明当前root节点无法引导我们获得正确的值 //将其从subList中删除(回溯的思想) subList.remove(subList.size()-1); }} 8.路径和III437. Path Sum III (Easy) 12345678910111213class Solution { public int pathSum(TreeNode root, int sum) { if(root == null) return 0; return helper(root,sum) + pathSum(root.left,sum) + pathSum(root.right,sum); } private int helper(TreeNode root,int sum){ if(root == null) return 0; int res = 0; if(sum-root.val==0) res++; res+= helper(root.left,sum-root.val)+helper(root.right,sum-root.val); return res; }} 9.判断树是否是另一个数的子树572. Subtree of Another Tree (Easy) 123456789101112class Solution { public boolean isSubtree(TreeNode s, TreeNode t) { if(s==null) return false; return helper(s,t) || isSubtree(s.left,t) || isSubtree(s.right,t); } private boolean helper(TreeNode s, TreeNode t){ if(t==null &amp;&amp; s==null) return true; if(t==null || s== null) return false; if(t.val!=s.val) return false; return helper(s.left,t.left) &amp;&amp; helper(s.right,t.right); }} 10.树的对称101. Symmetric Tree (Easy) 123456789101112class Solution { public boolean isSymmetric(TreeNode root) { if(root==null) return true; return helper(root.left,root.right); } private boolean helper(TreeNode left,TreeNode right){ if(left==null &amp;&amp; right==null) return true; if(left==null || right==null) return false; if(left.val != right.val) return false; return helper(left.left,right.right) &amp;&amp; helper(left.right,right.left); }} 11.左叶子结点的和404. Sum of Left Leaves (Easy) 12345678910class Solution { public int sumOfLeftLeaves(TreeNode root) { if(root == null) return 0; int res = 0; if(root.left!=null &amp;&amp; root.left.left==null &amp;&amp; root.left.right==null){ res+=root.left.val; } return res+sumOfLeftLeaves(root.left)+sumOfLeftLeaves(root.right); }} 12.二叉树最大路径和124. Binary Tree Maximum Path Sum(Hard) 对于每个节点，我们都会从两个方面思考 是路径的root，此时的最大值来自于node.left+node.right 不是路径的root，此时的最大值来自于node.left或node.right 1234567891011121314class Solution { private int max = Integer.MIN_VALUE; public int maxPathSum(TreeNode root) { helper(root); return max; } private int helper(TreeNode root){ if(root==null) return 0; int left = Math.max(0,helper(root.left)); int right = Math.max(0,helper(root.right)); max = Math.max(max,left+right+root.val); return Math.max(left,right)+root.val; }} 13.二叉树两结点最长路径543. Diameter of Binary Tree (Easy) 12345678910111213141516class Solution { private int max; public int diameterOfBinaryTree(TreeNode root) { depthHelper(root); //题目规定最大值是节点数-1 return max-1; } private int depthHelper(TreeNode root){ if(root == null) return 0; int left = depthHelper(root.left); int right = depthHelper(root.right); //这里记录的是节点数 max = Math.max(max,left+right+1); return Math.max(left,right)+1; }} 14. 相同节点值的最大路径长度687. Longest Univalue Path (Easy) 1234567891011121314151617class Solution { private int max; public int longestUnivaluePath(TreeNode root) { helper(root); return max; } private int helper(TreeNode root){ if (root == null) return 0; int left = helper(root.left); int right = helper(root.right); int leftPath = (root.left!=null &amp;&amp; root.left.val== root.val) ? left + 1 : 0; int rightPath = (root.right!=null &amp;&amp; root.right.val == root.val) ? right + 1 : 0; max = Math.max(max, leftPath + rightPath); return Math.max(leftPath, rightPath); }}","link":"/2020/05/16/leetcode%E6%A0%91%E7%BB%93%E6%9E%84%E7%BB%83%E4%B9%A0/"},{"title":"leetcode总结","text":"对leetcode题目进行了分类，完成的会加上链接。 数据结构 数组和链表 栈堆队列 哈希表 树结构 图结构 字符串 位运算 算法思想 二分查找 排序 搜索 双指针 递归和分治 贪心 动态规划 数学","link":"/2020/05/10/leetcode%E6%80%BB%E7%BB%93/"},{"title":"数据库锁理论","text":"主要内容 事务的ACID特性 并发一致性问题 封锁 事务的隔离级别 MVCC+Next-Key Locks 索引和锁 之前我们学习事务时，只是简单的介绍了事务是一组原子性的SQL语句，要么全部执行，要么全部不执行。但仅仅了解这些是不够的。事务的ACID特性和事务的隔离级别等都是十分重要的概念，只有理解清楚这些概念，我们才能根号的使用事务。 事务的ACID特性1.原子性（Atomicity）一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚。这就是事务的原子性。 2.一致性（Consistency） 数据库在事务执行前后是从一个一致性状态转移到另一个一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。 3.隔离性（Isolation）通常来说，一个事务所做的修改在最终提交以前，对其它事务是不可见的。 4.持久性（Durability）一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。 事务的 ACID 特性概念简单，但不是很好理解，主要是因为这几个特性不是一种平级关系： 只有满足一致性，事务的执行结果才是正确的。 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。 事务满足持久化是为了能应对系统崩溃的情况。 并发一致性问题在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。 丢失修改T1和T2两个事务都对一个数据进行修改，T1先修改，T2后修改，T2的修改覆盖了T1的修改。 脏读脏读就是事务可以读取未提交的数据。 T1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。 不可重复读T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。 幻影读当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时会发现其他事物插入了满足查询条件的新数据，这种现象称为幻影读。 T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。 产生并发不一致性问题的主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。 虽然实际使用过程中我们很少自己手动封锁，但是了解了封锁的过程有助于我们更好的理解下面事务的隔离级别。所以我们这里先了解下封锁的相关知识。 封锁封锁粒度MySQL 中提供了两种封锁粒度：行锁和表锁。 顾名思义，表锁就是在用户进行写操作(增删改)时锁定整张表。而行锁就是只锁定需要操作的行。 我们知道锁定的数据量越小，发生锁争用的可能就越小，系统的并发程度就越高。所以行锁的并发性高于表锁。但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。所以行锁的系统开销高于表锁。因此在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。 MySQL中InnoDB引擎使用的是行锁，MyISAM引擎使用的是表锁。 封锁类型(读写锁)互斥锁（Exclusive）:简写为 X 锁，又称写锁。共享锁（Shared）:简写为 S 锁，又称读锁。 一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。 简单一句话就是： 读读共享、 读写 写读 写写互斥 封锁协议一级封锁协议事务T在修改数据A之前必须先对其加X锁，直到事务结束才释放。事务结束包括正常结束（COMMIT）和非正常结束（ROLLBACK）。 注意这里是修改数据时加X锁，读取数据不进行修改时不加锁。所以不能保证可重复读和不读脏数据。 一级封锁协议可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 二级封锁协议在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。 可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 但在二级封锁协议中，由于读完数据后即可释放S锁，所以它不能保证可重复读。 三级封锁协议在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。 可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。 一次封锁or两段锁？一次封锁协议：因为有大量的并发访问，为了预防死锁，一般应用中推荐使用一次封锁法，就是在方法的开始阶段，已经预先知道会用到哪些数据，然后全部锁住，在方法运行之后，再全部解锁。这种方式可以有效的避免循环死锁，但在数据库中却不适用，因为在事务开始阶段，数据库并不知道会用到哪些数据。 InnoDB引擎使用的是两段锁协议，即将事务分成两个阶段，加锁阶段和解锁阶段（所以叫两段锁） 加锁阶段：在该阶段可以申请获得任何数据行的任何类型的锁，但是不能释放锁。比如在对任何数据进行读操作之前要申请并获得S锁，在进行写操作之前要申请并获得X锁。加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。 解锁阶段：事务可以释放任何类型的锁，但是不能加锁。锁只有在执行commit或者rollback时才会释放。 12345# 遵循两段锁协议lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B)# 不遵循两段锁协议lock-x(A)...unlock(A)...lock-s(B)...unlock(B)...lock-s(C)...unlock(C) 图片来自博客 https://tech.meituan.com/2014/08/20/innodb-lock.html 两段锁协议无法避免死锁，但是可以保证事务的并发调度是串行化的（串行化很重要，尤其是在数据恢复和备份的时候）。 串行化调度是指如果一个调度的动作首先是一个事务的所有动作，然后是另一个事务的所有动作。以此类推，而没有动作的混合，就是串行化调度。 事务遵循两段锁协议是保证可串行化调度的充分条件，但不是必要条件。 12345# 遵循两段锁协议 串行化调度lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B)# 不遵循两段锁协议 仍然是串行化调度lock-x(A)...unlock(A)...lock-s(B)...unlock(B)...lock-s(C)...unlock(C) 隐式和显式锁定InnoDB使用两段锁协议，在事务执行过程中，随时都可以锁定，锁只有在执行commit或者rollback时才会释放。这些说的都是隐式锁定，InnoDB会根据隔离级别在需要的时候自动加锁。另外InnoDB也支持通过特定的语句进行显式锁定: 12select ... from table where ? lock in share mode; -- s锁select ... from table where ? for update; -- x锁 乐观锁和悲观锁悲观锁总是假设最坏的情况，每次在拿数据的时候，都认为会被别人修改，所以每次拿数据都会上锁，这样别人想拿这个数据的时候就会阻塞 悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。 我们上面学习的x锁和s锁都是悲观锁。 乐观锁总是假设最好的情况，每次在拿数据的时候，都认为不会被别人修改，所以拿数据的时候都不会上锁，但是在更新的时候会判断一下，在此期间有没有别人更新这个数据 乐观锁，大多是基于数据版本（ Version ）记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。 我们之后要学习的MVCC就是使用了乐观锁的思想。 事务的隔离级别在数据库操作中，为了有效保证并发读取数据的正确性，提出的事务隔离级别。我们的数据库锁，也是为了构建这些隔离级别存在的。 未提交读（READ UNCOMMITTED） 事务中的修改，即使没有提交，对其它事务也是可见的。 提交读（READ COMMITTED） 一个事务只能读取已经提交的事务所做的修改。 可重复读（REPEATABLE READ） 在同一个事务中多次读取同一数据的结果是一样的。MySQL事务的默认隔离级别 可串行化（SERIALIZABLE） 完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞 MySQL数据库能够识别四种隔离级别，并且InnoDB引擎也支持上面四种隔离级别。MySQL默认隔离级别是可重复读，可以通过如下方法设置隔离级别： 12# 查看当前事物级别：SELECT @@tx_isolation; 1234567891011# 设置read uncommitted级别：set session transaction isolation level read uncommitted;# 设置read committed级别：set session transaction isolation level read committed;# 设置repeatable read级别：set session transaction isolation level repeatable read;#设置serializable级别：set session transaction isolation level serializable; 接下来我们通过demo验证一下我们比较常用的提交读和可重复读的隔离级别： 12345678910111213# 建表 CREATE TABLE `class_teacher` ( `id` int(11) NOT NULL AUTO_INCREMENT, `class_name` varchar(100) COLLATE utf8mb4_unicode_ci NOT NULL, `teacher_id` int(11) NOT NULL, PRIMARY KEY (`id`), KEY `idx_teacher_id` (`teacher_id`)) ENGINE=InnoDBCHARSET=utf8# 插数据insert into class_teacher (id,class_name,teacher_id) values(default,'初三一班',1);insert into class_teacher (id,class_name,teacher_id) values(default,'初二一班',2);insert into class_teacher (id,class_name,teacher_id) values(default,'初二二班',2); 首先我们来看提交读级别下的不可重复读： 1234# 设置为提交读级别set session transaction isolation level read committed;# 关闭自动提交set autocommit = 0; 事务B修改id=1的数据提交之后，事务A同样的查询，后一次和前一次的结果不一样，这就是不可重读（重新读取产生的结果不一样）。这就很可能带来一些问题。 接着我们来看看在可重复读级别中MySQL的表现： 12# 设置为可重复读级别set session transaction isolation level repeatable read; 我们注意到，当teacher_id=1时，事务A先做了一次读取，事务B中间修改了id=1的数据，并commit之后，事务A第二次读到的数据和第一次完全相同。所以说它是可重读的。 多版本并发控制(MVCC)之前我们已经了解了事务的隔离级别，那么数据库是如何实现这种隔离级别的呢？ 实际上基于提升并发性能的考虑，大部分数据库是通过实现多版本并发控制(MVCC)这种乐观锁的方法来进行并发的保证，而不是简单的使用我们上面提到的x锁和s锁。因为MVCC没有一个统一的实现标准，所以我们这里主要介绍MySQL的InnoDB引擎的MVCC的实现。 在InnoDB中，会在每行数据后添加两个额外的隐藏的列来实现MVCC，这两列一个记录这行数据的创建时间，另外一个记录这行数据过期时间（或者删除时间）。 在实际操作中，存储的并不是时间，而是版本号,即创建版本号和删除版本号。 事务版本号 TRX_ID ：事务开始时的系统版本号。每一个新事务都会使系统版本号加1。所以新事务等于上一个事务的版本号+1。 在可重复读Repeatable reads事务隔离级别下： SELECT时，读取创建版本号&lt;=当前事务版本号并且删除版本号为空或&gt;当前事务版本号的数据行。 INSERT时，保存当前事务版本号为行的创建版本号 DELETE时，保存当前事务版本号为行的删除版本号 UPDATE时，插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行 更加底层的可以参考这篇文章 里面详细介绍了undo log和版本链,上面是undo log和版本链的简单理解。 我们上面的表格中提到过可重复读级别可以解决不可重复读的问题，但无法解决幻影读的问题，而只有在Serializable级别才能解决幻读。但是测试后发现，MySQL的可重复读级别中，是解决了幻影读的读问题的。 这里需要着重强调两点：1.我们说的是解决了幻影读的读问题，而不是说直接解决了幻影读问题。至于为什么，这里先卖下关子，下文会讲到。 2.不可重复读和幻影读的区别:不可重复读重点在于update和delete，而幻影读的重点在于insert如果用锁机制来解释的话，就是在可重复读级别时update和delete时会对这些数据加锁，从而实现可重复读。但这种方法无法锁住insert的数据，所以会出现幻影读的问题。 快照读和当前读上面我们提到了在可重复读级别下，MVCC解决了幻影读的读问题，而不是说解决了幻影读问题。是因为MySQL中的读，和事务隔离级别中的读，是不一样的。事务的隔离级别虽然都是对于读数据的定义，但在这里，就被拆成了读和写两个模块来讲解。 在可重复读级别中，通过MVCC机制，虽然让数据变得可重复读，但我们读到的数据可能是历史数据，是不及时的数据，不是数据库当前的数据！这在一些对于数据的时效特别敏感的业务中，就很可能出问题。在MVCC中： 快照读：读取历史数据的方式就是select 1select * from table ….; 当前读：读取数据库当前版本数据的方式。 特殊的读操作，插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁。可以看到 MVCC 并不是完全不用加锁，而只是避免了 SELECT 的加锁操作。 123456insert;update ;delete;# 手动加锁select * from table where ? lock in share mode; -- s锁select * from table where ? for update; -- x锁 事务的隔离级别中虽然只定义了读数据的要求，实际上这也可以说是对写数据(当前读)的要求。到这里应该清楚了，我们上面学习的MVCC解决的幻影读的读问题，实际是讲的快照读。 而为了解决写(当前读中)的幻影读问题，MySQL事务使用了Next-Key锁。 Next-Key LocksNext-Key锁是行锁和GAP（间隙锁）的合并，行锁上面已经介绍了，接下来说下GAP间隙锁。 间隙锁(Gap locks)： 锁定索引之间的间隙，但是不包含索引本身。 我们先看下在提交读和可重复读下的对比 提交读级别: 可重复读级别： 通过对比我们可以发现，在提交读级别中，事务A修改了所有teacher_id=30的数据，但是当事务Binsert进新数据后，事务A发现莫名其妙多了一行teacher_id=30的数据，而且没有被之前的update语句所修改，这就是“当前读”的幻读。 可重复读级别中，事务A在update后加锁，事务B无法插入新数据，这样事务A在update前后读的数据保持一致，避免了幻读。这个锁，就是间隙锁。 间隙锁在MySQL是这么实现的： 在class_teacher这张表中，teacher_id是个索引，那么它就会维护一套B+树的数据关系，为了简化，我们用链表结构来表达（实际上是个树形结构，但原理相同） Innodb将这段数据分成几个个区间 123(negative infinity, 5],(5,30],(30,positive infinity)； update class_teacher set class_name=‘初三二班’ where teacher_id=30;不仅用行锁，锁住了相应的数据行；同时也在两边的区间，（5,30]和（30，positive infinity），都加入了间隙锁。这样事务B就无法在这个两个区间insert进新数据。 受限于这种实现方式，Innodb很多时候会锁住不需要锁的区间。如下所示： update的teacher_id=20是在(5，30]区间，即使没有修改任何数据，Innodb也会在这个区间加gap锁，而其它区间不会影响，事务C正常插入。 行锁防止别的事务修改或删除，间隙锁防止别的事务新增，行锁和间隙锁结合形成的的Next-Key锁共同解决了可重复读级别在写数据时的幻影读问题。 索引和锁上面我们的demo都是建立在teacher_id是索引的情况下(我们建表时建了索引)： 1KEY `idx_teacher_id` (`teacher_id`) 但是如果我们因为自己写的select语句导致索引失效，或者说就没有建立索引比如比如update class_teacher set teacher_id=7 where class_name=‘初三八班（即使没有匹配到任何数据）’,那么MySQL会给整张表的所有数据行的加行锁，同时会给全表加入间隙锁。 对于行锁而言，整个加锁过程如下: 如果没有使用索引，MySQL并不知道哪些数据行是class_name = ‘初三八班’的数据行，如果一个条件无法通过索引快速过滤，存储引擎层面就会将所有记录加锁后返回，再由MySQL服务层进行过滤。 在MySQL Server过滤条件，发现条件不满足后，会调用unlock_row方法，把不满足条件的记录释放锁 (违背了二段锁协议的约束)。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。 这种情况同样适用于MySQL的默认隔离级别可重复读。所以对一个数据量很大的表做批量修改的时候，如果无法使用相应的索引，MySQL服务层过滤数据的的时候特别慢，就会出现虽然没有修改某些行的数据，但是它们还是被锁住了的现象。 对于间隙锁而言，整个加锁过程如下:它不能像上文中行锁一样经过MySQL服务层过滤自动解除不满足条件的锁，因为没有索引，则这些字段也就没有排序，也就没有区间。除非该事务提交，否则其它事务无法插入任何数据。 这个很简单，就不再演示了。","link":"/2020/04/22/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%94%81%E7%90%86%E8%AE%BA/"},{"title":"leetcode数组和矩阵练习","text":"数组和矩阵练习tips 涉及到遍历数组时，如果使用for循环不方便时考虑使用while循环(数组下标可以在一定条件下进行+ -操作) 一个小tips是可以自定义一个数组下标idx，从而自由进行idx++操作。 对于矩阵而言，通常需要我们各种进行花式打印矩阵。这时候，就需要结合具体问题分析矩阵行、列的约束关系。 通常约束关系还涉及到矩阵的维度n 1.把数组中的 0 移到末尾283. Move Zeroes (Easy) 1234567891011class Solution { public void moveZeroes(int[] nums) { int idx = 0; for(int num:nums){ if(num!=0) nums[idx++] = num; } while(idx&lt;nums.length){ nums[idx++] = 0; } }} 2.改变矩阵维度566. Reshape the Matrix (Easy) 12345678910111213141516171819class Solution { public int[][] matrixReshape(int[][] nums, int r, int c) { int row=nums.length,col=nums[0].length; if(row*col != r*c) return nums; int[][] res = new int[r][c]; int rows=0,cols=0; for(int i=0;i&lt;row;i++){ for(int j=0;j&lt;col;j++){ res[rows][cols] = nums[i][j]; cols++; if(cols==c){ rows++; cols = 0; } } } return res; }} 3. 找出数组中最长的连续 1485. Max Consecutive Ones (Easy) 123456789101112class Solution { public int findMaxConsecutiveOnes(int[] nums) { int max = 0; int count = 0; for(int i=0;i&lt;nums.length;i++){ if(nums[i]==1) count++; else count = 0; max = Math.max(max,count); } return max; }} 4.有序矩阵查找I74. Search a 2D Matrix(Medium) 从左下或者右上进行寻找 12345678910111213class Solution { public boolean searchMatrix(int[][] matrix, int target) { if(matrix==null || matrix.length==0) return false; int row=matrix.length,col=matrix[0].length; int i=row-1,j=0; while(i&gt;=0 &amp;&amp; j&lt;col){ if(target==matrix[i][j]) return true; else if(target&lt;matrix[i][j]) i--; else j++; } return false; }} 5.有序矩阵查找II240. Search a 2D Matrix II (Medium) 和I完全没区别 12345678910111213class Solution { public boolean searchMatrix(int[][] matrix, int target) { if(matrix==null || matrix.length==0) return false; int row=matrix.length,col=matrix[0].length; int i=row-1,j=0; while(i&gt;=0 &amp;&amp; j&lt;col){ if(target==matrix[i][j]) return true; else if(target&lt;matrix[i][j]) i--; else j++; } return false; }} 6.有序矩阵的 Kth Element378. Kth Smallest Element in a Sorted Matrix ((Medium)) 1234567891011121314151617class Solution { public int kthSmallest(int[][] matrix, int k) { //Java默认是小顶堆，但这里为了求第k小的值我们需要大顶堆 //所以使用Collections.reverseOrder()进行倒叙 PriorityQueue&lt;Integer&gt; queue = new PriorityQueue&lt;&gt;(Collections.reverseOrder()); for(int[] row:matrix){ for(int num:row){ if(queue.size()&lt;k) queue.offer(num); else if(queue.peek()&gt;num){ queue.poll(); queue.offer(num); } } } return queue.peek(); }} 7. 一个数组元素在 [1, n] 之间，其中一个数被替换为另一个数，找出重复的数和丢失的数645. Set Mismatch (Easy) 最直接想到的方法是对数组进行排序或者使用过map存储元素和次数。但是排序时间复杂度为O(nlogn),使用map空间复杂度为O(n)，这道题目可以使用时间复杂度O(n),空间复杂度O(1)的方法进行解决。 主要思想是通过交换数组元素，使得数组上的元素在正确的位置上。 1234567891011121314151617181920class Solution { public int[] findErrorNums(int[] nums) { for (int i = 0; i &lt; nums.length; i++) { while (nums[i] != i + 1 &amp;&amp; nums[nums[i] - 1] != nums[i]) { swap(nums, i, nums[i] - 1); } } for (int i = 0; i &lt; nums.length; i++) { if (nums[i] != i + 1) { return new int[]{nums[i], i + 1}; } } return null; } private void swap(int[] nums, int i, int j) { int tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp; }} 找出数组中重复的数，数组值在 [1, n] 之间 287. Find the Duplicate Number (Medium) 双指针解法： 123456789101112131415class Solution { public int findDuplicate(int[] nums) { int lo=0,hi=nums.length-1; while(lo&lt;=hi){ int mid = lo +(hi-lo)/2; int count = 0; for(int i=0;i&lt;nums.length;i++){ if(nums[i]&lt;=mid) count++; } if(count&gt;mid) hi = mid-1; else lo = mid+1; } return lo; }} 快慢指针法，类似于我们之前的找链表环的交点 123456789101112131415class Solution { public int findDuplicate(int[] nums) { int slow = nums[0], fast = nums[nums[0]]; while (slow != fast) { slow = nums[slow]; fast = nums[nums[fast]]; } fast = 0; while (slow != fast) { slow = nums[slow]; fast = nums[fast]; } return slow; }} 8. 对角元素相等的矩阵766. Toeplitz Matrix (Easy) 1234567891011class Solution { public boolean isToeplitzMatrix(int[][] matrix) { int m = matrix.length,n=matrix[0].length; for(int i=0;i&lt;m-1;i++){ for(int j=0;j&lt;n-1;j++){ if(matrix[i][j]!=matrix[i+1][j+1]) return false; } } return true; }} 9. 嵌套数组565. Array Nesting (Medium) 123456789101112131415161718class Solution { public int arrayNesting(int[] nums) { int res = 0; boolean[] visited = new boolean[nums.length]; for(int i=0;i&lt;nums.length;i++){ if(!visited[i]){ int start = nums[i],count = 0; while(count==0 || start!=nums[i]){ visited[start] = true; start = nums[start]; count++; } res = Math.max(res,count); } } return res; }} 10.分隔数组769. Max Chunks To Make Sorted (Medium) original: 0, 2, 1, 4, 3, 5, 7, 6max: 0, 2, 2, 4, 4, 5, 7, 7sorted: 0, 1, 2, 3, 4, 5, 6, 7index: 0, 1, 2, 3, 4, 5, 6, 7 The chunks are: 0 | 2, 1 | 4, 3 | 5 | 7, 6 12345678910class Solution { public int maxChunksToSorted(int[] arr) { int res = 0,max = 0; for(int i=0;i&lt;arr.length;i++){ max = Math.max(max,arr[i]); if(max == i) res++; } return res; }}","link":"/2020/06/06/leetcode%E6%95%B0%E7%BB%84%E5%92%8C%E7%9F%A9%E9%98%B5%E7%BB%83%E4%B9%A0/"},{"title":"leetcode二分查找练习","text":"","link":"/2020/06/09/leetcode%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E7%BB%83%E4%B9%A0/"},{"title":"leetcode双指针练习","text":"","link":"/2020/06/09/leetcode%E5%8F%8C%E6%8C%87%E9%92%88%E7%BB%83%E4%B9%A0/"},{"title":"leetcode深搜、广搜和回溯练习","text":"深搜、广搜和回溯练习tips DFS用来求解可达性问题。使用栈(递归)+标记进行解决。 BFS用来解决最优解问题。使用队列+标记进行解决。 backtracking属于DFS,主要用来解决所有可能的解的问题。 深度优先搜索和广度优先搜索广泛运用于树和图中，但是它们的应用远远不止如此。 BFS0.原理广度优先搜索一层一层地进行遍历，每层遍历都是以上一层遍历的结果作为起点，遍历一个距离能访问到的所有节点。需要注意的是，遍历过的节点不能再次被遍历。 第一层： 0 -&gt; {6,2,1,5} 第二层： 6 -&gt; {4} 2 -&gt; {} 1 -&gt; {} 5 -&gt; {3} 第三层： 4 -&gt; {} 3 -&gt; {} 每一层遍历的节点都与根节点距离相同。设 di 表示第 i 个节点与根节点的距离，推导出一个结论：对于先遍历的节点 i 与后遍历的节点 j，有 di &lt;= dj。利用这个结论，可以求解最短路径等最优解问题：第一次遍历到目的节点，其所经过的路径为最短路径。 应该注意的是，从上面我们知道，使用 BFS 只能求解无权图的最短路径，无权图是指从一个节点到另一个节点的代价都记为 1。 在程序实现 BFS 时需要考虑以下问题： 队列：用来存储每一轮遍历得到的节点； 标记：对于遍历过的节点，应该将它标记，防止重复遍历。 1.计算在网格中从原点到特定点的最短路径长度1091. Shortest Path in Binary Matrix(Medium) 12345678910111213141516171819202122232425262728class Solution { public int shortestPathBinaryMatrix(int[][] grid) { int m = grid.length,n=grid[0].length; if(grid[0][0]==1 || grid[m-1][n-1]==1) return -1; int[][] direction = {{0,1},{0,-1},{1,0},{-1,0},{1,-1},{-1,1},{-1,-1},{1,1}}; boolean[][] visited = new boolean[m][n]; Queue&lt;int[]&gt; queue = new LinkedList&lt;&gt;(); queue.offer(new int[]{0,0}); int res = 0; while(!queue.isEmpty()){ int levNum = queue.size(); for(int i=0;i&lt;levNum;i++){ int[] node = queue.poll(); if(node[0]==m-1 &amp;&amp; node[1]==n-1) return res+1; for(int[] d:direction){ int nextX = node[0]+d[0]; int nextY = node[1]+d[1]; if(nextX&gt;=0 &amp;&amp; nextX&lt;m &amp;&amp; nextY&gt;=0 &amp;&amp; nextY&lt;n &amp;&amp; !visited[nextX][nextY] &amp;&amp; grid[nextX][nextY]==0){ queue.offer(new int[]{nextX,nextY}); visited[nextX][nextY] = true; } } } res++; } return -1; }} DFS0.原理广度优先搜索一层一层遍历，每一层得到的所有新节点，要用队列存储起来以备下一层遍历的时候再遍历。而深度优先搜索在得到一个新节点时立即对新节点进行遍历 从节点 0 出发开始遍历，得到到新节点 6 时，立马对新节点 6 进行遍历，得到新节点 4；如此反复以这种方式遍历新节点，直到没有新节点了，此时返回。返回到根节点 0 的情况是，继续对根节点 0 进行遍历，得到新节点 2，然后继续以上步骤。 从一个节点出发，使用 DFS 对一个图进行遍历时，能够遍历到的节点都是从初始节点可达的，DFS 常用来求解这种可达性问题。 在程序实现 DFS 时需要考虑以下问题： 栈：用栈来保存当前节点信息，当遍历新节点返回时能够继续遍历当前节点。可以使用递归栈。 标记：和 BFS 一样同样需要对已经遍历过的节点进行标记。 1.查找最大的连通面积695. Max Area of Island (Medium) 深搜： 123456789101112131415161718192021222324252627class Solution { private int m,n; private boolean[][] visited; private int[][] direction = {{1,0},{-1,0},{0,1},{0,-1}}; public int maxAreaOfIsland(int[][] grid) { if(grid==null || grid.length==0) return 0; m = grid.length; n = grid[0].length; visited = new boolean[m][n]; int res = 0; for(int i=0;i&lt;m;i++){ for(int j=0;j&lt;n;j++){ res = Math.max(res,dfs(grid,i,j)); } } return res; } private int dfs(int[][] grid,int i,int j){ if(i&lt;0 || i&gt;=m || j&lt;0 || j&gt;=n || visited[i][j] || grid[i][j]==0) return 0; visited[i][j] = true; int area = 1; for(int[] d:direction){ area += dfs(grid,i+d[0],j+d[1]); } return area; }} 当然这个题目也可以用广搜解决 1234567891011121314151617181920212223242526272829303132333435363738class Solution { private int m,n; private boolean[][] visited; private int[][] direction = new int[][]{{1,0},{-1,0},{0,1},{0,-1}}; public int maxAreaOfIsland(int[][] grid) { if(grid==null || grid.length==0 || grid[0].length==0) return 0; m = grid.length; n=grid[0].length; visited = new boolean[m][n]; int res = 0; for(int i=0;i&lt;m;i++){ for(int j=0;j&lt;n;j++){ if(grid[i][j]==1 &amp;&amp; !visited[i][j]){ res = Math.max(res,bfs(grid,i,j)); } } } return res; } private int bfs(int[][] grid,int i,int j){ Queue&lt;int[]&gt; queue = new LinkedList&lt;&gt;(); queue.offer(new int[]{i,j}); visited[i][j] = true; int res = 0; while(!queue.isEmpty()){ int[] node = queue.poll(); res++; for(int[] d:direction){ int X = node[0]+d[0]; int Y = node[1]+d[1]; if(X&lt;0 || X&gt;=m || Y&lt;0 || Y&gt;=n || visited[X][Y] || grid[X][Y] == 0) continue; queue.offer(new int[]{X,Y}); visited[X][Y] = true; } } return res; }} 2.矩阵中的连通分量数目200. Number of Islands (Medium) 12345678910111213141516171819202122232425262728class Solution { private int m,n; private boolean[][] visited; private int[][] direction = {{1,0},{-1,0},{0,1},{0,-1}}; public int numIslands(char[][] grid) { if(grid==null || grid.length==0) return 0; m = grid.length; n = grid[0].length; visited = new boolean[m][n]; int count = 0; for(int i=0;i&lt;m;i++){ for(int j=0;j&lt;n;j++){ if(!visited[i][j] &amp;&amp; grid[i][j]=='1'){ dfs(grid,i,j); count++; } } } return count; } private void dfs(char[][] grid,int i,int j){ if(i&lt;0 || i&gt;=m || j&lt;0 || j&gt;=n || visited[i][j] || grid[i][j] == '0') return; visited[i][j] = true; for(int[] d:direction){ dfs(grid,i+d[0],j+d[1]); } }} 同样也可以用广搜解决 123456789101112131415161718192021222324252627282930313233343536class Solution { private int m,n; private boolean[][] visited; private int[][] direction = new int[][]{{1,0},{-1,0},{0,1},{0,-1}}; public int numIslands(char[][] grid) { if(grid==null || grid.length==0 || grid[0].length==0) return 0; m = grid.length; n = grid[0].length; visited = new boolean[m][n]; int res = 0; for(int i=0;i&lt;m;i++){ for(int j=0;j&lt;n;j++){ if(!visited[i][j] &amp;&amp; grid[i][j]=='1'){ res++; bfs(grid,i,j); } } } return res; } private void bfs(char[][] grid,int i,int j){ Queue&lt;int[]&gt; queue = new LinkedList&lt;&gt;(); queue.offer(new int[]{i,j}); visited[i][j] = true; while(!queue.isEmpty()){ int[] node = queue.poll(); for(int[] d:direction){ int x = node[0]+d[0]; int y = node[1]+d[1]; if(x&lt;0 || x&gt;=m || y&lt;0 || y&gt;=n || visited[x][y] || grid[x][y]=='0') continue; queue.offer(new int[]{x,y}); visited[x][y] = true; } } }} 3.好友关系的连通分量数目547. Friend Circles (Medium) 12345678910111213141516171819202122232425class Solution { private int n; private boolean[] visited; public int findCircleNum(int[][] M) { if(M==null || M.length==0) return 0; n = M.length; visited = new boolean[n]; int res = 0; for(int i=0;i&lt;n;i++){ if(!visited[i]){ dfs(M,i); res++; } } return res; } private void dfs(int[][] M,int i){ visited[i] = true; for(int j=0;j&lt;n;j++){ if(M[i][j] == 1 &amp;&amp; !visited[j]){ dfs(M,j); } } }} 4.填充封闭区域130. Surrounded Regions (Medium) 1234567891011121314151617181920212223242526272829303132333435363738class Solution { private int m, n; private int[][] direction = {{0, 1}, {0, -1}, {1, 0}, {-1, 0}}; public void solve(char[][] board) { if (board == null || board.length == 0) return; m = board.length; n = board[0].length; //边界为O的一定不会变为X //找到所有边界为O的联通区域标记为T for (int i = 0; i &lt; m; i++) { dfs(board, i, 0); dfs(board, i, n - 1); } for (int i = 0; i &lt; n; i++) { dfs(board, 0, i); dfs(board, m - 1, i); } //内层的标记为X for (int i = 0; i &lt; m; i++) { for (int j = 0; j &lt; n; j++) { if (board[i][j] == 'T') { board[i][j] = 'O'; }else if (board[i][j] == 'O') { board[i][j] = 'X'; } } } } private void dfs(char[][] board, int i, int j) { if (i &lt; 0 || i &gt;= m || j &lt; 0 || j &gt;= n || board[i][j] != 'O') return; board[i][j] = 'T'; for (int[] d : direction) { dfs(board, i + d[0], j + d[1]); } }} 5.能到达的太平洋和大西洋的区域417. Pacific Atlantic Water Flow (Medium) 12345678910111213141516171819202122232425262728293031323334353637class Solution { private int m,n; private boolean[][] p; private boolean[][] a; private int[][] direction = {{1,0},{-1,0},{0,1},{0,-1}}; public List&lt;List&lt;Integer&gt;&gt; pacificAtlantic(int[][] matrix) { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); if(matrix==null || matrix.length==0) return res; m = matrix.length; n = matrix[0].length; p = new boolean[m][n]; a = new boolean[m][n]; for(int i=0;i&lt;m;i++){ dfs(matrix,i,0,0,p); dfs(matrix,i,n-1,0,a); } for(int j=0;j&lt;n;j++){ dfs(matrix,0,j,0,p); dfs(matrix,m-1,j,0,a); } for(int i=0;i&lt;m;i++){ for(int j=0;j&lt;n;j++){ if(p[i][j] &amp;&amp; a[i][j]){ res.add(Arrays.asList(i,j)); } } } return res; } private void dfs(int[][] matrix,int i,int j,int height,boolean[][] visited){ if(i&lt;0||i&gt;=m||j&lt;0||j&gt;=n||visited[i][j]||matrix[i][j]&lt;height) return; visited[i][j] = true; for(int[] d:direction){ dfs(matrix,i+d[0],j+d[1],matrix[i][j],visited); } }} backtracking0.原理Backtracking（回溯）属于 DFS。 普通 DFS 主要用在可达性问题 ，这种问题只需要执行到特点的位置然后返回即可。 而 Backtracking 主要用于求解排列组合问题，例如有 { ‘a’,’b’,’c’ } 三个字符，求解所有由这三个字符排列得到的字符串，这种问题在执行到特定的位置返回之后还会继续执行求解过程。 因为 Backtracking 不是立即返回，而要继续求解，因此在程序实现时，需要注意对元素的标记问题： 在访问一个新元素进入新的递归调用时，需要将新元素标记为已经访问，这样才能在继续递归调用时不用重复访问该元素； 但是在递归返回时，需要将元素标记为未访问，因为只需要保证在一个递归链中不同时访问一个元素，可以访问已经访问过但是不在当前递归链中的元素。 1.","link":"/2020/06/09/leetcode%E6%B7%B1%E6%90%9C%E5%B9%BF%E6%90%9C%E5%92%8C%E5%9B%9E%E6%BA%AF%E7%BB%83%E4%B9%A0/"},{"title":"十大排序算法总结","text":"主要内容 排序的基本概念 10种排序算法代码演示 排序算法总结 Java中的排序算法 排序的基本概念排序的一般定义排序是计算机中经常进行的操作，目的在于将一组无序的数据元素调整为有序的数据元素。序列：1，20，45，5，2，12排序后：1，2，5，12，20，45 排序的稳定性如果序列中的两个元素R[i]、R[j]，关键字分别为K[i]、K[j]并且K[i]=K[j]，在排序之前R[i]排在R[j]前面，如果排序操作后，元素R[i]仍然排在R[j]前面，则排序方法是稳定的；否则排序是不稳定的。 通俗的讲，就是排序前有两个相等的数a和b，且a在b前面，排序后如果a依然在b前面，则这次排序为稳定排序 。 例如对4,2,1,3(A),3(B),5进行从小到大排序，则 稳定排序： 1,2,3(A),3(B),4,5 3(A),3(B)和排序前顺序相同。 不稳定排序: 1,2,3(B),3(A),4,5 3(A),3(B)和排序前顺序不同。 这里我们先提一下我们下面要讲的排序算法的稳定性如下: 稳定排序： 冒泡排序、插入排序、归并排序、 基数排序 不稳定排序：选择排序、快速排序、希尔排序、 堆排序 内排序和外排序内排序 ：待排序列完全存放在内存中所进行的排序过程，适合不太大的元素序列外排序：指的是大文件的排序，即待排序的记录存储在外存储器上，无法一次装入内存，需要在内存和外部存储器之间进行多次数据交换，以达到排序整个文件的目的。 排序算法的性能评价时间性能:主要性能差异体现在比较和交换的数量辅助存储空间:为完成排序操作需要的额外的存储空间。必要时可以空间换时间算法的实现复杂性： 过于复杂的排序算法影响可读性和可维护性 排序的模板方法如下；排序模板方法如下: 12345678910111213141516public class SortMethod { //比较 private boolean less(int i,int j){ return i&lt;j; } //交换 private void swap(int[] num,int i,int j){ int temp = num[i]; num[i] = num[j]; num[j] = temp; } //打印 private void show(int[] num){ System.out.println(Arrays.toString(num)); }} 选择排序算法过程:从数组中选择最小元素，将它与数组的第一个元素交换位置。再从数组剩下的元素中选择出最小的元素，将它与数组的第二个元素交换位置。不断进行这样的操作，直到将整个数组排序。 1234567891011public void selectionSort(int[] num){ int min = 0; int n = num.length; for (int i = 0; i &lt; n; i++) { min = i; for (int j = i + 1; j &lt; n; j++) { if(less(num[j],num[min])) min = j; } swap(num,i,min); }} 选择排序算法分析:时间复杂度: 因为无论怎样，选择排序都会进行1+2+……+（n-1）次比较操作，时间复杂度为O(n^2)空间复杂度： O(1) 原地排序稳定性: 不稳定排序。 比如5(A),8,5(B),2,9 最终排完序后为 2,5(B),5(A),8,9 冒泡排序算法过程:从左到右不断交换相邻逆序的元素，在一轮的循环之后，可以让未排序的最大元素上浮到右侧。 在一轮循环中，如果没有发生交换，那么说明数组已经是有序的,可以通过添加标志位来避免无用的比较操作。 1234567891011121314public void bubbleSort(int[] num){ int n = num.length; boolean exchange; for (int i = n-1; i &gt; 0; i--) { exchange = false; for (int j = 0; j &lt; i; j++) { if(less(num[j+1],num[j])) { swap(num,j,j+1); exchange = true; } } if(!exchange) break; }} 冒泡排序算法分析:时间复杂度:平均时间复杂度为O(n^2) 最好情况：数组正序，复杂度为O(n) 最坏情况：数组倒序，复杂度为O(n^2)空间复杂度：O(1) 原地排序稳定性:稳定排序 因为只有在后一位比自己大时才交换,相等时不进行交换。 插入排序算法思想:每次都将当前元素插入到左侧已经排序的数组中，使得插入之后左侧数组依然有序。 123456789public void insertionSort(int[] num){ int n = num.length; for (int i = 1; i &lt; n; i++) { for (int j = i; j &gt;0 &amp;&amp; less(num[j],num[j-1]); j--) { swap(num,j,j-1); } show(num); }} 对于数组 {3, 5, 2, 4, 1}，它具有以下逆序：(3, 2), (3, 1), (5, 2), (5, 4), (5, 1), (2, 1), (4, 1)，插入排序每次只能交换相邻元素，令逆序数量减少1，因此插入排序需要交换的次数为逆序数量。 插入排序的时间复杂度取决于数组的初始顺序，如果数组已经部分有序了，那么逆序较少，需要的交换次数也就较少，时间复杂度较低。 平均情况下插入排序需要 ~N2/4 比较以及 ~N2/4 次交换； 最坏的情况下需要 ~N2/2 比较以及 ~N2/2 次交换，最坏的情况是数组是倒序的； 最好的情况下需要 N-1 次比较和 0 次交换，最好的情况就是数组已经有序了。 插入排序算法分析:时间复杂度:取决于数组的初始顺序 通常认为平均时间复杂度为O(n^2)空间复杂度：O(1) 原地排序稳定性:稳定排序 因为只有在后一位比自己大时才插入,相等时直接插在后面所以是稳定排序。 希尔排序对于大规模的数组，插入排序很慢，因为它只能交换相邻的元素，每次只能将逆序数量减少1。希尔排序的出现就是为了解决插入排序的这种局限性，它通过交换不相邻的元素，每次可以将逆序数量减少大于 1。 算法思想:希尔排序也是一种插入排序，也称为缩小增量排序。主要思想是使用插入排序对增量h的序列进行排序。通过不断减小h，最后令 h=1，就可以使得整个数组是有序的。 可以参考上图，在此我们选择增量gap=length/2，缩小增量继续以gap = gap/2的方式，这种增量选择我们可以用一个序列来表示，{n/2,(n/2)/2...1}，称为增量序列。希尔排序的增量序列的选择与证明是个数学难题。通常比较常见的有两种: {n/2,(n/2)/2…1} 1/2(3^k-1) {1,4,…3h+1} (通常比上面的效率高) 实现时不用循环按组处理，我们可以从第h个元素开始，逐个跨组处理。 123456789101112131415161718public void shellSort(int[] num){ int n = num.length; //这里直接使用第二个增量序列 //找到初始增量 int h = 1; while(h&lt;n/3) h = 3*h+1; //1,4,13,40... //排序过程 while(h&gt;=1){ //就是一个插入排序 for (int i = h; i &lt; n; i++) { for (int j = i; j &gt;=h &amp;&amp; less(num[j],num[j-h]); j-=h) { swap(num,j,j-h); } } //改变增量 h = h/3; }} 时间复杂度：O(n1.3)~O(n2)之间空间复杂度：O(1) 原地排序稳定性:不稳定排序 相同元素可能分到不同的组中，每一组又单独进行插入排序，所以有可能其稳定性就会被打乱。 其实对于希尔排序的时间复杂度一直没有一个统一的说法，主要在于希尔排序取决于增量序列的选择。只需要知道 希尔排序超越了我们之前所讲的三种简单算法的O(n^2) 即可。 归并排序算法思想:将一个数组(递归地)分成两部分分别进行排序，最后将结果归并起来。使用了分治法的思想。 图片来自于文章 https://www.cnblogs.com/chengxiao/p/6194356.html 自顶向下归并排序(递归) 从上往下，将大数组分为小数组 12345678910111213141516171819202122232425262728293031private int[] workspace;public void mergeSort(int[] num){ workspace = new int[num.length]; sort(num,0,num.length-1);}private void sort(int[] num,int lo,int hi){ if(lo &gt;= hi) return; int mid = lo + (hi-lo)/2; sort(num,lo,mid); //左半边排序 sort(num,mid+1,hi); //右半边排序 merge(num,lo,mid,hi); //归并结果 show(num);}private void merge(int[] num, int lo, int mid, int hi) { int i = lo; int j = mid+1; for (int k = lo; k &lt;= hi; k++) { workspace[k] = num[k]; //先复制到临时数组中 } for (int k = lo; k &lt;=hi ; k++) { if(i &gt; mid) num[k] = workspace[j++]; //左边数组完成，右边没有完成 else if(j &gt; hi) num[k] = workspace[i++]; //右边数组完成，左边没有完成 else if(less(workspace[i],workspace[j])) num[k] = workspace[i++]; //左边小于右边，num数组中放左边的值 else num[k] = workspace[j++]; //右边小于左边，num数组中放右边的值 }} 贴一下运行结果 12345678初始数组:[6, 2, 7, 4, 8, 1, 5, 3][2, 6, 7, 4, 8, 1, 5, 3] //6,2排序为2,6[2, 6, 4, 7, 8, 1, 5, 3] //7,4排序为4,7[2, 4, 6, 7, 8, 1, 5, 3] //2,6,4,7排序为2, 4, 6, 7[2, 4, 6, 7, 1, 8, 5, 3] //8,1排序为1,8[2, 4, 6, 7, 1, 8, 3, 5] //5,3排序为3,5[2, 4, 6, 7, 1, 3, 5, 8] //1, 8, 3, 5排序为1, 3, 5, 8[1, 2, 3, 4, 5, 6, 7, 8] //最后整体排序 自底向上递归排序(迭代)先归并小数组，然后成对归并得到的小数组。 12345678910//merge没变，只需要更改sort即可private void sort2(int num[]){ int n = num.length; for (int sz = 1; sz&lt;n; sz+=sz) { //sz子数组的大小 for (int lo = 0; lo &lt; n - sz; lo += sz + sz) { //lo子数组索引 merge(num, lo, lo + sz - 1, Math.min(lo + sz + sz - 1, n- 1)); } show(num); }} 归并排序复杂度分析:时间复杂度：始终是O(nlogn) 与数据的顺序无关空间复杂度：O(n)，借助了临时数组workspace稳定性:稳定排序 上面我们首先判断左边是否小于右边，所以是稳定个排序 快速排序算法思想 归并排序将数组分为两个子数组分别排序，并将有序的子数组归并使得整个数组排序； 快速排序通过一个切分元素将数组分为两个子数组，左子数组小于等于切分元素，右子数组大于等于切分元素，将这两个子数组排序也就将整个数组排序了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public void quickSort(Integer[] num){ shuffle(num); //消除数组对数据的依赖性 qSort(num,0,num.length-1); } private void qSort(Integer[] num, int lo, int hi) { if(hi &lt;= low) return; int j = partion(num,lo,hi); qSort(num,lo,j-1); qSort(num,j+1,hi); show(num); } /** * 切分方法 */ private int partion(Integer[] num,int lo,int hi){ //将数组切分为num[lo..pivotkey-1],num[pivotkey],num[pivotkey+1..hi] int i = lo; //从左往右扫描指针 int j = hi + 1; //从右往左扫描指针 int pivotkey = num[lo]; while (true){ //从左往右扫描直到找到一个大于等于pivotkey的元素 while(less(num[++i],pivotkey)) if(i==hi) break; //从右往左扫描直到找到一个小于等于pivotkey的元素 while(less(pivotkey,num[--j])) if(j==lo) break; //当两个指针相遇时，跳出循环进行之后的交换操作 if(i &gt;= j) break; //交换位置 swap(num,i,j); } //进行num[lo]和左子数组最右侧元素num[j]交换，返回j即可 swap(num,lo,j); return j; } /** * 打乱数组 */ private void shuffle(Integer[] num){ List&lt;Integer&gt; list = Arrays.asList(num); Collections.shuffle(list); list.toArray(num); } 快速排序的复杂度分析时间复杂度：平均是O(nlogn) 最好情况下，递归树的深度为log2n + 1次，时间复杂度为O(nlog2n)。最坏情况下，序列为正序或逆序,递归树画出来就是一个斜树，因此要执行n-1次递归调用，总的时间复杂度为O(n^2) 空间复杂度：从上面的分析可以看到，最好情况递归树的深度为log2n，最坏情况为O(n)。所以平均情况下快速排序的空间复杂度为O(logn) 稳定性： 不稳定排序 因为关键字的比较和交换是跳跃进行的。 快速排序的改进1.切换到插入排序因为快速排序在小数组中也会递归调用自己，对于小数组，插入排序比快速排序的性能更好，因此在小数组中可以切换到插入排序。 12345//只需要在qSort中将if(hi &lt;= lo) return;替换为if(hi &lt;= lo + M){ insertionSort(num,lo,hi); return;} 2.三数取中法 一般找到数组的中位数最好，但是寻找数组中位数代价较高。一般取3个关键字先进行排序，将排在中间的数作为基准。一般是取左端，右端和中间三个数。当然数据量大的时候也可以九数取中。 1234567891011121314//原来在partion中直接取数组最左边第一个数做pivotkey int pivotkey = num[lo];//这里可以直接调用函数得到int pivotkey = getPivotkey(num);//找三个数的中间的数private int getPivotkey(Integer[] num,int lo,int hi){ int pivotkey; int mid = (lo+hi)/2; if(num[lo]&gt;num[hi]) swap(num,lo,hi); if(num[mid]&gt;num[hi]) swap(num,mid,hi); if(num[mid]&gt;num[lo]) swap(num,mid,lo); pivotkey = num[lo]; return pivotkey;} 3.三向切分法对于有大量重复元素的数组，可以将数组切分为三部分，分别对应小于、等于和大于切分元素。 对于有大量重复元素的随机数组，三向切分法可以将排序时间从线性对数级别降低到线性级别。 12345678910111213141516171819202122/** * 维护3个指针，lt, i , gt * num[lo..lt-1]都小于pivotkey num[gt+1..hi]都大于pivotkey * num[lt..i-1]都等于pivotkey num[i..gt]元素未确定 * * 最终num[lo..lt-1]&lt;pivotkey = num[lt..gt] &lt; num[gt+1..hi] * */public void quick3wayQsort(Integer[] num,int lo,int hi){ if(hi &lt;= lo) return; int lt = lo; int i = lo+1; int gt = hi; int pivotkey = num[lo]; while(i &lt;= gt){ if(less(num[i], pivotkey)) swap(num,lt++,i++); else if(less(pivotkey,num[i])) swap(num,i,gt--); else i++; } //现在num[lo..lt-1]&lt;pivotkey = num[lt..gt] &lt; num[gt+1..hi]成立 qSort(num,lo,lt-1); qSort(num,gt+1,hi);} 堆排序关于优先队列和堆的定义和基本性质参考我的文章 算法思想：把最大元素和当前堆中数组的最后一个元素交换位置，并且不删除它，那么就可以得到一个从尾到头的递减序列，从正向来看就是一个递增序列，这就是堆排序。 主要包含两步: 构建堆 交换堆顶元素与最后一个元素 无序数组建立堆最直接的方法是从左到右遍历数组进行上浮操作。一个更高效的方法是从右至左进行下沉操作，如果一个节点的两个子节点都已经是有序的，那么进行下沉操作可以使得这个节点为根节点的堆有序。叶子节点不需要进行下沉操作，可以忽略叶子节点的元素，因此只需要遍历一半的元素即可。 1234567891011121314151617181920212223242526272829303132333435363738public void heapSort(int[] num){ int N = num.length; //构造堆 //使用shiftDown方法将num[1]到num[N]排序 for(int k = N/2;k&gt;=1;k--){ shiftDown(num,k,N); } //将num[1]和num[N]交换并修复堆 //重复直到堆变空 while(N&gt;1){ swap(num,1,N--); shiftDown(num,1,N); }}private void shiftDown(int[] num, int k, int N) { while (2 * k &lt;= N) { int j = 2 * k; //和两个孩子节点中值大的交换 if (j&lt;N &amp;&amp; less(num,j, j + 1)) j++; if (!less(num,k, j)) break; swap(num,k, j); k = j; }}//数组num[0]放元素，如果要放元素，并且对数组进行排序，则需要将less和swap中的索引减1private boolean less(int[] num,int i, int j){ return num[i-1]&lt;num[j-1];}private void swap(int[] num,int i,int j){ int temp = num[i-1]; num[i-1] = num[j-1]; num[j-1] = temp;} 堆排序的复杂度分析时间复杂度：平均是O(nlogn) 构建初始堆经复杂度为O(n)，在交换并重建堆的过程中，需交换n-1次，而重建堆的过程中，根据完全二叉树的性质，[log2(n-1),log2(n-2)…1]逐步递减，近似为nlogn。空间复杂度：O(1) 就地排序稳定性： 不稳定排序 记录的比较与交换是跳跃式的 下面的三种方法都是线性时间非比较类排序： 计数排序算法思想：核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 1234567891011121314151617181920212223public void countSort(int[] num) { //1.先找出最大和最小元素 int min = num[0]; int max = num[0]; for (int i = 0; i &lt; num.length; i++) { if(num[i]&lt;min) min = num[i]; if(num[i]&gt;max) max = num[i]; } int[] bucket = new int[max-min+1]; Arrays.fill(bucket,0); //元素对应放入bucket中并计数 for (int i = 0; i &lt; num.length; i++) { bucket[num[i]-min]++; } int index = 0; for (int i = 0; i &lt; bucket.length; i++) { while(bucket[i] != 0){ num[index++] = i+min; bucket[i]--; } } System.out.println(\"排序后\"+Arrays.toString(num));} 计数排序复杂度分析时间复杂度：始终是O(n+k) 整个过程是对待排数组进行遍历。空间复杂度：O(num[max]-num[min]) 从上面可以看到，计数排序需要一个num[max]-num[min]长度的数组做辅助来排序稳定性:稳定排序 由于计数排序都没有出现比较元素的操作。这个算法很明显是稳定的所以计数排序是稳定排序 桶排序算法思想 桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。 12345678910111213141516171819202122232425262728public void bucketSort(int[] num,int bucketSize) { int min = num[0]; int max = num[0]; for (int i = 0; i &lt; num.length; i++) { if(num[i]&lt;min) min = num[i]; if(num[i]&gt;max) max = num[i]; } int bucketCount = (max-min)/bucketSize+1; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; bucketnum= new ArrayList&lt;&gt;(bucketCount); int[] newnum = new int[num.length]; for (int i = 0; i &lt; bucketCount; i++) { bucketnum.add(new ArrayList&lt;&gt;()); } // 把数据放入桶中 for (int i = 0; i &lt;num.length ; i++) { bucketnum.get((num[i]-min)/bucketSize).add(num[i]); } int index = 0; for (int i = 0; i &lt; bucketCount; i++) { //对于每个桶中的数据可以使用其他排序方式排序 //也可以使用桶排序进行递归调用，但是涉及到list和array之间的转换比较繁琐 //所以最好是待排序数组是list时比较方便 Collections.sort(bucketnum.get(i)); for (int j = 0; j &lt; bucketnum.get(i).size(); j++) { newnum[index++] = bucketnum.get(i).get(j); } }} 桶排序复杂度分析时间复杂度：平均是O(n+k)桶排序包括两个部分：1.循环计算每个关键字的桶映射函数，这个时间复杂度是O(n)。2.利用先进的比较排序算法对每个桶内的所有数据进行排序。很显然，第2部分是桶排序性能好坏的决定因素。 空间复杂度：O(n+k) 如果相对于同样的n，桶数量k越大，其效率越高，最好的时间复杂度达到O(n)。当然桶排序的空间复杂度为O(n+k)，如果输入数据非常庞大，而桶的数量也非常多，则空间代价无疑是昂贵的。稳定性:稳定排序 对于桶排序，在对每个桶内数据进行排序时，由于排序算法使用的不同，可能会出现不稳定排序，但是使用桶排序递归排序时是稳定排序，所以一般认为桶排序是稳定排序 基数排序算法思想：按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。 1234567891011121314151617181920212223242526272829303132public static radixSort(int[] num) { //1.先找出最大位的位数 int maxNum = num[0]; for (int i = 1; i &lt; num.length; i++) { if(num[i]&gt;maxNum) maxNum = num[i]; } int maxDigit = 0; while(maxNum != 0){ maxNum /= 10; maxDigit++; } int mod = 10; int div = 1; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; bucketList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) { bucketList.add(new ArrayList&lt;Integer&gt;()); } for (int i = 0; i &lt; maxDigit; i++,mod *=10,div *=10) { for (int j = 0; j &lt; num.length; j++) { int num = (num[j] % mod)/div; bucketList.get(num).add(num[j]); } int index = 0; for (int j = 0; j &lt; bucketList.size(); j++) { for (int k = 0; k &lt; bucketList.get(j).size(); k++) { num[index++] = bucketList.get(j).get(k); } bucketList.get(j).clear(); } }} 基数排序复杂度分析时间复杂度：O(nk) 该算法所花的时间基本是在把元素分配到桶里和把元素从桶里串起来；把元素分配到桶里：循环 n 次；把元素从桶里串起来也是n次空间复杂度：O(n+k) 该算法的空间复杂度就是在分配元素时，使用的桶空间稳定性:稳定排序 排序算法总结 从上面的图中我们可以把非线性时间比较排序分为两类： 简单算法：直接插入、直接选择、冒泡 改进算法：希尔排序、堆排序、快速排序、 归并排序 从平均情况看，希尔排序是突破了O(n^2)。但是后三种改进算法要胜过希尔排序，并远胜过前三种简单算法。 从最好情况看，反而冒泡排序和直接插入排序效果最好，也就是说，如果待排序列总是基本有序，反而可以直接使用冒泡或者直接插入排序。 从最坏情况看，堆排序与归并排序又好于快速排序和其他简单排序，所以对于待排序列基本倒叙则可以考虑堆排序和归并排序。 从空间复杂度上来所，归并排序和快速排序都有相应的空间要求，反而堆排序确是O(1)，所以对于只有少量内存进行排序时可以考虑使用堆排序。并且对于海量数据的排序可以通过建立小顶堆或者大顶堆的方式进行排序。 另外对于线性时间非比较类的3种排序方法：计数排序更适用于在已知序列中的元素0-k之间，且要求排序的复杂度在线性效率上的情况。桶排序可应用于数据量分布比较均匀，或比较侧重区间数量时使用。基数排序最适用于基数很大但关键字较小的序列 Java中的排序算法Java中主要排序方法为 java.util.Arrays.sort()，对于原始数据类型使用三向切分的快速排序，对于引用类型使用归并排序。","link":"/2020/05/03/%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"},{"title":"Redis初探","text":"","link":"/2020/06/18/Redis%E5%88%9D%E6%8E%A2/"},{"title":"leetcode贪心思想练习","text":"贪心思想练习tips 贪心思想在对问题进行求解时，总是做出在当前看来是最好的选择。所以适用贪心算法的场景是子问题的最优解能够递推得到最终问题的最优解。 1.分配饼干 给一个孩子的饼干应当尽量小并且又能满足该孩子，这样大饼干才能拿来给满足度比较大的孩子。 因为满足度最小的孩子最容易得到满足，所以先满足满足度最小的孩子。 455. Assign Cookies (Easy) 12345678910111213141516class Solution { public int findContentChildren(int[] g, int[] s) { Arrays.sort(g); Arrays.sort(s); int res = 0; int i=0,j=0; while(i&lt;s.length &amp;&amp; j&lt;g.length){ if(s[i]&gt;=g[j]){ i++; j++; res++; }else i++; } return res; }} 2.不重叠的区间个数435. Non-overlapping Intervals (Medium) 先计算最多能组成的不重叠区间个数，然后用区间总个数减去不重叠区间的个数。 在每次选择不重叠区间时，区间的结尾最为重要，选择的区间结尾越小，留给后面的区间的空间越大，那么后面能够选择的区间个数也就越大，那么需要删除的区间个数也就最小。 按区间的结尾进行排序，每次选择结尾最小，并且和前一个区间不重叠的区间。 123456789101112131415161718class Solution { public int eraseOverlapIntervals(int[][] intervals) { if(intervals.length==0) return 0; Arrays.sort(intervals,new Comparator&lt;int[]&gt;(){ public int compare(int[] o1,int[]o2){ return o1[1]-o2[1]; } }); int count = 1; int end = intervals[0][1]; for(int i=1;i&lt;intervals.length;i++){ if(intervals[i][0]&lt;end) continue; end = intervals[i][1]; count++; } return intervals.length-count; }} 3. 投飞镖刺破气球452. Minimum Number of Arrows to Burst Balloons (Medium)也是计算不重叠的区间个数，不过和上面不重叠区间的区别在于，[1, 2] 和 [2, 3] 在本题中算是重叠区间。 1234567891011121314151617class Solution { public int findMinArrowShots(int[][] points) { if(points.length==0) return 0; Arrays.sort(points,new Comparator&lt;int[]&gt;(){ public int compare(int[] o1,int[]o2){ return o1[1]-o2[1]; } }); int count = 1,end = points[0][1]; for(int i=1;i&lt;points.length;i++){ if(points[i][0]&lt;=end) continue; end = points[i][1]; count++; } return count; }} 4.根据身高和序号重组队列406. Queue Reconstruction by Height(Medium) 为了使插入操作不影响后续的操作，身高较高的学生应该先做插入操作，否则身高较小的学生原先正确插入的第 k 个位置可能会变成第 k+1 个位置。 身高 h 降序、个数 k 值升序，然后将某个学生插入队列的第 k 个位置中。 1234567891011121314class Solution { public int[][] reconstructQueue(int[][] people) { if (people == null || people.length == 0 || people[0].length == 0) { return new int[0][0]; } //身高升序 个数降序 Arrays.sort(people, (a,b) -&gt; (a[0]==b[0] ? a[1]-b[1] : b[0]-a[0])); List&lt;int[]&gt; list = new ArrayList&lt;&gt;(); for(int[] p:people){ list.add(p[1],p); } return list.toArray(new int[list.size()][]); }} 5.买卖股票最大的收益121. Best Time to Buy and Sell Stock (Easy) 123456789101112class Solution { public int maxProfit(int[] prices) { if(prices.length==0) return 0; int min = prices[0]; int res = 0; for(int p:prices){ if(p&lt;min) min = p; else res = Math.max(res,p-min); } return res; }} 6.买卖股票的最大收益 II122. Best Time to Buy and Sell Stock II (Easy) 对于 [a, b, c, d]，如果有 a &lt;= b &lt;= c &lt;= d ，那么最大收益为 d - a。而 d - a = (d - c) + (c - b) + (b - a) ，因此当访问到一个 prices[i] 且 prices[i] - prices[i-1] &gt; 0，那么就把 prices[i] - prices[i-1] 添加到收益中。 123456789class Solution { public int maxProfit(int[] prices) { int res = 0; for(int i=1;i&lt;prices.length;i++){ if(prices[i]&gt;prices[i-1]) res+=prices[i]-prices[i-1]; } return res; }} 7. 种植花朵605. Can Place Flowers (Easy) 123456789101112131415class Solution { public boolean canPlaceFlowers(int[] flowerbed, int n) { int count = 0; for(int i=0;i&lt;flowerbed.length;i++){ if(flowerbed[i]==1) continue; int pre = i==0 ? 0 : flowerbed[i-1]; //开始位置的前面记为0 int next = i==flowerbed.length-1 ? 0 : flowerbed[i+1]; //结束位置的后面也记为0 if(pre==0 &amp;&amp; next==0){ count++; flowerbed[i]==1; } } return count&gt;=n; }} 8.修改一个数成为非递减数组665. Non-decreasing Array (Easy) 在出现 nums[i] &lt; nums[i - 1] 时，需要考虑的是应该修改数组的哪个数，使得本次修改能使 i 之前的数组成为非递减数组，并且 不影响后续的操作 。优先考虑令 nums[i - 1] = nums[i]，因为如果修改 nums[i] = nums[i - 1] 的话，那么 nums[i] 这个数会变大，就有可能比 nums[i + 1] 大，从而影响了后续操作。还有一个比较特别的情况就是 nums[i] &lt; nums[i - 2]，修改 nums[i - 1] = nums[i] 不能使数组成为非递减数组，只能修改 nums[i] = nums[i - 1]。 12345678910111213class Solution { public boolean checkPossibility(int[] nums) { int count = 0; for(int i=1;i&lt;nums.length;i++){ if(nums[i]&lt;nums[i-1]){ count++; if(i-2&gt;=0 &amp;&amp; nums[i]&lt;nums[i-2]) nums[i] = nums[i-1]; else nums[i-1] = nums[i]; } } return count&lt;=1; }}","link":"/2020/06/09/leetcode%E8%B4%AA%E5%BF%83%E6%80%9D%E6%83%B3%E7%BB%83%E4%B9%A0/"},{"title":"Java连接redis的Jedis以及Springboot整合redis","text":"主要内容 Jedis的基本使用 Springboot整合redis Springboot整合redis源码分析 Jedis的基本使用 什么是Jedis? Jedis是 Redis 官方推荐的 java连接开发工具！ 使用Java 操作Redis 中间件！如果我们要使用java操作redis，那么一定要对Jedis 十分的熟悉！ 1.导入Jedis的依赖 1234567891011121314&lt;dependencies&gt; &lt;!--导入Jedis的包--&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--导入fastjson包方便我们下面进行测试--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.71&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.编码测试 1234567891011121314151617181920212223package com.company.test;import redis.clients.jedis.Jedis;import java.util.Set;public class TestJedis { public static void main(String[] args) { //1.新建Jedis对象 点开源码会有很多重载的方法 // 这里就使用常用的 主机地址+端口号 Jedis jedis = new Jedis(\"redis服务器的IP地址\",6379); //2.使用jedis对象进行操作 这里的方法和我们之前学习的redis基本指令完全相同 jedis.set(\"k1\",\"v1\"); jedis.set(\"k2\",\"v2\"); System.out.println(jedis.get(\"k1\")); Set&lt;String&gt; keys = jedis.keys(\"*\"); System.out.println(keys); //3.关闭连接 jedis.close(); }} 同样，我们这里也来测试一下redis的事务 123456789101112131415161718192021222324252627282930313233package com.company.test;import com.alibaba.fastjson.JSONObject;import redis.clients.jedis.Jedis;import redis.clients.jedis.Transaction;public class TestTX { public static void main(String[] args) { Jedis jedis = new Jedis(\"redis服务器的IP地址\",6379); JSONObject jsonObject = new JSONObject(); jsonObject.put(\"name\",\"chen33\"); jsonObject.put(\"age\",18); //开启事务 Transaction multi = jedis.multi(); String result = jsonObject.toJSONString(); try { multi.set(\"user1\",result); multi.set(\"user2\",result); //执行事务 multi.exec(); } catch (Exception e) { //出错则放弃事务 multi.discard(); e.printStackTrace(); } finally { System.out.println(jedis.get(\"user1\")); System.out.println(jedis.get(\"user2\")); jedis.close(); } }} Springboot整合redis1.导入redis依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 2.配置连接 123# 配置redis 其他配置用的时候再配spring.redis.host= redis服务器的IP地址spring.redis.port=6379 3.测试 12 Springboot整合redis源码分析","link":"/2020/06/20/Java%E8%BF%9E%E6%8E%A5redis%E7%9A%84Jedis%E4%BB%A5%E5%8F%8ASpringboot%E6%95%B4%E5%90%88redis/"},{"title":"Redis数据类型","text":"主要内容 String、List、Set、Hash、Zset应用场景及常用API Geospatial、Hyperloglog、Bitmap应用场景及常用API 五种基本数据类型String(字符串)123456789101112131415161718192021222324252627282930313233343536373839404142127.0.0.1:6379&gt; keys * # 查看所有的key(empty list or set)127.0.0.1:6379&gt; set name chen33 # set keyOK127.0.0.1:6379&gt; set age 18OK127.0.0.1:6379&gt; keys *1) \"age\"2) \"name\"127.0.0.1:6379&gt; exists name # 判断当前key是否存在(integer) 1127.0.0.1:6379&gt; exists name1(integer) 0127.0.0.1:6379&gt; del name # 移除当前的key(integer) 1127.0.0.1:6379&gt; keys *1) \"age\"127.0.0.1:6379&gt; set name coderchen33OK127.0.0.1:6379&gt; keys *1) \"age\"2) \"name\"127.0.0.1:6379&gt; get name\"coderchen33\"127.0.0.1:6379&gt; expire name 10 # 设置key的过期时间，单位是秒(integer) 1127.0.0.1:6379&gt; ttl name # 查看当前key的剩余时间(integer) 7127.0.0.1:6379&gt; ttl name(integer) 4127.0.0.1:6379&gt; ttl name(integer) 2127.0.0.1:6379&gt; ttl name(integer) -2127.0.0.1:6379&gt; get name(nil)127.0.0.1:6379&gt; keys *1) \"age\"127.0.0.1:6379&gt; type name # 查看当前key的类型none127.0.0.1:6379&gt; type agestring 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121##########################################################################127.0.0.1:6379&gt; set k1 v1 # 设置值OK127.0.0.1:6379&gt; get k1 # 获得值\"v1\"127.0.0.1:6379&gt; keys * # 查看所有key1) \"k1\"127.0.0.1:6379&gt; exists k1 # 判断当前key是否存在(integer) 1127.0.0.1:6379&gt; append k1 hello # 追加字符串，如果当前key不存在，就相当于setkey(integer) 7127.0.0.1:6379&gt; get k1\"v1hello\"127.0.0.1:6379&gt; strlen k1 # 获取字符串的长度(integer) 7########################################################################## # incr 自增1# decr 自减1# incrby 和 decrby可以指定步长127.0.0.1:6379&gt; set views 0 # 初始浏览量为0OK127.0.0.1:6379&gt; incr views # 自增1 浏览量变为1(integer) 1127.0.0.1:6379&gt; incr views # 自增1 浏览量变为2(integer) 2127.0.0.1:6379&gt; get views\"2\"127.0.0.1:6379&gt; decr views # 自减1 浏览量-1(integer) 1127.0.0.1:6379&gt; decr views(integer) 0127.0.0.1:6379&gt; decr views(integer) -1127.0.0.1:6379&gt; incr views(integer) 0127.0.0.1:6379&gt; incrby views 10 # 可以设置步长，指定增量(integer) 10127.0.0.1:6379&gt; decrby views 5(integer) 5127.0.0.1:6379&gt; get views\"5\"########################################################################### getrange 获得指定范围内的值# setrange 修改指定范围内的值127.0.0.1:6379&gt; set k1 coderchen33OK127.0.0.1:6379&gt; get k1\"coderchen33\"127.0.0.1:6379&gt; getrange k1 0 4 # 截取字符串 [0,4]\"coder\"127.0.0.1:6379&gt; getrange k1 0 -1 # 获取全部的字符串 和 get k1是一样的\"coderchen33\"127.0.0.1:6379&gt; set k2 abcdefgOK127.0.0.1:6379&gt; get k2\"abcdefg\"127.0.0.1:6379&gt; setrange k2 1 xx # 替换指定位置开始的字符串(integer) 7127.0.0.1:6379&gt; get k2\"axxdefg\"########################################################################### setex (set with expire) # 设置过期时间# setnx (set if not exist) # 不存在在设置 （在分布式锁中会常常使用！）127.0.0.1:6379&gt; setex key3 30 \"hello\" # 设置key3 的值为 hello,30秒后过期OK127.0.0.1:6379&gt; ttl key3(integer) 26127.0.0.1:6379&gt; get key3\"hello\"127.0.0.1:6379&gt; setnx mykey \"redis\" # 如果mykey 不存在，创建mykey(integer) 1127.0.0.1:6379&gt; keys *1) \"key2\"2) \"mykey\"3) \"key1\"127.0.0.1:6379&gt; ttl key3(integer) -2127.0.0.1:6379&gt; setnx mykey \"MongoDB\" # 如果mykey存在，创建失败！(integer) 0127.0.0.1:6379&gt; get mykey\"redis\"###########################################################################mset 同时设置多个值#mget 同时获取多个值127.0.0.1:6379&gt; mset k1 v1 k2 v2 k3 v3 # 同时设置多个值OK127.0.0.1:6379&gt; keys *1) \"k1\"2) \"k2\"3) \"k3\"127.0.0.1:6379&gt; mget k1 k2 k3 # 同时获取多个值1) \"v1\"2) \"v2\"3) \"v3\"127.0.0.1:6379&gt; msetnx k1 v1 k4 v4 # msetnx 是一个原子性的操作，要么一起成功，要么一起失败！(integer) 0127.0.0.1:6379&gt; get k4(nil)########################################################################### 对象set user:1 {name:zhangsan,age:3} # 设置一个user:1 对象 值为 json字符来保存一个对象！# 这里的key是一个巧妙的设计： user:{id}:{filed} , 如此设计在Redis中是完全OK了！127.0.0.1:6379&gt; mset user:1:name zhangsan user:1:age 2OK127.0.0.1:6379&gt; mget user:1:name user:1:age1) \"zhangsan\"2) \"2\"########################################################################### getset 先get然后在set127.0.0.1:6379&gt; getset db redis # 如果不存在值，则返回 nil(nil)127.0.0.1:6379&gt; get db\"redis127.0.0.1:6379&gt; getset db mongodb # 如果存在值，获取原来的值，并设置新的值\"redis\"127.0.0.1:6379&gt; get db\"mongodb\" String类似的使用场景：value除了是我们的字符串还可以是我们的数字！ 计数器 统计多单位的数量 粉丝数 对象缓存存储！ List(列表)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116##########################################################################127.0.0.1:6379&gt; lpush list one #列表头部添加元素(integer) 1127.0.0.1:6379&gt; lpush list two(integer) 2127.0.0.1:6379&gt; lpush list three(integer) 3127.0.0.1:6379&gt; lrange list 0 -1 # 查看列表中所有元素1) \"three\"2) \"two\"3) \"one\"127.0.0.1:6379&gt; lrange list 0 1 # 查看指定范围元素1) \"three\"2) \"two\"127.0.0.1:6379&gt; rpush list zero # 列表尾部插入元素(integer) 4127.0.0.1:6379&gt; lrange list 0 -11) \"three\"2) \"two\"3) \"one\"4) \"zero\"127.0.0.1:6379&gt; lpop list # 列表头部删除元素\"three\"127.0.0.1:6379&gt; lpop list\"two\"127.0.0.1:6379&gt; lrange list 0 -11) \"one\"2) \"zero\"127.0.0.1:6379&gt; rpop list # 列表尾部删除元素\"zero\"127.0.0.1:6379&gt; rpop list\"one\"###########################################################################lset 将列表中指定下标的值替换为另外一个值127.0.0.1:6379&gt; EXISTS list # 判断这个列表是否存在(integer) 0127.0.0.1:6379&gt; lset list 0 item # 如果不存在列表我们去更新就会报错(error) ERR no such key127.0.0.1:6379&gt; lpush list value1(integer) 1127.0.0.1:6379&gt; lrange list 0 01) \"value1\"127.0.0.1:6379&gt; lset list 0 item # 如果存在，更新当前下标的值OK127.0.0.1:6379&gt; lrange list 0 01) \"item\"127.0.0.1:6379&gt; lset list 1 other # 如果不存在，则会报错！(error) ERR index out of range###########################################################################linsert 将某个具体的value插入到列把你中某个元素的前面或者后面！127.0.0.1:6379&gt; rpush mylist \"hello\"(integer) 1127.0.0.1:6379&gt; rpush mylist \"world\"(integer) 2127.0.0.1:6379&gt; linsert mylist before \"world\" \"other\"(integer) 3127.0.0.1:6379&gt; lrange mylist 0 -11) \"hello\"2) \"other\"3) \"world\"127.0.0.1:6379&gt; linsert mylist after world new(integer) 4127.0.0.1:6379&gt; LRANGE mylist 0 -11) \"hello\"2) \"other\"3) \"world\"4) \"new\"########################################################################### lindex 获得指定下标处的值# llen 获得列表长度127.0.0.1:6379&gt; lpush list one (integer) 1127.0.0.1:6379&gt; lpush list two(integer) 2127.0.0.1:6379&gt; lindex list 1 #获得list的下标1处元素\"one\"127.0.0.1:6379&gt; lindex list 0\"two\"127.0.0.1:6379&gt; llen list # 获得列表长度(integer) 2########################################################################### lrem删除list集合中指定个数的元素127.0.0.1:6379&gt; lrange list 0 -11) \"three\"2) \"three\"3) \"two\"4) \"one\"127.0.0.1:6379&gt; lrem list 1 one # 删除list集合中指定个数的元素(integer) 1127.0.0.1:6379&gt; lrange list 0 -11) \"three\"2) \"three\"3) \"two\"127.0.0.1:6379&gt; lrem list 2 three(integer) 2127.0.0.1:6379&gt; lrange list 0 -11) \"two\"########################################################################### ltrim 修剪127.0.0.1:6379&gt; rpush mylist hello(integer) 1127.0.0.1:6379&gt; rpush mylist hello2(integer) 2127.0.0.1:6379&gt; rpush mylist hello3(integer) 3127.0.0.1:6379&gt; lrange mylist 0 -11) \"hello\"2) \"hello2\"3) \"hello3\"127.0.0.1:6379&gt; ltrim mylist 1 2 #修建mylist 只剩指定范围内的元素OK127.0.0.1:6379&gt; lrange mylist 0 -11) \"hello2\"2) \"hello3\" Set(集合)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990##########################################################################127.0.0.1:6379&gt; sadd myset hello # 添加元素(integer) 1127.0.0.1:6379&gt; sadd myset coder(integer) 1127.0.0.1:6379&gt; sadd myset chen33(integer) 1127.0.0.1:6379&gt; SMEMBERS myset # 查看集合中所有元素1) \"coder\"2) \"chen33\"3) \"hello\"127.0.0.1:6379&gt; SISMEMBER myset hello # 判断元素是否在集合中(integer) 1127.0.0.1:6379&gt; SISMEMBER myset chen22(integer) 0127.0.0.1:6379&gt; scard myset # 获得集合的大小(integer) 3127.0.0.1:6379&gt; SREM myset hello #删除集合中的指定元素(integer) 1127.0.0.1:6379&gt; scard myset(integer) 2127.0.0.1:6379&gt; SMEMBERS myset1) \"coder\"2) \"chen33\"########################################################################### srandmember 随机抽取一个元素# spop 随机删除一个元素127.0.0.1:6379&gt; SMEMBERS myset1) \"v2\"2) \"v4\"3) \"v3\"4) \"v1\"127.0.0.1:6379&gt; SRANDMEMBER myset #随机抽取一个元素\"v2\"127.0.0.1:6379&gt; SRANDMEMBER myset\"v1\"127.0.0.1:6379&gt; SRANDMEMBER myset 2 #随机抽取指定个数元素1) \"v4\"2) \"v1\"127.0.0.1:6379&gt; SPOP myset # 随机删除一个元素\"v1\"127.0.0.1:6379&gt; SMEMBERS myset1) \"v2\"2) \"v4\"3) \"v3\"127.0.0.1:6379&gt; SPOP myset 2 #随机删除指定个数元素1) \"v3\"2) \"v2\"127.0.0.1:6379&gt; smembers myset1) \"v4\"########################################################################### smove 将一个集合中的元素移动到另一个集合127.0.0.1:6379&gt; SMEMBERS myset1) \"coder\"2) \"hello\"127.0.0.1:6379&gt; sadd myset2 set2(integer) 1127.0.0.1:6379&gt; smove myset myset2 hello # 从myset中移动hello元素到myset2中(integer) 1127.0.0.1:6379&gt; SMEMBERS myset1) \"coder\"127.0.0.1:6379&gt; smembers myset21) \"hello\"2) \"set2\"##########################################################################数字集合类：- 差集 SDIFF- 交集- 并集127.0.0.1:6379&gt; SMEMBERS myset11) \"a\"2) \"c\"3) \"b\"127.0.0.1:6379&gt; smembers myset21) \"e\"2) \"c\"3) \"d\"127.0.0.1:6379&gt; SDIFF myset1 myset2 # 差集 myset1中和myset2中的不同元素1) \"a\"2) \"b\"127.0.0.1:6379&gt; SINTER myset1 myset2 # 交集1) \"c\"127.0.0.1:6379&gt; SUNION myset1 myset2 # 并集1) \"a\"2) \"c\"3) \"b\"4) \"e\"5) \"d\" Hash(哈希)123456789101112131415161718192021222324252627282930313233343536373839127.0.0.1:6379&gt; hset myhash field1 value1 #设置一个字段(integer) 2127.0.0.1:6379&gt; hmset user:1 name chen33 age 18 Province hebei # 设置多个字段 Hash更适合存储对象(integer) 3127.0.0.1:6379&gt; hget user:1 name # 获得一个字段的值\"chen33\"127.0.0.1:6379&gt; hmget user:1 age Province # 获得多个字段的值1) \"18\"2) \"hebei\"127.0.0.1:6379&gt; hgetall user:1 # 获得所有字段和对应的值1) \"name\"2) \"chen33\"3) \"age\"4) \"18\"5) \"Province\"6) \"hebei\"127.0.0.1:6379&gt; hlen user:1 # 获得hash长度(integer) 3127.0.0.1:6379&gt; hexists user:1 age #判断是否存在某个字段(integer) 1127.0.0.1:6379&gt; hkeys user:1 # 获得所有field1) \"name\"2) \"age\"3) \"Province\"127.0.0.1:6379&gt; hvals user:1 # 获得所有value1) \"chen33\"2) \"18\"3) \"hebei\"127.0.0.1:6379&gt; hdel user:1 Province #删除指定字段(integer) 1127.0.0.1:6379&gt; hkeys user:11) \"name\"2) \"age\"##########################################################################127.0.0.1:6379&gt; HINCRBY user:1 age 10 # 增加指定步长(integer) 28127.0.0.1:6379&gt; HINCRBY user:1 age -10(integer) 18 Zset(有序集合)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263########################################################################### set key1 value1# zset key1 score value1127.0.0.1:6379&gt; zadd myset 1 one # 添加一个分数为1的元素one(integer) 1127.0.0.1:6379&gt; zadd myset 2 two(integer) 1127.0.0.1:6379&gt; zrange myset 0 -1 # 查看所有元素1) \"one\"2) \"two\"127.0.0.1:6379&gt; zcard myset # 获得有序集合大小(integer) 2127.0.0.1:6379&gt; zrem myset one # 删除集合中指定元素(integer) 1127.0.0.1:6379&gt; zrange myset 0 -11) \"two\"127.0.0.1:6379&gt; zadd myset 1 yi(integer) 1127.0.0.1:6379&gt; zadd myset 3 three(integer) 1127.0.0.1:6379&gt; zadd myset 1 one(integer) 1127.0.0.1:6379&gt; zrange myset 0 -11) \"one\"2) \"yi\"3) \"two\"4) \"three\"127.0.0.1:6379&gt; zcount myset 1 2 #获取指定区间的元素数量[1,2](integer) 3127.0.0.1:6379&gt; zcount myset 2 3(integer) 2##########################################################################排序如何实现# zrangebyscore 从小到大排序 可以指定范围# zrevrange 从大到小排序127.0.0.1:6379&gt; zadd age 18 chen11(integer) 1127.0.0.1:6379&gt; zadd age 20 chen22(integer) 1127.0.0.1:6379&gt; zadd age 19 chen33(integer) 1127.0.0.1:6379&gt; ZRANGEBYSCORE age -inf +inf # 显示全部的用户 从小到大1) \"chen11\"2) \"chen33\"3) \"chen22\"127.0.0.1:6379&gt; ZRANGEBYSCORE age -inf +inf withscores # 显示所有的用户和对应分数 从小到大1) \"chen11\"2) \"18\"3) \"chen33\"4) \"19\"5) \"chen22\"6) \"20\"127.0.0.1:6379&gt; ZRANGEBYSCORE age -inf 19 withscores # 显示小于19的元素1) \"chen11\"2) \"18\"3) \"chen33\"4) \"19\"127.0.0.1:6379&gt; ZREVRANGE age 0 -1 # 从大到小显示所有元素1) \"chen22\"2) \"chen33\"3) \"chen11\" 三种特殊数据类型Geospatial(地理位置)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576##########################################################################127.0.0.1:6379&gt; GEOADD china:city 116.40 39.90 beijing(integer) 1127.0.0.1:6379&gt; GEOADD china:city 121.47 31.23 shanghai(integer) 1127.0.0.1:6379&gt; GEOADD china:city 106.50 29.53 chongqing 114.05 22.52 shengzhen(integer) 2127.0.0.1:6379&gt; GEOADD china:city 120.16 30.24 hangzhou 108.96 34.26 xian(integer) 2##########################################################################127.0.0.1:6379&gt; GEOPOS china:city beijing1) 1) \"116.39999896287918091\" 2) \"39.90000009167092543\"127.0.0.1:6379&gt; GEOPOS china:city beijing chongqing1) 1) \"116.39999896287918091\" 2) \"39.90000009167092543\"2) 1) \"106.49999767541885376\" 2) \"29.52999957900659211\"##########################################################################127.0.0.1:6379&gt; GEODIST china:city beijing shanghai km\"1067.3788\"127.0.0.1:6379&gt; GEODIST china:city beijing chongqing km\"1464.0708\"##########################################################################127.0.0.1:6379&gt; GEORADIUS china:city 110 30 1000 km1) \"chongqing\"2) \"xian\"3) \"shengzhen\"4) \"hangzhou\"127.0.0.1:6379&gt; GEORADIUS china:city 110 30 500 km1) \"chongqing\"2) \"xian\"127.0.0.1:6379&gt; GEORADIUS china:city 110 30 500 km withdist1) 1) \"chongqing\" 2) \"341.9374\"2) 1) \"xian\" 2) \"483.8340\"127.0.0.1:6379&gt; GEORADIUS china:city 110 30 500 km withcoord1) 1) \"chongqing\" 2) 1) \"106.49999767541885376\" 2) \"29.52999957900659211\"2) 1) \"xian\" 2) 1) \"108.96000176668167114\" 2) \"34.25999964418929977\"##########################################################################127.0.0.1:6379&gt; GEORADIUSBYMEMBER china:city beijing 1000 km1) \"beijing\"2) \"xian\"127.0.0.1:6379&gt; GEORADIUSBYMEMBER china:city shanghai 400 km1) \"hangzhou\"2) \"shanghai\"##########################################################################127.0.0.1:6379&gt; GEOHASH china:city beijing1) \"wx4fbxxfke0\"127.0.0.1:6379&gt; GEOHASH china:city chongqing1) \"wm5xzrybty0\"##########################################################################127.0.0.1:6379&gt; zrange china:city 0 -11) \"chongqing\"2) \"xian\"3) \"shengzhen\"4) \"hangzhou\"5) \"shanghai\"6) \"beijing\"127.0.0.1:6379&gt; zrem china:city beijing(integer) 1127.0.0.1:6379&gt; zrange china:city 0 -11) \"chongqing\"2) \"xian\"3) \"shengzhen\"4) \"hangzhou\"5) \"shanghai\"127.0.0.1:6379&gt; Hyperloglog123456789101112131415161718##########################################################################127.0.0.1:6379&gt; pfadd codehole user1(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 1127.0.0.1:6379&gt; pfadd codehole user2 user3 user4 user5(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 5127.0.0.1:6379&gt; pfadd codehole2 user4 user5 user6 user7 user8(integer) 1127.0.0.1:6379&gt; pfcount codehole2(integer) 5##########################################################################127.0.0.1:6379&gt; pfmerge codehole3 codehole codehole2OK127.0.0.1:6379&gt; pfcount codehole3(integer) 8 Bitmap1234567891011121314151617181920127.0.0.1:6379&gt; setbit sign 0 1(integer) 0127.0.0.1:6379&gt; setbit sign 1 0(integer) 0127.0.0.1:6379&gt; setbit sign 2 0(integer) 0127.0.0.1:6379&gt; setbit sign 3 1(integer) 0127.0.0.1:6379&gt; setbit sign 4 1(integer) 0127.0.0.1:6379&gt; setbit sign 5 0(integer) 0127.0.0.1:6379&gt; setbit sign 6 0(integer) 0127.0.0.1:6379&gt; getbit sign 3(integer) 1127.0.0.1:6379&gt; getbit sign 6(integer) 0127.0.0.1:6379&gt; bitcount sign(integer) 3","link":"/2020/06/18/Redis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"title":"ArrayList源码分析","text":"","link":"/2020/06/21/ArrayList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"redis中的事务","text":"123456789101112131415161718127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; set k3 v3QUEUED127.0.0.1:6379&gt; get k2QUEUED127.0.0.1:6379&gt; set k4 v4QUEUED127.0.0.1:6379&gt; exec1) OK2) OK3) OK4) \"v2\"5) OK 123456789101112127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; set k5 v5QUEUED127.0.0.1:6379&gt; discardOK127.0.0.1:6379&gt; get k5(nil) 1234567891011121314151617181920212223242526272829303132333435127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; getset k2(error) ERR wrong number of arguments for 'getset' command127.0.0.1:6379&gt; set k3 v3QUEUED127.0.0.1:6379&gt; exec(error) EXECABORT Transaction discarded because of previous errors.127.0.0.1:6379&gt; get k1(nil)127.0.0.1:6379&gt; get k3(nil)127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 \"v1\"QUEUED127.0.0.1:6379&gt; incr k1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; set k3 v3QUEUED127.0.0.1:6379&gt; exec1) OK2) (error) ERR value is not an integer or out of range3) OK4) OK127.0.0.1:6379&gt; get k1\"v1\"127.0.0.1:6379&gt; get k3\"v3\" 123456789101112131415127.0.0.1:6379&gt; set money 100OK127.0.0.1:6379&gt; set out 0OK127.0.0.1:6379&gt; watch moneyOK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; decrby money 20QUEUED127.0.0.1:6379&gt; incrby out 20QUEUED127.0.0.1:6379&gt; exec1) (integer) 802) (integer) 20 123456789101112131415127.0.0.1:6379&gt; watch moneyOK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; decrby money 10QUEUED127.0.0.1:6379&gt; incrby out 10QUEUED####################127.0.0.1:6379&gt; exec(nil)127.0.0.1:6379&gt; get money\"200\"127.0.0.1:6379&gt; get out\"20\" 1234127.0.0.1:6379&gt; get money\"80\"127.0.0.1:6379&gt; set money 200OK 12345678910111213127.0.0.1:6379&gt; unwatchOK127.0.0.1:6379&gt; watch moneyOK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; decrby money 15QUEUED127.0.0.1:6379&gt; incrby out 15QUEUED127.0.0.1:6379&gt; exec1) (integer) 1852) (integer) 35","link":"/2020/06/20/redis%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1/"},{"title":"HashMap源码分析","text":"","link":"/2020/06/21/HashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Java集合类概述","text":"","link":"/2020/06/21/Java%E9%9B%86%E5%90%88%E7%B1%BB%E6%A6%82%E8%BF%B0/"},{"title":"HashSet、LinkedHashSet和TreeSet源码分析","text":"","link":"/2020/06/21/HashSet%E3%80%81LinkedHashSet%E5%92%8CTreeSet%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"LinkedList源码分析","text":"","link":"/2020/06/21/LinkedList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"LinkedHashMap源码分析","text":"","link":"/2020/06/21/LinkedHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Map集合的简单使用","text":"","link":"/2020/06/21/Map%E9%9B%86%E5%90%88%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/"},{"title":"TreeMap源码分析","text":"","link":"/2020/06/21/TreeMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"List集合的简单使用","text":"","link":"/2020/06/21/List%E9%9B%86%E5%90%88%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/"},{"title":"leetcode动态规划练习","text":"斐波那契数列1.斐波那契数列509. Fibonacci Number(Easy) 递归法 时间复杂度O(2^n) 空间复杂度O(n) 123456class Solution { public int fib(int N) { if(N&lt;=1) return N; return fib(N-1)+fib(N-2); }} 简单dp 时间复杂度O(n) 空间复杂度O(n) 123456789101112class Solution { public int fib(int N) { if(N&lt;=1) return N; int[] dp = new int[N+1]; dp[0] = 0; dp[1] = 1; for(int i=2;i&lt;=N;i++){ dp[i] = dp[i-1]+dp[i-2]; } return dp[N]; }} 考虑到 dp[i] 只与 dp[i - 1] 和 dp[i - 2] 有关，因此可以只用两个变量来存储 dp[i - 1] 和 dp[i - 2]，使得原来的 O(N) 空间复杂度优化为 O(1) 复杂度。 123456789101112class Solution { public int fib(int N) { if(N&lt;=1) return N; int pre2=0,pre1=1,cur=0; for(int i=2;i&lt;=N;i++){ cur = pre1+pre2; pre2 = pre1; pre1 = cur; } return pre1; }} 2.爬楼梯70. Climbing Stairs (Easy) 和斐波那契数列相同 状态定义 dp[i]:爬到第i级台阶的总方式递推公式 dp[i] = dp[i-1] + dp[i-2] 同样这里dp[i] 只与 dp[i-1]和dp[i-2]，有关为了降低空间复杂度使用两个变量代替 123456789101112class Solution { public int climbStairs(int n) { if(n&lt;=2) return n; int pre2 = 1,pre1 = 2,cur=0; for(int i=3;i&lt;=n;i++){ cur = pre1+pre2; pre2 = pre1; pre1 = cur; } return pre1; }} 3.强盗抢劫198. House Robber (Easy) 状态定义 dp[i]:抢劫前i间房屋的最大价值转移方程 dp[i]= Math.max(dp[i-2]+nums[i],dp[i-1])(抢第i间房子 和 不抢第i间房子 的最大值) 同样这里使用两个变量简化空间 1234567891011class Solution { public int rob(int[] nums) { int pre2=0,pre1=0,cur=0; for(int i=0;i&lt;nums.length;i++){ cur = Math.max(pre2+nums[i],pre1); pre2 = pre1; pre1 = cur; } return pre1; }} 4.强盗在环形街区抢劫213. House Robber II(Medium) 上面问题的升级，我们可以把这个问题分成两个子问题，分别寻找(0,n-2)和(1,n - 1)范围的最大值，并比较最终的最大值即可 1234567891011121314151617class Solution { public int rob(int[] nums) { if(nums==null || nums.length==0) return 0; int n = nums.length; if(n==1) return nums[0]; return Math.max(rob(nums,0,n-2),rob(nums,1,n-1)); } private int rob(int[] nums,int lo,int hi){ int pre2=0,pre1=0,cur=0; for(int i=lo;i&lt;=hi;i++){ cur = Math.max(pre2+nums[i],pre1); pre2 = pre1; pre1 = cur; } return pre1; }} 5.信件错排题目描述：有 N 个 信 和 信封，它们被打乱，求错误装信方式的数量。 状态定义 dp[i]表示前i个信和信封的错误方式数量。 假设第 i 个信装到第 j 个信封里面，而第 j 个信装到第 k 个信封里面。根据 i 和 k 是否相等，有两种情况： i==k，交换 i 和 j 的信后，它们的信和信封在正确的位置，但是其余 i-2 封信有 dp[i-2] 种错误装信的方式。由于 j 有 i-1 种取值，因此共有 (i-1)*dp[i-2] 种错误装信方式。 i != k，交换 i 和 j 的信后，第 i 个信和信封在正确的位置，其余 i-1 封信有 dp[i-1] 种错误装信方式。由于 j 有 i-1 种取值，因此共有 (i-1)*dp[i-1] 种错误装信方式。 综上所述，错误装信数量方式数量即状态转移方程为： dp[i] = (i-1)*dp[i-2] + (i-1)*dp[i-1] 6.母牛生产程序员代码面试指南-P181 题目描述：假设农场中成熟的母牛每年都会生 1 头小母牛，并且永远不会死。第一年有 1 只小母牛，从第二年开始，母牛开始生小母牛。每只小母牛 3 年之后成熟又可以生小母牛。给定整数 N，求 N 年后牛的数量。 第 i 年成熟的牛的数量为：dp[i] = dp[i-1] + dp[i-3] 矩阵路径1.矩阵的最小路径和64. Minimum Path Sum (Medium) 典型的dp问题 状态定义 dp[i][j] 到达坐标(i,j)时的路径和转移方程 dp[i][j] = Math.min(dp[i-1][j],dp[i][j-1])+grid[i][j] (即从左侧走过来 和 从上面走下来) 另外对于边界节点，如最左侧j=0时只能从上往下走 对于最上层i=0只能从左往右走进行处理即可 1234567891011121314151617class Solution { public int minPathSum(int[][] grid) { if(grid==null || grid.length==0 || grid[0].length==0) return 0; int m = grid.length; int n = grid[0].length; int[][] dp = new int[m][n]; dp[0][0] = grid[0][0]; for(int i=0;i&lt;m;i++){ for(int j=0;j&lt;n;j++){ if(i==0 &amp;&amp; j!=0) dp[i][j] = dp[i][j-1] + grid[i][j]; if(i!=0 &amp;&amp; j==0) dp[i][j] = dp[i-1][j] + grid[i][j]; if(i!=0 &amp;&amp; j!=0) dp[i][j] = Math.min(dp[i-1][j],dp[i][j-1])+grid[i][j]; } } return dp[m-1][n-1]; }} 因为我们不需要每一层都需要进行记忆，因此可以把空间复杂度降低为O(n) 1234567891011121314151617class Solution { public int minPathSum(int[][] grid) { if(grid==null || grid.length==0 || grid[0].length==0) return 0; int m = grid.length; int n = grid[0].length; int[] dp = new int[n]; dp[0] = grid[0][0]; for(int i=0;i&lt;m;i++){ for(int j=0;j&lt;n;j++){ if(i==0 &amp;&amp; j!=0) dp[j] = dp[j-1] + grid[i][j]; if(i!=0 &amp;&amp; j==0) dp[j] = dp[j] + grid[i][j]; if(i!=0 &amp;&amp; j!=0) dp[j] = Math.min(dp[j],dp[j-1])+grid[i][j]; } } return dp[n-1]; }} 2.矩阵的总路径数62. Unique Paths (Medium) 状态定义 dp[i][j] 到达（i,j）节点的路径数转移方程 dp[i][j] = dp[i-1][j] + dp[i][j-1] 同样对于边界处理有dp[0][j]=dp[i][0]=1 同样可以可以把空间复杂度降低为O(n) 123456789101112class Solution { public int uniquePaths(int m, int n) { int[] dp = new int[n]; Arrays.fill(dp,1); for(int i=1;i&lt;m;i++){ for(int j=1;j&lt;n;j++){ dp[j] = dp[j] + dp[j-1]; } } return dp[n-1]; }} 最长递增子序列已知一个序列 {S1, S2,…,Sn}，取出若干数组成新的序列 {Si1, Si2,…, Sim}，其中 i1、i2 … im 保持递增，即新序列中各个数仍然保持原数列中的先后顺序，称新序列为原序列的一个子序列。 如果在子序列中，当下标 ix &gt; iy 时，Six &gt; Siy，称子序列为原序列的一个递增子序列 。 定义一个数组 dp 存储最长递增子序列的长度，dp[n] 表示以 Sn 结尾的序列的最长递增子序列长度。对于一个递增子序列 {Si1, Si2,…,Sim}，如果 im &lt; n 并且 Sim &lt; Sn，此时 {Si1, Si2,…, Sim, Sn} 为一个递增子序列，递增子序列的长度增加 1。满足上述条件的递增子序列中，长度最长的那个递增子序列就是要找的，在长度最长的递增子序列上加上 Sn 就构成了以 Sn 为结尾的最长递增子序列。因此dp[n] = max{ dp[i]+1 | Si &lt; Sn &amp;&amp; i &lt; n}。 因为在求 dp[n] 时可能无法找到一个满足条件的递增子序列，此时 {Sn} 就构成了递增子序列，需要对前面的求解方程做修改，令 dp[n] 最小为 1，即： 1dp[n] = max{1, dp[i]+1 | Si &lt; Sn &amp;&amp; i &lt; n} 对于一个长度为 N 的序列，最长递增子序列并不一定会以 SN 为结尾，因此 dp[N] 不是序列的最长递增子序列的长度，需要遍历 dp 数组找出最大值才是所要的结果，max{ dp[i] | 1 &lt;= i &lt;= N} 即为所求。 1.最长递增子序列300. Longest Increasing Subsequence (Medium) 状态定义 dp[i] 到元素i的最长递增子序列的数转移方程 dp[i] = Math.max(dp[i],dp[j]+1) （因为不一定就是i-1，所以是dp[j]） 12345678910111213141516class Solution { public int lengthOfLIS(int[] nums) { if(nums==null || nums.length==0) return 0; int n = nums.length; int[]dp = new int[n]; Arrays.fill(dp,1); int res = 1; for(int i=1;i&lt;n;i++){ for(int j=0;j&lt;i;j++){ if(nums[i]&gt;nums[j]) dp[i] = Math.max(dp[i],dp[j]+1); } res = Math.max(res,dp[i]); } return res; }} 2. 一组整数对能够构成的最长链646. Maximum Length of Pair Chain (Medium) 1234567891011121314151617class Solution { public int findLongestChain(int[][] pairs) { if(pairs==null || pairs.length==0 || pairs[0].length==0) return 0; Arrays.sort(pairs,(a,b)-&gt;(a[0]-b[0])); int n = pairs.length; int[] dp = new int[n]; Arrays.fill(dp,1); int res = 1; for(int i=1;i&lt;n;i++){ for(int j=0;j&lt;i;j++){ if(pairs[j][1]&lt;pairs[i][0]) dp[i] = Math.max(dp[i],dp[j]+1); } res = Math.max(res,dp[i]); } return res; }} 3.最长摆动子序列376. Wiggle Subsequence (Medium) 12345678910111213141516171819202122class Solution { public int wiggleMaxLength(int[] nums) { int n = nums.length; if(nums.length &lt;2) return n; int[] up = new int[n]; int[] down = new int[n]; up[0] = down[0] = 1; for(int i=1;i&lt;n;i++){ if(nums[i]&gt;nums[i-1]){ up[i] = down[i-1]+1; down[i] = down[i-1]; }else if(nums[i]&lt;nums[i-1]){ down[i] = up[i-1]+1; up[i] = up[i-1]; }else { down[i] = down[i-1]; up[i] = up[i-1]; } } return Math.max(down[n-1],up[n-1]); }} 由于只用到了前面一个元素，所以可以降低空间复杂度为O(1) 123456789101112class Solution { public int wiggleMaxLength(int[] nums) { int n = nums.length; if(nums.length &lt;2) return n; int up=1,down=1; for(int i=1;i&lt;nums.length;i++){ if(nums[i]&gt;nums[i-1]) up = down+1; else if(nums[i]&lt;nums[i-1]) down = up+1; } return Math.max(down,up); }} 最长公共子序列对于两个子序列 S1 和 S2，找出它们最长的公共子序列。 定义一个二维数组 dp 用来存储最长公共子序列的长度，其中 dp[i][j] 表示 S1 的前 i 个字符与 S2 的前 j 个字符最长公共子序列的长度。考虑 S1i 与 S2j 值是否相等，分为两种情况： 当 S1i==S2j 时，那么就能在 S1 的前 i-1 个字符与 S2 的前 j-1 个字符最长公共子序列的基础上再加上 S1i 这个值，最长公共子序列长度加 1，即 dp[i][j] = dp[i-1][j-1] + 1。 当 S1i != S2j 时，此时最长公共子序列为 S1 的前 i-1 个字符和 S2 的前 j 个字符最长公共子序列，或者 S1 的前 i 个字符和 S2 的前 j-1 个字符最长公共子序列，取它们的最大者，即 dp[i][j] = max{ dp[i-1][j], dp[i][j-1] }。综上，最长公共子序列的状态转移方程为： 对于长度为 N 的序列 S1 和长度为 M 的序列 S2，dp[N][M] 就是序列 S1 和序列 S2 的最长公共子序列长度。 与最长递增子序列相比，最长公共子序列有以下不同点： 针对的是两个序列，求它们的最长公共子序列。 在最长递增子序列中，dp[i] 表示以 Si 为结尾的最长递增子序列长度，子序列必须包含 Si ；在最长公共子序列中，dp[i][j] 表示 S1 中前 i 个字符与 S2 中前 j 个字符的最长公共子序列长度，不一定包含 S1i 和 S2j。 在求最终解时，最长公共子序列中 dp[N][M] 就是最终解，而最长递增子序列中 dp[N] 不是最终解，因为以 SN 为结尾的最长递增子序列不一定是整个序列最长递增子序列，需要遍历一遍 dp 数组找到最大者。 最长公共子序列1143. Longest Common Subsequence 12345678910111213141516class Solution { public int longestCommonSubsequence(String text1, String text2) { int n1 = text1.length(),n2 = text2.length(); int[][] dp = new int[n1+1][n2+1]; for(int i=1;i&lt;=n1;i++){ for(int j=1;j&lt;=n2;j++){ if(text1.charAt(i-1)==text2.charAt(j-1)){ dp[i][j] = dp[i-1][j-1]+1; }else { dp[i][j] = Math.max(dp[i-1][j],dp[i][j-1]); } } } return dp[n1][n2]; }} 0-1背包有一个容量为 N 的背包，要用这个背包装下物品的价值最大，这些物品有两个属性：体积 w 和价值 v。 定义一个二维数组 dp 存储最大价值，其中 dp[i][j] 表示前 i 件物品体积不超过 j 的情况下能达到的最大价值。设第 i 件物品体积为 w，价值为 v，根据第 i 件物品是否添加到背包中，可以分两种情况讨论： 第 i 件物品没添加到背包，总体积不超过 j 的前 i 件物品的最大价值就是总体积不超过 j 的前 i-1 件物品的最大价值，dp[i][j] = dp[i-1][j]。 第 i 件物品添加到背包中，dp[i][j] = dp[i-1][j-w] + v。 第 i 件物品可添加也可以不添加，取决于哪种情况下最大价值更大。因此，0-1 背包的状态转移方程为： 1dp[i][j] = Math.max(dp[i-1][j],dp[i-1][j-w]+v) 123456789101112131415161718// W 为背包总体积// N 为物品数量// weights 数组存储 N 个物品的重量// values 数组存储 N 个物品的价值public int knapsack(int W, int N, int[] weights, int[] values) { int[][] dp = new int[N + 1][W + 1]; for (int i = 1; i &lt;= N; i++) { int w = weights[i - 1], v = values[i - 1]; for (int j = 1; j &lt;= W; j++) { if (j &gt;= w) { dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - w] + v); } else { dp[i][j] = dp[i - 1][j]; } } } return dp[N][W];} 空间优化 在程序实现时可以对 0-1 背包做优化。观察状态转移方程可以知道，前 i 件物品的状态仅与前 i-1 件物品的状态有关，因此可以将 dp 定义为一维数组，其中 dp[j] 既可以表示 dp[i-1][j] 也可以表示 dp[i][j]。此时， 1dp[j] = Math.max(dp[j],dp[j-w]+v) 因为 dp[j-w] 表示 dp[i-1][j-w]，因此不能先求 dp[i][j-w]，防止将 dp[i-1][j-w] 覆盖。也就是说要先计算 dp[i][j] 再计算 dp[i][j-w]，在程序实现时需要按倒序来循环求解。 123456789101112public int knapsack(int W, int N, int[] weights, int[] values) { int[] dp = new int[W + 1]; for (int i = 1; i &lt;= N; i++) { int w = weights[i - 1], v = values[i - 1]; for (int j = W; j &gt;= 1; j--) { if (j &gt;= w) { dp[j] = Math.max(dp[j], dp[j - w] + v); } } } return dp[W];} 无法使用贪心算法的解释0-1 背包问题无法使用贪心算法来求解，也就是说不能按照先添加性价比最高的物品来达到最优，这是因为这种方式可能造成背包空间的浪费，从而无法达到最优。考虑下面的物品和一个容量为 5 的背包，如果先添加物品 0 再添加物品 1，那么只能存放的价值为 16，浪费了大小为 2 的空间。最优的方式是存放物品 1 和物品 2，价值为 22. id|w|v|v/w|:-:|:-:|:-:|:-:|0|1|6|6|1|2|10|5|2|3|12|4 变种完全背包：物品数量为无限个多重背包：物品数量有限制多维费用背包：物品不仅有重量，还有体积，同时考虑这两种限制其它：物品之间相互约束或者依赖 1.划分数组为和相等的两部分416. Partition Equal Subset Sum (Medium) 这道题可以转换为一个背包大小为sum/2的0-1背包问题 状态定义： dp[i][j] 前i个元素能否达到和为j转移方程 dp[i][j] = dp[i-1][j] || dp[i-1][j-nums[i-1]] 不拿当前元素i 和 拿当前元素i 123456789101112131415161718class Solution { public boolean canPartition(int[] nums) { int n = nums.length; int sum=0; for(int num:nums) sum+=num; if(sum%2==1) return false; int W = sum/2; boolean[][] dp = new boolean[n+1][W+1]; dp[0][0] = true; for(int i=1;i&lt;=n;i++){ for(int j=1;j&lt;=W;j++){ if(j&gt;=nums[i-1]) dp[i][j] = dp[i-1][j] || dp[i-1][j-nums[i-1]]; else dp[i][j] = dp[i-1][j]; } } return dp[n][W]; }} 同样可以简化空间 1234567891011121314151617class Solution { public boolean canPartition(int[] nums) { int n = nums.length; int sum=0; for(int num:nums) sum+=num; if(sum%2==1) return false; int W = sum/2; boolean[] dp = new boolean[W+1]; dp[0] = true; for(int i=1;i&lt;=n;i++){ for(int j=W;j&gt;=1;j--){ if(j&gt;=nums[i-1]) dp[j] = dp[j] || dp[j-nums[i-1]]; } } return dp[W]; }} 2.改变一组数的正负号使得它们的和为一给定数494. Target Sum (Medium) 该问题可以转换为 Subset Sum 问题，从而使用 0-1 背包的方法来求解。 可以将这组数看成两部分，P 和 N，其中 P 使用正号，N 使用负号，有以下推导： 123 sum(P) - sum(N) = targetsum(P) + sum(N) + sum(P) - sum(N) = target + sum(P) + sum(N) 2 * sum(P) = target + sum(nums) 因此只要找到一个子集，令它们都取正号，并且和等于 (target + sum(nums))/2，就证明存在解。 1234567891011121314151617class Solution { public int findTargetSumWays(int[] nums, int S) { int n = nums.length; int sum = 0; for(int num:nums) sum+=num; if(sum&lt;S || (sum + S) % 2 == 1) return 0; int W = (sum+S)/2; int[] dp = new int[W+1]; dp[0] = 1; for(int num:nums){ for(int j=W;j&gt;=num;j--){ dp[j] = dp[j] + dp[j-num]; } } return dp[W]; }} 3.01 字符构成最多的字符串474. Ones and Zeroes (Medium) 这是一个多维费用的 0-1 背包问题，有两个背包大小，0 的数量和 1 的数量。 dp[z][i][j] : 前z个元素在不超过i个0和j个1时的最大数量 同样进行了空间简化 12345678910111213141516171819class Solution { public int findMaxForm(String[] strs, int m, int n) { if(strs==null || strs.length==0) return 0; int[][] dp = new int[m+1][n+1]; for(String s:strs){ int zeros=0,ones=0; for(char c:s.toCharArray()){ if(c=='0') zeros++; else ones++; } for(int i=m;i&gt;=zeros;i--){ for(int j=n;j&gt;=ones;j--){ dp[i][j] = Math.max(dp[i][j],dp[i-zeros][j-ones]+1); } } } return dp[m][n]; }} 4.找零钱的最少硬币数322. Coin Change (Medium) 因为硬币可以重复使用，因此这是一个完全背包问题。完全背包只需要将 0-1 背包的逆序遍历 dp 数组改为正序遍历即可。 12345678910111213class Solution { public int coinChange(int[] coins, int amount) { int[] dp = new int[amount+1]; Arrays.fill(dp,amount+1); dp[0] = 0; for(int coin : coins){ for(int i=coin;i&lt;=amount;i++){ if(i&gt;=coin) dp[i] = Math.min(dp[i],dp[i-coin]+1); } } return dp[amount]&gt;amount ? -1 : dp[amount]; }} 5.找零钱的硬币数组合518. Coin Change 2 (Medium) 12345678910111213class Solution { public int change(int amount, int[] coins) { if(coins==null) return 0; int[] dp = new int[amount+1]; dp[0] = 1; for(int coin:coins){ for(int i=coin;i&lt;=amount;i++){ dp[i] = dp[i] + dp[i-coin]; } } return dp[amount]; }} 6.字符串按单词列表分割139. Word Break (Medium) dict 中的单词没有使用次数的限制，因此这是一个完全背包问题。该问题涉及到字典中单词的使用顺序，也就是说物品必须按一定顺序放入背包中。 求解顺序的完全背包问题时，对物品的迭代应该放在最里层，对背包的迭代放在外层，只有这样才能让物品按一定顺序放入背包中。 12 7.组合总和377. Combination Sum IV (Medium) 12 股票交易","link":"/2020/06/09/leetcode%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%BB%83%E4%B9%A0/"},{"title":"leetcode位运算练习","text":"位运算练习tips: 通常如果比较简单的题目但是限制的要求比较多无法使用一些正常的方法时,或者题目中出现明显的位运算时，考虑使用位运算来解决。 比较常用的是异或^和n&amp;(n-1)以及mask运算来进行解决。 熟悉java中比价常用的api 0.位运算基本知识0s 表示一串 0，1s 表示一串 1。 123x ^ 0s = x x &amp; 0s = 0 x | 0s = xx ^ 1s = ~x x &amp; 1s = x x | 1s = 1sx ^ x = 0 x &amp; x = x x | x = x 利用 x ^ 1s = ~x 的特点，可以将位级表示翻转；利用 x ^ x = 0 的特点，可以将三个数中重复的两个数去除，只留下另一个数。 利用 x &amp; 0s = 0 和 x &amp; 1s = x 的特点，可以实现掩码操作。一个数 num 与 mask：00111100 进行位与操作，只保留 num 中与 mask 的 1 部分相对应的位。 利用 x | 0s = x 和 x | 1s = 1s 的特点，可以实现设值操作。一个数 num 与 mask：00111100 进行位或操作，将 num 中与 mask 的 1 部分相对应的位都设置为 1。 位与运算技巧 n&amp;(n-1) 去除 n 的位级表示中最低的那一位。例如对于二进制表示 10110100，减去 1 得到 10110011，这两个数相与得到 10110000。 n&amp;(-n) 得到 n 的位级表示中最低的那一位。-n 得到 n 的反码加 1，对于二进制表示 10110100，-n 得到 01001100，相与得到 00000100。 n-n&amp;(~n+1) 去除 n 的位级表示中最高的那一位。 移位运算 &gt;&gt; n 为算术右移，相当于除以 2n； &gt;&gt;&gt; n 为无符号右移，左边会补上 0。 &lt;&lt; n 为算术左移，相当于乘以 2n。 mask计算 要获取 111111111，将 0 取反即可，~0。 要得到只有第 i 位为 1 的 mask，将 1 向左移动 i-1 位即可，1&lt;&lt;(i-1) 。例如 1&lt;&lt;4 得到只有第 5 位为 1 的 mask ：00010000。 要得到 1 到 i 位为 1 的 mask，1&lt;&lt;(i+1)-1 即可，例如将 1&lt;&lt;(4+1)-1 = 00010000-1 = 00001111。 要得到 1 到 i 位为 0 的 mask，只需将 1 到 i 位为 1 的 mask 取反，即 ~(1&lt;&lt;(i+1)-1)。 Java 中的位操作 123static int Integer.bitCount(); // 统计 1 的数量static int Integer.highestOneBit(); // 获得最高位static String toBinaryString(int i); // 转换为二进制表示的字符串 1.统计两个数的二进制表示有多少位不同461.Hamming Distance (Easy) 12345678910111213class Solution { public int hammingDistance(int x, int y) { //对两个数异或,则不同的位结果为1 int n = x^y; int res = 0; //利用n&amp;(n-1)去掉最低位的1 while(n!=0){ n = n&amp;(n-1); res++; } return res; }} 也可以使用 Integer.bitcount() 来统计 1 个的个数 123public int hammingDistance(int x, int y) { return Integer.bitCount(x ^ y);} 2.统计从 0 ~ n 每个数的二进制表示中 1 的个数338.Counting Bits (Medium) 1234567891011121314151617class Solution { public int[] countBits(int num) { int[] res = new int[num+1]; for(int i=0;i&lt;=num;i++){ res[i] = count(i); } return res; } private int count(int i){ int sum = 0; while(i!=0){ i=i&amp;(i-1); sum++; } return sum; }} 3.数组中唯一一个不重复的元素136. Single Number (Easy) 首先第一个想到的是利用哈希表，但是题目要求我们不能使用额外空间并且线性时间复杂度，这时候可以考虑使用x^x=0进行求解。 123456789class Solution { public int singleNumber(int[] nums) { int res = 0; for(int num:nums){ res = res^num; } return res; }} 4.数组中不重复的两个元素260.Single Number III (Medium) 两个不相等的元素在位级表示上必定会有一位存在不同。 将数组的所有元素异或得到的结果为不存在重复的两个元素异或的结果。 diff &amp;= -diff 得到出 diff 最右侧不为 0 的位，也就是不存在重复的两个元素在位级表示上最右侧不同的那一位，利用这一位就可以将两个元素区分开来。 1234567891011121314class Solution { public int[] singleNumber(int[] nums) { int[] res = new int[2]; int diff = 0; for(int num:nums) diff ^= num; diff &amp;= - diff; //得到二进制中最右一位不为0的数 for(int num:nums){ //将剩下的数分成两组 if((num &amp; diff)== 0) res[0] ^= num; else res[1] ^= num; } return res; }} 5.找出数组中缺失的那个数268. Missing Number (Easy) 以0 4 3 1缺2为例(顺序无关) Index 0 1 2 3Value 0 1 3 4 missing =4∧(0∧0)∧(1∧1)∧(2∧3)∧(3∧4)=(4∧4)∧(0∧0)∧(1∧1)∧(3∧3)∧2=0∧0∧0∧0∧2=2 123456789class Solution { public int missingNumber(int[] nums) { int missing = nums.length; for(int i=0;i&lt;nums.length;i++){ missing = missing^i^nums[i]; } return missing; }} 6. 翻转一个数的比特位190. Reverse Bits (Easy) 123456789101112public class Solution { // you need treat n as an unsigned value public int reverseBits(int n) { int res = 0; for(int i=0;i&lt;32;i++){ res += n &amp; 1; n &gt;&gt;&gt;=1; if(i&lt;31) res &lt;&lt;=1; } return res; }} 如果该函数需要被调用很多次，可以将 int 拆成 4 个 byte，然后缓存 byte 对应的比特位翻转，最后再拼接起来。 1234567891011121314151617181920212223242526272829// cacheprivate final Map&lt;Byte, Integer&gt; cache = new HashMap&lt;Byte, Integer&gt;();public int reverseBits(int n) { byte[] bytes = new byte[4]; for (int i = 0; i &lt; 4; i++) // convert int into 4 bytes bytes[i] = (byte)((n &gt;&gt;&gt; 8*i) &amp; 0xFF); int result = 0; for (int i = 0; i &lt; 4; i++) { result += reverseByte(bytes[i]); // reverse per byte if (i &lt; 3) result &lt;&lt;= 8; } return result;}private int reverseByte(byte b) { Integer value = cache.get(b); // first look up from cache if (value != null) return value; value = 0; // reverse by bit for (int i = 0; i &lt; 8; i++) { value += ((b &gt;&gt;&gt; i) &amp; 1); if (i &lt; 7) value &lt;&lt;= 1; } cache.put(b, value); return value;} 7. 不用额外变量交换两个数的值程序员代码面试指南 123a = a ^ b;b = a ^ b;a = a ^ b; 8.判断一个数是不是2的n次方231. Power of Two (Easy) 2的整数次幂的二进制表示中只有1位是1，其他全是0 1234567class Solution { public boolean isPowerOfTwo(int n) { if(n&lt;=0) return false; //2的整数次幂的二进制中只有1位是1 return (n&amp;(n-1))==0; }} 9. 判断一个数是不是 4 的 n 次方342. Power of Four (Easy) 4的n次方的整数幂在二进制表示中有且只有一个奇数位为 1，例如 16（10000）。 123456class Solution { public boolean isPowerOfFour(int num) { if(num &lt;=0) return false; return (num&amp;(num-1))== 0 &amp;&amp; (num &amp; 0x55555555) != 0; //5表示0101 }} 10.判断一个数的位级表示是否不会出现连续的 0 和 1693. Binary Number with Alternating Bits (Easy) 对于 1010 这种位级表示的数，把它向右移动 1 位得到 101，这两个数每个位都不同，因此异或得到的结果为 1111。 1234public boolean hasAlternatingBits(int n) { int a = (n ^ (n &gt;&gt; 1)); return (a &amp; (a + 1)) == 0;} 11. 求一个数的补码476. Number Complement (Easy) 这里的补码按题目中的要求是将位中的1变0 0变1即可。并不是我们通常意义上说的补码 num = 00000101mask = 11111000~mask &amp; ~num = 00000010 1234567class Solution { public int findComplement(int num) { int mask = ~0; while ((num&amp;mask) != 0) mask &lt;&lt;= 1; return ~mask &amp; ~num; }} 12.实现整数的加法371. Sum of Two Integers (Easy) a ^ b 表示没有考虑进位的情况下两数的和，(a &amp; b) &lt;&lt; 1 就是进位。 递归会终止的原因是 (a &amp; b) &lt;&lt; 1 最右边会多一个 0，那么继续递归，进位最右边的 0 会慢慢增多，最后进位会变为 0，递归终止。 123public int getSum(int a, int b) { return b == 0 ? a : getSum((a ^ b), (a &amp; b) &lt;&lt; 1);}","link":"/2020/06/06/leetcode%E4%BD%8D%E8%BF%90%E7%AE%97%E7%BB%83%E4%B9%A0/"},{"title":"leetcode栈堆队列练习","text":"栈堆队列的tips: 栈和队列的基本特性: 栈是后入先出、队列是先入先出。 对于单调栈问题的处理 堆主要用来处理Top K问题。(数据流和滑动窗口) 1.用栈实现队列232. Implement Queue using Stacks (Easy) 1.使用两个栈实现。 入队列O(1) 出队列和得到队列元素O(n) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class MyQueue { private Stack&lt;Integer&gt; stack1; private Stack&lt;Integer&gt; stack2; /** Initialize your data structure here. */ public MyQueue() { this.stack1 = new Stack&lt;&gt;(); this.stack2 = new Stack&lt;&gt;(); } /** Push element x to the back of queue. */ public void push(int x) { stack1.push(x); } /** Removes the element from in front of queue and returns that element. */ public int pop() { if(stack2.empty()){ while(!stack1.empty()){ stack2.push(stack1.pop()); } } return stack2.pop(); } /** Get the front element. */ public int peek() { if(stack2.empty()){ while(!stack1.empty()){ stack2.push(stack1.pop()); } } return stack2.peek(); } /** Returns whether the queue is empty. */ public boolean empty() { return stack1.isEmpty() &amp;&amp; stack2.isEmpty(); }}/** * Your MyQueue object will be instantiated and called as such: * MyQueue obj = new MyQueue(); * obj.push(x); * int param_2 = obj.pop(); * int param_3 = obj.peek(); * boolean param_4 = obj.empty(); */ 使用两个栈。 入队列O(n),出队列和取得队列元素O(1) 123456789101112131415161718192021222324252627282930313233343536373839404142434445class MyQueue { private Stack&lt;Integer&gt; stack1; private Stack&lt;Integer&gt; stack2; /** Initialize your data structure here. */ public MyQueue() { this.stack1 = new Stack&lt;&gt;(); this.stack2 = new Stack&lt;&gt;(); } /** Push element x to the back of queue. */ public void push(int x) { while(!stack1.isEmpty()){ stack2.push(stack1.pop()); } stack1.push(x); while(!stack2.isEmpty()){ stack1.push(stack2.pop()); } } /** Removes the element from in front of queue and returns that element. */ public int pop() { return stack1.pop(); } /** Get the front element. */ public int peek() { return stack1.peek(); } /** Returns whether the queue is empty. */ public boolean empty() { return stack1.isEmpty(); }}/** * Your MyQueue object will be instantiated and called as such: * MyQueue obj = new MyQueue(); * obj.push(x); * int param_2 = obj.pop(); * int param_3 = obj.peek(); * boolean param_4 = obj.empty(); */ 2.用队列实现栈225. Implement Stack using Queues (Easy) 1.使用两个队列，入栈O(1) 出栈和获得栈顶元素O(n) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class MyStack { private Queue&lt;Integer&gt; queue1; private Queue&lt;Integer&gt; queue2; /** Initialize your data structure here. */ public MyStack() { this.queue1 = new LinkedList&lt;&gt;(); this.queue2 = new LinkedList&lt;&gt;(); } /** Push element x onto stack. */ public void push(int x) { queue1.offer(x); } /** Removes the element on top of the stack and returns that element. */ public int pop() { int len = queue1.size(); for(int i=0;i&lt;len-1;i++){ queue2.offer(queue1.poll()); } Queue&lt;Integer&gt; temp = queue1; queue1 = queue2; queue2 = temp; return queue2.poll(); } /** Get the top element. */ public int top() { int len = queue1.size(); for(int i=0;i&lt;len-1;i++){ queue2.offer(queue1.poll()); } int top = queue1.peek(); queue2.offer(queue1.poll()); Queue&lt;Integer&gt; temp = queue1; queue1 = queue2; queue2 = temp; return top; } /** Returns whether the stack is empty. */ public boolean empty() { return queue1.isEmpty(); }}/** * Your MyStack object will be instantiated and called as such: * MyStack obj = new MyStack(); * obj.push(x); * int param_2 = obj.pop(); * int param_3 = obj.top(); * boolean param_4 = obj.empty(); */ 2.使用两个队列，入栈O(n) 出栈和获得栈顶元素O(1) 123456789101112131415161718192021222324252627282930313233343536373839404142434445class MyStack { private Queue&lt;Integer&gt; queue1; private Queue&lt;Integer&gt; queue2; /** Initialize your data structure here. */ public MyStack() { this.queue1 = new LinkedList&lt;&gt;(); this.queue2 = new LinkedList&lt;&gt;(); } /** Push element x onto stack. */ public void push(int x) { while(!queue1.isEmpty()){ queue2.offer(queue1.poll()); } queue1.offer(x); while(!queue2.isEmpty()){ queue1.offer(queue2.poll()); } } /** Removes the element on top of the stack and returns that element. */ public int pop() { return queue1.poll(); } /** Get the top element. */ public int top() { return queue1.peek(); } /** Returns whether the stack is empty. */ public boolean empty() { return queue1.isEmpty(); }}/** * Your MyStack object will be instantiated and called as such: * MyStack obj = new MyStack(); * obj.push(x); * int param_2 = obj.pop(); * int param_3 = obj.top(); * boolean param_4 = obj.empty(); */ 3.使用一个队列，入栈O(n) 出栈和获得栈顶元素O(1) 1234567891011121314151617181920212223242526272829303132333435363738394041class MyStack { private Queue&lt;Integer&gt; queue1; /** Initialize your data structure here. */ public MyStack() { this.queue1 = new LinkedList&lt;&gt;(); } /** Push element x onto stack. */ public void push(int x) { queue1.offer(x); int len = queue1.size(); for(int i=0;i&lt;len-1;i++){ queue1.offer(queue1.poll()); } } /** Removes the element on top of the stack and returns that element. */ public int pop() { return queue1.poll(); } /** Get the top element. */ public int top() { return queue1.peek(); } /** Returns whether the stack is empty. */ public boolean empty() { return queue1.isEmpty(); }}/** * Your MyStack object will be instantiated and called as such: * MyStack obj = new MyStack(); * obj.push(x); * int param_2 = obj.pop(); * int param_3 = obj.top(); * boolean param_4 = obj.empty(); */ 3.最小值栈155. Min Stack (Easy) 123456789101112131415161718192021222324252627282930313233343536373839class MinStack { private Stack&lt;Integer&gt; dataStack; private Stack&lt;Integer&gt; minStack; int min = Integer.MAX_VALUE; /** initialize your data structure here. */ public MinStack() { this.dataStack = new Stack&lt;&gt;(); this.minStack = new Stack&lt;&gt;(); } public void push(int x) { dataStack.push(x); if(x&lt;min) min = x; minStack.push(min); } public void pop() { dataStack.pop(); minStack.pop(); min = minStack.isEmpty()?Integer.MAX_VALUE:minStack.peek(); } public int top() { return dataStack.peek(); } public int getMin() { return minStack.peek(); }}/** * Your MinStack object will be instantiated and called as such: * MinStack obj = new MinStack(); * obj.push(x); * obj.pop(); * int param_3 = obj.top(); * int param_4 = obj.getMin(); */ 4.括号匹配20. Valid Parentheses(Easy) 12345678910111213class Solution { public boolean isValid(String s) { Stack&lt;Character&gt; stack = new Stack&lt;&gt;(); for(char c:s.toCharArray()){ if(c=='(' || c=='[' || c=='{'){stack.push(c);} else if(c==')' &amp;&amp; !stack.isEmpty()&amp;&amp;stack.peek()=='(') stack.pop(); else if(c==']' &amp;&amp; !stack.isEmpty()&amp;&amp;stack.peek()=='[') stack.pop(); else if(c=='}' &amp;&amp; !stack.isEmpty()&amp;&amp;stack.peek()=='{') stack.pop(); else return false; } return stack.isEmpty(); }} 下面的5.6.7都是单调栈的应用 5.数组中元素与下一个比它大的元素之间的距离739. Daily Temperatures (Medium) 我们维护一个单调递减的stack，stack内部存的是原数组的每个index。每当我们遇到一个比当前栈顶所对应的数（就是T[i]&gt;T[stack.peek()）大的数的时候，我们就遇到了一个“大数“。这个”大数“比它之前多少个数大我们不知道，但是至少比当前栈顶所对应的数大。我们弹出栈内所有对应数比这个数小的栈内元素，并更新它们在返回数组中对应位置的值。因为这个栈本身的单调性，当我们栈顶元素所对应的数比这个元素大的时候，我们可以保证，栈内所有元素都比这个元素大。对于每一个元素，当它出栈的时候，说明它遇到了自己的next greater element，我们也就要更新return数组中的对应位置的值。如果一个元素一直不曾出栈，那么说明不存在next greater element，我们也就不用更新return数组了。 1234567891011121314151617class Solution { public int[] dailyTemperatures(int[] T) { int[] res = new int[T.length]; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); for(int i=0;i&lt;T.length;i++){ //2. 更改距离 //因为不知道有多少个数比新加入的T[i]小，所以使用while循环 while(!stack.isEmpty() &amp;&amp; T[i]&gt;T[stack.peek()]){ int index = stack.pop(); res[index] = i-index; } //1.把index先push进去 stack.push(i); } return res; }} 6.数组比当前数组中元素大的下一个元素496. Next Greater Element I (Easy) 123456789101112131415class Solution { public int[] nextGreaterElement(int[] nums1, int[] nums2) { int[] res = new int[nums1.length]; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); for(int num:nums2){ while(!stack.isEmpty() &amp;&amp; stack.peek()&lt;num) map.put(stack.pop(),num); stack.push(num); } for(int i=0;i&lt;nums1.length;i++){ res[i] = map.getOrDefault(nums1[i],-1); } return res; }} 7.循环数组中比当前元素大的下一个元素503. Next Greater Element II (Medium) 这里需要注意对于循环数组的问题一个常见的处理手段就是通过余数，然后将数组的长度扩大两倍即可 1234567891011121314class Solution { public int[] nextGreaterElements(int[] nums) { int N = nums.length; int[] res = new int[N]; Arrays.fill(res,-1); Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); for(int i=0;i&lt; 2*N;i++){ int num = nums[i%N]; while(!stack.isEmpty() &amp;&amp; num&gt;nums[stack.peek()]) res[stack.pop()] = num; if(i&lt;N) stack.push(i); } return res; }} 8.返回数据流中第K大元素703. Kth Largest Element in a Stream (Easy) 12345678910111213141516171819202122232425262728class KthLargest { private PriorityQueue&lt;Integer&gt; q; //Java中默认是小顶堆 private int k; public KthLargest(int k, int[] nums) { this.k = k; q = new PriorityQueue&lt;&gt;(k); for(int num:nums){ add(num); } } public int add(int val) { if(q.size()&lt;k) q.offer(val); else if(q.peek() &lt; val){ q.poll(); q.offer(val); } return q.peek(); }}/** * Your KthLargest object will be instantiated and called as such: * KthLargest obj = new KthLargest(k, nums); * int param_1 = obj.add(val); */ 9. 滑动窗口最大值239. Sliding Window Maximum (Hard) 1234567891011121314151617class Solution { public int[] maxSlidingWindow(int[] nums, int k) { if(nums == null || k==0 || nums.length&lt;k) return new int[0]; int[] res = new int[nums.length-k+1]; Deque&lt;Integer&gt; window = new LinkedList&lt;&gt;(); for(int i=0;i&lt;nums.length;i++){ //超出window左界 if(i&gt;=k &amp;&amp; window.peekFirst() &lt;= i-k) window.pollFirst(); while(!window.isEmpty() &amp;&amp; nums[i]&gt;nums[window.peekLast()]) window.pollLast(); window.offer(i); if (i &gt;= k-1) { res[i - k+1] = nums[window.peekFirst()]; } } return res; }}","link":"/2020/05/11/leetcode%E6%A0%88%E5%A0%86%E9%98%9F%E5%88%97%E7%BB%83%E4%B9%A0/"},{"title":"leetcode字符串练习","text":"字符串练习tips 通常字符串是结合其他算法进行考察，如果是单纯的字符串问题，只需要具体问题具体分析即可。 A的ascii码是65 小a的ascii码是97。使用过程中通常会定义数组int[256]进行哈希存储键盘可输入字符的次数。 Java中对于字符串的常用API等。 1.字符串循环移位包含编程之美 3.1 给定两个字符串 s1 和 s2，要求判定 s2 是否能够被 s1 做循环移位得到的字符串包含。 s1 = AABCD, s2 = CDAAReturn : true s1 进行循环移位的结果是 s1s1 的子字符串，因此只要判断 s2 是否是 s1s1 的子字符串即可。 例如如果保留循环移位前的单词，那么AABCD会变为AABCDA AABCDAA .. 最终变为AABCDAABCD,这时只需要在s1s1中判断是否存在s2即可。 12s1 += s1;return s1.indexOf(s2)!=-1; 2.字符串循环移位编程之美 2.17 将字符串向右循环移动 k 位。 s = “abcd123” k = 3Return “123abcd” 将 abcd123 中的 abcd 和 123 单独翻转，得到 dcba321，然后对整个字符串进行翻转，得到 123abcd。 1234567891011121314void RightShift(char[] str,int N,int k){ K%=N; //K可能大于N reverse(str,0,N-K-1); reverse(str,N-K,N-1); reverse(str,0,N-1);} void reverse(char[] str,int lo,int hi){ for(;lo&lt;hi;lo++,hi--){ char temp = str[lo]; str[lo] = str[hi]; str[hi] = temp; }} 3.字符串中单词的翻转程序员代码面试指南 s = “I am a student”Return “student a am I” 和上面的方法类似，先将每个单词翻转，然后将整个字符串翻转。 4.两个字符串包含的字符是否完全相同242. Valid Anagram (Easy) 12345678910class Solution { public boolean isAnagram(String s, String t) { int[] count = new int[26];//本题只包含小写字符 for(char c:s.toCharArray()) count[c-'a']++; for(char c:t.toCharArray()) count[c-'a']--; for(int x:count) if(x!=0) return false; return true; }} 5. 计算一组字符集合可以组成的回文字符串的最大长度409.Longest Palindrome (Easy) 123456789101112class Solution { public int longestPalindrome(String s) { int res = 0; int[] count = new int[256]; for(char c:s.toCharArray()) count[c]++; for(int x:count){ res += x/2*2; //比如3个可以拿出两个来凑回文字符串 } if(res&lt;s.length()) res++; return res; }} 6.字符串同构205. Isomorphic Strings (Easy) 只需要记录上次字符出现的位置即可。 12345678910111213class Solution { public boolean isIsomorphic(String s, String t) { if(s.length()!=t.length()) return false; int[] m1 = new int[256]; int[] m2 = new int[256]; for(int i=0;i&lt;s.length();i++){ if(m1[s.charAt(i)]!=m2[t.charAt(i)]) return false; m1[s.charAt(i)] = i+1; //这里只是为了避开初始化为0的情况，加几都可以 m2[t.charAt(i)] = i+1; } return true; }} 7. 回文子字符串个数647. Palindromic Substrings (Medium) 1234567891011121314151617class Solution { private int res; public int countSubstrings(String s) { for(int i=0;i&lt;s.length();i++){ extend(s,i,i); extend(s,i,i+1); } return res; } private void extend(String s,int start,int end){ while(start&gt;=0 &amp;&amp; end &lt; s.length() &amp;&amp; s.charAt(start)==s.charAt(end)){ res++; start--; end++; } }} 8.判断一个整数是否是回文数9. Palindrome Number (Easy) 要求不能使用额外空间，也就不能将整数转换为字符串进行判断。 将整数分成左右两部分，右边那部分需要转置，然后判断这两部分是否相等。 123456789101112class Solution { public boolean isPalindrome(int x) { if(x==0) return true; if(x&lt;0 || x%10==0) return false; int right = 0; while(right&lt;x){ right = right*10 + x%10; x =x/10; } return right==x || right/10==x; }}","link":"/2020/06/06/leetcode%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%BB%83%E4%B9%A0/"},{"title":"leetcode链表练习","text":"链表题的tips: 常用方法： 递归、迭代、快慢指针 prev、cur指针结合题目的使用 如果头结点不确定，考虑是否需要dummy节点 1.反转链表206. Reverse Linked List (Easy) 递归法： 12345678910class Solution { public ListNode reverseList(ListNode head) { if(head == null || head.next == null){return head;} ListNode temp = head.next; ListNode newHead = reverseList(temp); temp.next = head; //反转 head.next = null; //避免出现环 return newHead; }} 迭代法： 1234567891011121314class Solution { public ListNode reverseList(ListNode head) { if(head == null || head.next == null) return head; ListNode cur = head; ListNode prev = null; while(cur!=null){ ListNode next = cur.next; cur.next = prev; //注意顺序 prev = cur; cur = next; } return prev; }} 2.反转链表中相邻结点24. Swap Nodes in Pairs (Medium) 1234567891011121314151617class Solution { public ListNode swapPairs(ListNode head) { ListNode dummy = new ListNode(-1); dummy.next = head; ListNode prev = dummy; ListNode cur = head; while(cur!=null &amp;&amp; cur.next!=null){ ListNode next = cur.next; cur.next = cur.next.next; //1--&gt;3 next.next = prev.next; //2--&gt;1 prev.next = next; //prev--&gt;2 prev = cur; cur = cur.next; } return dummy.next; }} 3.判断链表是否有环141. Linked List Cycle(Easy) 快慢指针法： 12345678910111213public class Solution { public boolean hasCycle(ListNode head) { if(head==null || head.next== null) return false; ListNode slow = head; ListNode fast = head; while(fast!=null &amp;&amp; fast.next!=null){ slow = slow.next; fast = fast.next.next; if(fast==slow) return true; } return false; }} 4.判断链表是否有环并输出环的起始位置142. Linked List Cycle II (Medium) To understand this solution, you just need to ask yourself these question.Assume the distance from head to the start of the loop is x1 the distance from the start of the loop to the point fast and slow meet is x2 the distance from the point fast and slow meet to the start of the loop is x3 What is the distance fast moved? What is the distance slow moved? And their relationship? x1 + x2 + x3 + x2x1 + x2x1 + x2 + x3 + x2 = 2 (x1 + x2)Thus x1 = x3 12345678910111213141516171819public class Solution { public ListNode detectCycle(ListNode head) { ListNode slow = head; ListNode fast = head; while(fast!=null &amp;&amp; fast.next!=null){ slow = slow.next; fast = fast.next.next; if(fast==slow){ ListNode slow2 = head; while(slow2!=slow){ slow = slow.next; slow2 = slow2.next; } return slow2; } } return null; }} 5.归并两个有序链表21. Merge Two Sorted Lists (Easy) 递归法： 12345678910111213class Solution { public ListNode mergeTwoLists(ListNode l1, ListNode l2) { if(l1 == null) return l2; if(l2 == null) return l1; if(l1.val &lt; l2.val){ l1.next = mergeTwoLists(l1.next, l2); return l1; }else{ l2.next = mergeTwoLists(l1, l2.next); return l2; } }} 迭代法： 12345678910111213141516171819class Solution { public ListNode mergeTwoLists(ListNode l1, ListNode l2) { ListNode dummy = new ListNode(-1); ListNode cur = dummy; while(l1!=null &amp;&amp; l2!=null){ if(l1.val &lt; l2.val){ cur.next = l1; l1 = l1.next; }else{ cur.next = l2; l2 = l2.next; } cur = cur.next; } if(l1==null){cur.next = l2;} if(l2==null){cur.next = l1;} return dummy.next; }} 6.从有序链表中删除重复节点83. Remove Duplicates from Sorted List (Easy) 12345678910111213class Solution { public ListNode deleteDuplicates(ListNode head) { ListNode cur = head; while(cur!=null &amp;&amp; cur.next!=null){ if(cur.val == cur.next.val){ cur.next = cur.next.next; }else{ cur = cur.next; } } return head; }} 7.从有序链表中删除重复节点II82. Remove Duplicates from Sorted List II (Medium) 1234567891011121314151617181920class Solution { public ListNode deleteDuplicates(ListNode head) { ListNode dummy = new ListNode(0); dummy.next = head; ListNode prev = dummy; ListNode cur = head; while(cur!=null){ while(cur.next!=null &amp;&amp; cur.val == cur.next.val){ cur = cur.next; } if(prev.next == cur){ prev = cur; }else{ prev.next = cur.next; } cur = cur.next; } return dummy.next; }} 8.删除链表的倒数第 n 个结点19. Remove Nth Node From End of List (Medium) 123456789101112131415161718class Solution { public ListNode removeNthFromEnd(ListNode head, int n) { ListNode dummy = new ListNode(0); dummy.next = head; ListNode cur = head; int count = 0; while(cur!=null){ cur = cur.next; count++; } cur = dummy; for(int i=0;i&lt;count-n;i++){ cur = cur.next; } cur.next = cur.next.next; return dummy.next; }} 9.找出两个链表的交点160. Intersection of Two Linked Lists (Easy) a+c+b = a+b+c 1234567891011public class Solution { public ListNode getIntersectionNode(ListNode headA, ListNode headB) { ListNode curA = headA; ListNode curB = headB; while(curA != curB){ curA = curA==null?headB:curA.next; curB = curB==null?headA:curB.next; } return curA; }} 10.回文链表234. Palindrome Linked List (Easy) 12345678910111213141516171819202122232425262728293031class Solution { public boolean isPalindrome(ListNode head) { ListNode fast = head; ListNode slow = head; while(fast!=null &amp;&amp; fast.next!=null){ slow = slow.next; fast = fast.next.next; } ListNode slowFront = reverseList(slow); while(slowFront!=null){ if(head.val==slowFront.val){ head = head.next; slowFront = slowFront.next; }else{ return false; } } return true; } private ListNode reverseList(ListNode node){ ListNode prev = null; ListNode cur = node; while(cur!=null){ ListNode next = cur.next; cur.next = prev; prev = cur; cur = next; } return prev; }} 11.链表求和2. Add Two Numbers(Easy) 1234567891011121314151617181920212223class Solution { public ListNode addTwoNumbers(ListNode l1, ListNode l2) { ListNode dummy = new ListNode(0); ListNode cur1 = l1; ListNode cur2 = l2; ListNode cur = dummy; int carry = 0; while (cur1 != null || cur2 != null) { int x = (cur1 != null) ? cur1.val : 0; int y = (cur2 != null) ? cur2.val : 0; int sum = carry + x + y; carry = sum / 10; cur.next = new ListNode(sum % 10); cur = cur.next; if (cur1 != null) cur1 = cur1.next; if (cur2 != null) cur2 = cur2.next; } if (carry &gt; 0) { cur.next = new ListNode(carry); } return dummy.next; }} 12.分隔链表725. Split Linked List in Parts(Medium) 123456789101112131415161718192021222324class Solution { public ListNode[] splitListToParts(ListNode root, int k) { int count = 0; ListNode cur = root; ListNode prev = null; ListNode[] parts = new ListNode[k]; while(cur != null){ count++; cur = cur.next; } int n = count/k; int r = count%k; cur = root; for(int i=0;i&lt;k &amp;&amp; cur!=null;i++,r--){ parts[i] = cur; for(int j=0;j&lt;n+(r&gt;0?1:0);j++){ prev = cur; cur = cur.next; } prev.next = null; } return parts; }} 13.链表元素按奇偶聚集328. Odd Even Linked List (Medium) 要求：空间复杂度O(1),时间复杂度O(n) 123456789101112131415161718192021222324/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */class Solution { public ListNode oddEvenList(ListNode head) { if(head==null){return null;} ListNode odd = head; ListNode evenHead = head.next; ListNode even = evenHead; while(even!=null &amp;&amp; even.next!=null){ odd.next = odd.next.next; even.next = even.next.next; odd = odd.next; even = even.next; } odd.next = evenHead; return head; }}","link":"/2020/05/11/leetcode%E9%93%BE%E8%A1%A8%E7%BB%83%E4%B9%A0/"},{"title":"操作系统基础","text":"之前笔记在github上，这里直接贴上链接: 概述 启动与系统调用 进程与线程 内存管理 文件管理 I/O管理 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. Bryant, R. E., &amp; O’Hallaron, D. R. (2004). 深入理解计算机系统. 计算机操作系统[M]. 西安电子科技大学出版社 操作系统(李治军老师) 配套实验","link":"/2020/04/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"多线程","slug":"多线程","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"HTTP","slug":"HTTP","link":"/tags/HTTP/"},{"name":"HTTPS","slug":"HTTPS","link":"/tags/HTTPS/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"AQS","slug":"AQS","link":"/tags/AQS/"},{"name":"ConcurrentHashMap","slug":"ConcurrentHashMap","link":"/tags/ConcurrentHashMap/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"algorithm","slug":"algorithm","link":"/tags/algorithm/"},{"name":"leetcode","slug":"leetcode","link":"/tags/leetcode/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"Springboot","slug":"Springboot","link":"/tags/Springboot/"},{"name":"linux","slug":"linux","link":"/tags/linux/"}],"categories":[{"name":"计算机基础","slug":"计算机基础","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"计算机网络","slug":"计算机基础/计算机网络","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"Java基础","slug":"Java基础","link":"/categories/Java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"Java基础/多线程","link":"/categories/Java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"JVM","slug":"Java基础/JVM","link":"/categories/Java%E5%9F%BA%E7%A1%80/JVM/"},{"name":"数据库(MySQL)","slug":"计算机基础/数据库-MySQL","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93-MySQL/"},{"name":"数据结构与算法","slug":"计算机基础/数据结构与算法","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"集群与分布式","slug":"集群与分布式","link":"/categories/%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"Redis","slug":"集群与分布式/Redis","link":"/categories/%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/Redis/"},{"name":"操作系统(linux)","slug":"计算机基础/操作系统-linux","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-linux/"}]}